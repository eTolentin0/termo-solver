{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f0f6d4e4-283e-4a28-b3b8-f1383f2c05ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.edge.service import Service\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76a0546c-f598-47c8-a42a-e652ced2eed0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'palavras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-485eaeabf26b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'palavras_termo.txt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mpalavra\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpalavras\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mpalavra\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'done'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'palavras' is not defined"
     ]
    }
   ],
   "source": [
    "#não executar, apenas mandar para o final para adicionar palavras\n",
    "\n",
    "with open('palavras_termo.txt','w', encoding = 'utf8') as f:\n",
    "    for palavra in palavras:\n",
    "        f.write(\"%s\\n\" % palavra)\n",
    "    print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7132831-2596-4988-b452-3e2c7fefe03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cef58651-0443-4b2b-b9e6-776a747e551e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def conta_vogais(palavra):\n",
    "    \n",
    "    contador = 0\n",
    "    vogais = 'aeiouAEIOU'\n",
    "    allowed = frozenset('aeiouAEIOU')\n",
    "    \n",
    "    for letra in palavra:\n",
    "        if letra in vogais:\n",
    "            contador += 1\n",
    "    vogais_unicas = len(allowed.intersection(palavra))\n",
    "    \n",
    "    return vogais_unicas, contador\n",
    "\n",
    "\n",
    "conta_vogais('perde')    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7aedb45-776a-4e46-bc2f-b4ba89cd5c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87564c1f-35e5-4071-969e-f525cf9a661f",
   "metadata": {},
   "source": [
    "-----------------------------\n",
    "\n",
    "Palavras excluidas do dicionario baixado da usp:\n",
    "- lermo\n",
    "- canaa\n",
    "- propo\n",
    "- coemo\n",
    "- doemo\n",
    "- jobim\n",
    "- suamo\n",
    "- sorta\n",
    "- premo\n",
    "- iremo\n",
    "- prepo\n",
    "\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b2c9b38-cec9-4582-83e4-fd8cd28da1ba",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>n_vogais</th>\n",
       "      <th>vogais_unicas</th>\n",
       "      <th>letra_0</th>\n",
       "      <th>letra_1</th>\n",
       "      <th>letra_2</th>\n",
       "      <th>letra_3</th>\n",
       "      <th>letra_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aarao</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>a</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abner</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acaia</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>i</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acker</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>k</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aires</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>i</td>\n",
       "      <td>r</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  palavra  n_vogais  vogais_unicas letra_0 letra_1 letra_2 letra_3 letra_4\n",
       "0   aarao         4              2       a       a       r       a       o\n",
       "1   abner         2              2       a       b       n       e       r\n",
       "2   acaia         4              2       a       c       a       i       a\n",
       "3   acker         2              2       a       c       k       e       r\n",
       "4   aires         3              3       a       i       r       e       s"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavras = []\n",
    "file = open('br-utf8.txt', 'r', encoding = 'utf8')\n",
    "\n",
    "while True:\n",
    "    line = file.readline()\n",
    "    palavra = line.strip().replace('\\n','')\n",
    "    if not line:\n",
    "        break\n",
    "    if len(palavra) == 5:\n",
    "        #print(palavra)\n",
    "        palavras.append(remove_acentos(palavra))\n",
    "        \n",
    "\n",
    "file.close()\n",
    "\n",
    "\n",
    "#nesse caso não tem a palavra lermo, então vamos remover da lista e rodar novamente\n",
    "#criar uma função para quando isso acontecer e criar uma lista das palavras que o termo não aceita!\n",
    "#assim podemos ir melhorando o algoritmo\n",
    "\n",
    "palavras.remove('lermo')\n",
    "palavras.remove('canaa')\n",
    "palavras.remove('propo')\n",
    "palavras.remove('coemo')\n",
    "palavras.remove('doemo')\n",
    "palavras.remove('jobim')\n",
    "palavras.remove('sorta')\n",
    "palavras.remove('suamo')\n",
    "#ainda nõa executado abaixo\n",
    "palavras.remove('premo')\n",
    "palavras.remove('iremo')\n",
    "palavras.remove('prepo')\n",
    "\n",
    "\n",
    "\n",
    "#print(len(palavras))\n",
    "df = pd.DataFrame(palavras)\n",
    "df.drop_duplicates(inplace = True)\n",
    "df.rename(columns = {0:'palavra'}, inplace = True)\n",
    "\n",
    "df['n_vogais'] = df['palavra'].apply(lambda x: conta_vogais(x)[1])\n",
    "df['vogais_unicas'] = df['palavra'].apply(lambda x: conta_vogais(x)[0])\n",
    "\n",
    "\n",
    "df['letra_0'] = df.palavra.str[0]\n",
    "df['letra_1'] = df.palavra.str[1]\n",
    "df['letra_2'] = df.palavra.str[2]\n",
    "df['letra_3'] = df.palavra.str[3]\n",
    "df['letra_4'] = df.palavra.str[4]\n",
    "df.to_csv('br-utf8.csv', index = False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8d265966-b087-4ffe-b0a6-acc92d0eba62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('br-utf8.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298de44e-f959-4301-b5e3-48a02f97d458",
   "metadata": {},
   "source": [
    "# Função de sortear palavra\n",
    "estou usando esse metodo até criar um esquema de pontuação para as palavras\n",
    "\n",
    "(depois necessário criação de CSV com a pontuação e todo a manipulação de dados, para que no final só fique o filtro!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "5779b679-f337-4f5b-9dac-5162af556538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def sorteia_palavra(lista_palavra):\n",
    "    if len(lista_palavra) == 1:\n",
    "        return lista_palavra[0]\n",
    "    else:\n",
    "        return lista_palavra[random.randint(0,(len(lista_palavra)-1))]\n",
    "\n",
    "def sorteia_palavra(df):\n",
    "    if len(df) == 1:\n",
    "        return df.palavra.values.tolist()[0]\n",
    "    else:\n",
    "        mask_consoantes = df.consoantes_unicas == max(df.consoantes_unicas)\n",
    "        df = df[mask2]\n",
    "        return df.palavra[df.probabilidade == max(df.probabilidade)].values.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1b50be42-1f6e-4e41-9826-aaa769d98205",
   "metadata": {},
   "outputs": [],
   "source": [
    "melhores_palavras_para_vogais = df[df.vogais_unicas == 4]\n",
    "#escolher entre essas palavras para começar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096783d1-7512-448f-bc5e-b3777ca768d8",
   "metadata": {},
   "source": [
    "# Startando o termoo no navegador\n",
    "aqui seria onde comecei a entender como fazer a busca pela palavra e tentar criar alguma metrica pra achar letras nas strings\n",
    "\n",
    "\n",
    "como proceder com palavras que tem letras repetidas?\n",
    "\n",
    "aqui podemos fazer uma condição para cada posição estar com a letra certa\n",
    "\n",
    "\n",
    "while pos1 == wrongletter or pos2 == wrongletter or pos3 == wrongletter or pos4 == wrongletter or pos5 == wrongletter\n",
    "\n",
    "e ir lupando nas tentativas que temos, que aparentemente são 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "624ea126-5249-4682-945a-263416987904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>n_vogais</th>\n",
       "      <th>vogais_unicas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3628</th>\n",
       "      <td>nervo</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     palavra  n_vogais  vogais_unicas\n",
       "3628   nervo         2              2"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.palavra == 'nervo',:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57b1cce-c97a-4d0a-baf4-d8597743f6d5",
   "metadata": {},
   "source": [
    "esse é o pensamento inicial, depois que começar o scraping no site e inserção poderemos saber quando acertarmos a posição da letra. \n",
    "\n",
    "Quando isso acontecer será necessário trocar essa função para adicionar só palavras com letra naquela posição!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06d5c81-a004-4f56-b605-425da49b8d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebd0f0fd-d727-4cdb-884d-5066872b9656",
   "metadata": {},
   "source": [
    "teoricamente aqui conseguimos resolver mais ou menos o termo, agora é pesquisar novas metricas e testar nos outros dias, melhorando o filtro e a seleção, também seria legal rankear as palavras mais comuns e ver se conseguimos gerar um peso de palavras\n",
    "\n",
    "- trabalhar em melhorar as funções e como elas vão conversar entre elas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c9d779-6dad-4e5a-a35a-1b4146739f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed93c68-50a1-4697-8f75-6a0ffa551167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b86e270-c5cd-4cb8-af85-f8e845e3a35e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2eb7fe-ba8d-494e-8200-0dfbd38587d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c56e5132-6226-416d-b799-8cd6282690a1",
   "metadata": {},
   "source": [
    "# Organizando todas as funções!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90599355-6ded-400f-a2cd-211071b1670e",
   "metadata": {},
   "source": [
    "- Carregar o DF\n",
    "- listar as palavras melhroes rankeadas para começar o jogo\n",
    "- iniciar o jogo\n",
    "- escolher uma palavra da lista de mais rankeadas\n",
    "- mandar a primeira palavra para o jogo\n",
    "- retornar dicionario de resultado da primeira palavra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae70994-f1e8-4aed-9495-052ad7fa178b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a56624c9-c69d-473d-b12e-8a3c346152f0",
   "metadata": {},
   "source": [
    "## Core Functions - Analitics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d06071b-33eb-4030-b147-ad8e308a11bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "\n",
    "def remove_acentos(string):\n",
    "    normalized = unicodedata.normalize('NFD', string)\n",
    "    return re.sub(r'[\\u0300-\\u036f]', '', normalized).casefold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13f12b3c-4503-4681-908f-81ca26e699cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def carrega_dataframe_csv(caminho):\n",
    "    return pd.read_csv(caminho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b821920d-d48e-4ebd-8757-0287af60ef13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def sorteia_palavra_2(lista_palavra): #possivelmente ser substituida\n",
    "    if len(lista_palavra) == 1:\n",
    "        return lista_palavra[0]\n",
    "    else:\n",
    "        return lista_palavra[random.randint(0,(len(lista_palavra)-1))]\n",
    "    \n",
    "    \n",
    "def sorteia_palavra(df):\n",
    "    if len(df) == 1:\n",
    "        return df.palavra.values.tolist()[0]\n",
    "    else:\n",
    "        mask_consoantes = df.consoantes_unicas == max(df.consoantes_unicas)\n",
    "        df = df[mask_consoantes]\n",
    "        return df.palavra[df.probabilidade == max(df.probabilidade)].values.tolist()[0]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "91100f28-3d22-46f1-8e59-18b2da0c3677",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recebe lista de letra e posicao correta\n",
    "#lista_exemplo = ['letra',posicao]\n",
    "\n",
    "def letra_na_posicao(lista_letra_correta, df):\n",
    "    \n",
    "    if len(lista_letra_correta) == 0:\n",
    "        return df\n",
    "    else:\n",
    "        for letra, posicao in lista_letra_correta:\n",
    "            if posicao == 0:\n",
    "                mask = df.letra_0 == letra\n",
    "                df = df.loc[mask,:]\n",
    "            elif posicao == 1:\n",
    "                mask = df.letra_1 == letra\n",
    "                df = df.loc[mask,:]\n",
    "            elif posicao == 2:\n",
    "                mask = df.letra_2 == letra\n",
    "                df = df.loc[mask,:]\n",
    "            elif posicao == 3:\n",
    "                mask = df.letra_3 == letra\n",
    "                df = df.loc[mask,:]\n",
    "            elif posicao == 4:\n",
    "                mask = df.letra_4 == letra\n",
    "                df = df.loc[mask,:]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6c1f52bf-de42-436e-9d69-a84462e7a155",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "#https://www.tutorialspoint.com/program-to-remove-duplicate-characters-from-a-given-string-in-python\n",
    "def tira_duplicadas_palavra(s): #removendo as duplicadas da string\n",
    "    d = OrderedDict()\n",
    "    for c in s:\n",
    "        if c not in d:\n",
    "            d[c] = 0\n",
    "        d[c] += 1\n",
    "\n",
    "    return ''.join(d.keys())\n",
    "\n",
    "def confere_letras_nas_palavras(palavra, letras_desejadas): \n",
    "    #aqui uma simples checagem se as cada letra da palavra está em letras desejadas (letras)\n",
    "    contador = 0\n",
    "    reduzido = tira_duplicadas_palavra(palavra)\n",
    "    \n",
    "    for letra in tira_duplicadas_palavra(palavra):\n",
    "        if (letra in letras_desejadas): #condicional para que se tiver na palavra some 1 ao contador\n",
    "            contador += 1\n",
    "\n",
    "#     'pavor' = tira_duplicadas => 'pavor'\n",
    "#     'aro' = tira duplicadas => 'aro'\n",
    "#     len(aro) = 3\n",
    "#     contador = 3\n",
    "\n",
    "    if (contador == len(tira_duplicadas_palavra(letras_desejadas))): \n",
    "        #se for verdadeiro o tamanho das letras_desejadas com o numero do contador\n",
    "        \n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "        \n",
    "\n",
    "def palavras_com_letra_posicao_errada(lista_de_letras_com_posicao, df):\n",
    "    letras = ''\n",
    "    for letra,posicao in lista_de_letras_com_posicao:\n",
    "        letras += letra\n",
    "\n",
    "        if posicao == 0:\n",
    "            mask = (df.letra_0 != letra)\n",
    "            df = df.loc[mask,:]\n",
    "        elif posicao == 1:\n",
    "            mask = (df.letra_1 != letra)\n",
    "            df = df.loc[mask,:]\n",
    "        elif posicao == 2:\n",
    "            mask = (df.letra_2 != letra)\n",
    "            df = df.loc[mask,:]\n",
    "        elif posicao == 3:\n",
    "            mask = (df.letra_3 != letra)\n",
    "            df = df.loc[mask,:]\n",
    "        elif posicao == 4:\n",
    "            mask = (df.letra_4 != letra)\n",
    "            df = df.loc[mask,:]\n",
    "\n",
    "    return df[df.palavra.apply(lambda x: confere_letras_nas_palavras(x, letras))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3111acc2-8d47-4df2-8408-5d29dbe55f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def letras_nao_aceitas(letras, df, letras_aceitas):\n",
    "    lista = []\n",
    "\n",
    "\n",
    "    for letra, indice,status_letras_aceitas in letras:\n",
    "        if status_letras_aceitas == False:\n",
    "            lista.append(letra)\n",
    "        else:\n",
    "            mask = df[f'letra_{indice}'] != letra\n",
    "            df = df.loc[mask,:]\n",
    "\n",
    "        if len(lista) > 0:\n",
    "            mask = ~df.letra_0.isin(lista) & ~df.letra_1.isin(lista) & ~df.letra_2.isin(lista) & ~df.letra_3.isin(lista) & ~df.letra_4.isin(lista)    \n",
    "            df = df.loc[mask,:]\n",
    "        \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3155ad91-b9b5-40a7-a958-91778a4eb962",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aqui foi necessário fazer varios for, pra primeiro\n",
    "\n",
    "def descompacta_dicionario(dicionario, letras_aceitas):\n",
    "\n",
    "    letras_erradas = []\n",
    "    letras_lugar_errado = []\n",
    "    letras_corretas = []\n",
    "\n",
    "    #primeiro sempre adicionando as letras corretas!\n",
    "    for item in dicionario:\n",
    "        letra = remove_acentos(dicionario[item][1]).lower()\n",
    "        condicao = letra in letras_aceitas\n",
    "        if dicionario[item][0] == 'letter right':\n",
    "            letras_aceitas += letra\n",
    "            letras_corretas.append((dicionario[item][1], item))\n",
    "\n",
    "    #adicionando as letras corretas mas em posição errada!\n",
    "    for item in dicionario:\n",
    "        letra = remove_acentos(dicionario[item][1]).lower()\n",
    "        condicao = letra in letras_aceitas        \n",
    "        if dicionario[item][0] == 'letter place':\n",
    "            letras_aceitas += letra\n",
    "            letras_lugar_errado.append((dicionario[item][1], item))\n",
    "            \n",
    "    #e só por fim adicionar as letras erradas a equação    \n",
    "    for item in dicionario:\n",
    "        letra = remove_acentos(dicionario[item][1]).lower()\n",
    "        condicao = letra in letras_aceitas\n",
    "        if dicionario[item][0] == 'letter wrong':\n",
    "            if dicionario[item][1] in letras_aceitas:\n",
    "                letras_erradas.append((dicionario[item][1], item, True))\n",
    "                #retornando true se a letra errada está na lista de letras aceitas\n",
    "            else: \n",
    "                letras_erradas.append((dicionario[item][1], item, False))\n",
    "                #retornando false se a letra errada está na lista de letras aceitas\n",
    "    #será necessário criar uma condição só pra letra não aceita + letra aceita por causa do erro do site!\n",
    "            \n",
    "            \n",
    "            \n",
    "    return letras_erradas, letras_lugar_errado, letras_corretas, letras_aceitas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8b56cf5c-b4eb-401c-9cfa-dd88f51281de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtra_df_2(dicionario, df, letras_aceitas):\n",
    "#         envia_palavra(palavra_sorteada)\n",
    "\n",
    "#         #pegar informações da palavra enviada\n",
    "#         dicionario = retorna_dicionario_respostas(tentativa)\n",
    "\n",
    "        #retornar resultado das letras\n",
    "        letras_erradas, letras_lugar_errado, letras_corretas, letras_aceitas = descompacta_dicionario(dicionario, letras_aceitas)\n",
    "        \n",
    "        df = letras_nao_aceitas(letras_erradas, df, letras_aceitas)\n",
    "        df = palavras_com_letra_posicao_errada(letras_lugar_errado, df)\n",
    "        df = letra_na_posicao(letras_corretas, df)\n",
    "        \n",
    "        \n",
    "        return df, letras_aceitas, letras_erradas, letras_lugar_errado, letras_corretas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bcb633-918d-497d-aa6d-cfc113cb3f5e",
   "metadata": {},
   "source": [
    "# Teste resolução dueto termo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9c986075-5f7a-4d3c-991e-9eeb38e0f8b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>n_vogais</th>\n",
       "      <th>vogais_unicas</th>\n",
       "      <th>letra_0</th>\n",
       "      <th>letra_1</th>\n",
       "      <th>letra_2</th>\n",
       "      <th>letra_3</th>\n",
       "      <th>letra_4</th>\n",
       "      <th>probabilidade</th>\n",
       "      <th>n_consoantes</th>\n",
       "      <th>consoantes_unicas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aarao</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>a</td>\n",
       "      <td>o</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abner</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acaia</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>i</td>\n",
       "      <td>a</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acker</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>k</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aires</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>i</td>\n",
       "      <td>r</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  palavra  n_vogais  vogais_unicas letra_0 letra_1 letra_2 letra_3 letra_4  \\\n",
       "0   aarao         4              2       a       a       r       a       o   \n",
       "1   abner         2              2       a       b       n       e       r   \n",
       "2   acaia         4              2       a       c       a       i       a   \n",
       "3   acker         2              2       a       c       k       e       r   \n",
       "4   aires         3              3       a       i       r       e       s   \n",
       "\n",
       "   probabilidade  n_consoantes  consoantes_unicas  \n",
       "0       0.000000             1                  1  \n",
       "1       0.000000             3                  3  \n",
       "2       0.000000             1                  1  \n",
       "3       0.000000             3                  3  \n",
       "4       0.000037             2                  2  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#caminho = 'br-utf8.csv'\n",
    "caminho = 'br-utf8_prob.csv'\n",
    "\n",
    "df = carrega_dataframe_csv(caminho)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "620c3bac-cdc1-4dfa-bf71-2c9544e5619b",
   "metadata": {},
   "outputs": [],
   "source": [
    "letras_aceitas = ''\n",
    "letras_aceitas_2 = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d6d2717f-ee5d-4518-96a9-82666d1ecac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "03bc1573-218f-4a78-93de-75bda5eddb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "letras erradas:  [('e', 3, False)]\n",
      "letras lugar errado:  [('r', 2), ('o', 4)]\n",
      "letras corretas:  [('a', 0), ('u', 1)]\n",
      "letras aceitas:  auro\n",
      "--------- 2 coluna ---------\n",
      "letras erradas:  [('a', 0, False), ('e', 3, False)]\n",
      "letras lugar errado:  [('o', 4)]\n",
      "letras corretas:  [('u', 1), ('r', 2)]\n",
      "letras aceitas:  uro\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dicionario = {0: ('letter right', 'a'), 1: ('letter right', 'u'), 2: ('letter place', 'r'), 3: ('letter wrong', 'e'), 4: ('letter place', 'o')}\n",
    "dicionario_2 = {0: ('letter wrong', 'a'), 1: ('letter right', 'u'), 2: ('letter right', 'r'), 3: ('letter wrong', 'e'), 4: ('letter place', 'o')}\n",
    "\n",
    "df, letras_aceitas, letras_erradas, letras_lugar_errado, letras_corretas = filtra_df_2(dicionario, df, letras_aceitas)\n",
    "df_2, letras_aceitas_2, letras_erradas_2, letras_lugar_errado_2, letras_corretas_2 = filtra_df_2(dicionario_2, df_2, letras_aceitas_2)\n",
    "\n",
    "print('letras erradas: ', letras_erradas)\n",
    "print('letras lugar errado: ', letras_lugar_errado)\n",
    "print('letras corretas: ', letras_corretas)\n",
    "print('letras aceitas: ',letras_aceitas)\n",
    "\n",
    "print('--------- 2 coluna ---------')\n",
    "print('letras erradas: ', letras_erradas_2)\n",
    "print('letras lugar errado: ', letras_lugar_errado_2)\n",
    "print('letras corretas: ', letras_corretas_2)\n",
    "print('letras aceitas: ',letras_aceitas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6e20c4f9-5693-4c85-af49-f8be8c027d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primeiro  1\n",
      "segundo  12\n"
     ]
    }
   ],
   "source": [
    "print('primeiro ',len(df.palavra))\n",
    "print('segundo ',len(df_2.palavra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "09c41d2b-3d1b-4649-bb7e-a8be19f38bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autor\n"
     ]
    }
   ],
   "source": [
    "#print(sorteia_palavra(df.palavra.values.tolist()))\n",
    "print(sorteia_palavra(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d470251-b76f-4d35-b4b6-caf128d399ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "letras erradas:  [('g', 0, False)]\n",
      "letras lugar errado:  [('n', 2), ('r', 3)]\n",
      "letras corretas:  [('e', 1), ('o', 4)]\n",
      "letras aceitas:  oreeonr\n",
      "--------- 2 coluna ---------\n",
      "letras erradas:  [('g', 0, False), ('e', 1, False), ('r', 3, False), ('o', 4, False)]\n",
      "letras lugar errado:  [('n', 2)]\n",
      "letras corretas:  []\n",
      "letras aceitas:  aun\n"
     ]
    }
   ],
   "source": [
    "dicionario = {0: ('letter wrong', 'g'), 1: ('letter right', 'e'), 2: ('letter place', 'n'), 3: ('letter place', 'r'), 4: ('letter right', 'o')}\n",
    "dicionario_2 = {0: ('letter wrong', 'g'), 1: ('letter wrong', 'e'), 2: ('letter place', 'n'), 3: ('letter wrong', 'r'), 4: ('letter wrong', 'o')}\n",
    "\n",
    "\n",
    "df, letras_aceitas, letras_erradas, letras_lugar_errado, letras_corretas = filtra_df_2(dicionario, df, letras_aceitas)\n",
    "df_2, letras_aceitas_2, letras_erradas_2, letras_lugar_errado_2, letras_corretas_2 = filtra_df_2(dicionario_2, df_2, letras_aceitas_2)\n",
    "\n",
    "print('letras erradas: ', letras_erradas)\n",
    "print('letras lugar errado: ', letras_lugar_errado)\n",
    "print('letras corretas: ', letras_corretas)\n",
    "print('letras aceitas: ',letras_aceitas)\n",
    "print('--------- 2 coluna ---------')\n",
    "print('letras erradas: ', letras_erradas_2)\n",
    "print('letras lugar errado: ', letras_lugar_errado_2)\n",
    "print('letras corretas: ', letras_corretas_2)\n",
    "print('letras aceitas: ',letras_aceitas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d925233b-d7e9-41d5-84a8-4fac4aa42660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primeiro  1\n",
      "segundo  15\n"
     ]
    }
   ],
   "source": [
    "print('primeiro ',len(df.palavra))\n",
    "print('segundo ',len(df_2.palavra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62dad7d5-b484-4a4a-b6b0-99a0ddc13468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reino\n"
     ]
    }
   ],
   "source": [
    "print(sorteia_palavra(df.palavra.values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2ba74ec7-8112-4372-973b-c49ae7342e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- 2 coluna ---------\n",
      "letras erradas:  [('a', 0, False), ('t', 2, False)]\n",
      "letras lugar errado:  [('r', 4)]\n",
      "letras corretas:  [('u', 1), ('o', 3)]\n",
      "letras aceitas:  urouor\n"
     ]
    }
   ],
   "source": [
    "#dicionario = {0: ('letter wrong', 'c'), 1: ('letter place', 'l'), 2: ('letter place', 'a'), 3: ('letter place', 'm'), 4: ('letter right', 'o')}\n",
    "dicionario_2 = {0: ('letter wrong', 'a'), 1: ('letter right', 'u'), 2: ('letter wrong', 't'), 3: ('letter right', 'o'), 4: ('letter place', 'r')}\n",
    "\n",
    "\n",
    "#df, letras_aceitas, letras_erradas, letras_lugar_errado, letras_corretas = filtra_df_2(dicionario, df, letras_aceitas)\n",
    "df_2, letras_aceitas_2, letras_erradas_2, letras_lugar_errado_2, letras_corretas_2 = filtra_df_2(dicionario_2, df_2, letras_aceitas_2)\n",
    "\n",
    "# print('letras erradas: ', letras_erradas)\n",
    "# print('letras lugar errado: ', letras_lugar_errado)\n",
    "# print('letras corretas: ', letras_corretas)\n",
    "# print('letras aceitas: ',letras_aceitas)\n",
    "print('--------- 2 coluna ---------')\n",
    "print('letras erradas: ', letras_erradas_2)\n",
    "print('letras lugar errado: ', letras_lugar_errado_2)\n",
    "print('letras corretas: ', letras_corretas_2)\n",
    "print('letras aceitas: ',letras_aceitas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fac664e6-98ad-408b-8c37-a309a108d09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "muros\n"
     ]
    }
   ],
   "source": [
    "#print(sorteia_palavra(df_2.palavra.values.tolist()))\n",
    "print(sorteia_palavra(df_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19dde398-951e-4ada-b15d-f01c41cd5bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3c248c25-f3ce-432b-a49b-311105deed81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- 2 coluna ---------\n",
      "letras erradas:  [('m', 0, False)]\n",
      "letras lugar errado:  []\n",
      "letras corretas:  [('u', 1), ('r', 2), ('o', 3), ('s', 4)]\n",
      "letras aceitas:  urouoruros\n"
     ]
    }
   ],
   "source": [
    "dicionario_2 = {0: ('letter wrong', 'm'), 1: ('letter right', 'u'), 2: ('letter right', 'r'), 3: ('letter right', 'o'), 4: ('letter right', 's')}\n",
    "df_2, letras_aceitas_2, letras_erradas_2, letras_lugar_errado_2, letras_corretas_2 = filtra_df_2(dicionario_2, df_2, letras_aceitas_2)\n",
    "print('--------- 2 coluna ---------')\n",
    "print('letras erradas: ', letras_erradas_2)\n",
    "print('letras lugar errado: ', letras_lugar_errado_2)\n",
    "print('letras corretas: ', letras_corretas_2)\n",
    "print('letras aceitas: ',letras_aceitas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ecbd2ce1-8139-4198-9e51-d48dd147f8ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "714fb99b-7346-49b6-a128-8038c3a46f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duros\n"
     ]
    }
   ],
   "source": [
    "#print(sorteia_palavra(df_2.palavra.values.tolist()))\n",
    "print(sorteia_palavra(df_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "41d19a4a-0b96-4cc1-ac3e-1b83d9b2b420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>n_vogais</th>\n",
       "      <th>vogais_unicas</th>\n",
       "      <th>letra_0</th>\n",
       "      <th>letra_1</th>\n",
       "      <th>letra_2</th>\n",
       "      <th>letra_3</th>\n",
       "      <th>letra_4</th>\n",
       "      <th>probabilidade</th>\n",
       "      <th>n_consoantes</th>\n",
       "      <th>consoantes_unicas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>duros</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "      <td>r</td>\n",
       "      <td>o</td>\n",
       "      <td>s</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2185</th>\n",
       "      <td>furos</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>f</td>\n",
       "      <td>u</td>\n",
       "      <td>r</td>\n",
       "      <td>o</td>\n",
       "      <td>s</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2606</th>\n",
       "      <td>juros</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>j</td>\n",
       "      <td>u</td>\n",
       "      <td>r</td>\n",
       "      <td>o</td>\n",
       "      <td>s</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3436</th>\n",
       "      <td>ouros</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>o</td>\n",
       "      <td>u</td>\n",
       "      <td>r</td>\n",
       "      <td>o</td>\n",
       "      <td>s</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3846</th>\n",
       "      <td>puros</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>p</td>\n",
       "      <td>u</td>\n",
       "      <td>r</td>\n",
       "      <td>o</td>\n",
       "      <td>s</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     palavra  n_vogais  vogais_unicas letra_0 letra_1 letra_2 letra_3 letra_4  \\\n",
       "1680   duros         2              2       d       u       r       o       s   \n",
       "2185   furos         2              2       f       u       r       o       s   \n",
       "2606   juros         2              2       j       u       r       o       s   \n",
       "3436   ouros         3              2       o       u       r       o       s   \n",
       "3846   puros         2              2       p       u       r       o       s   \n",
       "\n",
       "      probabilidade  n_consoantes  consoantes_unicas  \n",
       "1680       0.000224             3                  3  \n",
       "2185       0.000037             3                  3  \n",
       "2606       0.000000             3                  3  \n",
       "3436       0.000000             2                  2  \n",
       "3846       0.000056             3                  3  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bb7706da-c742-4575-adf9-379ea08b1a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- 2 coluna ---------\n",
      "letras erradas:  [('d', 0, False)]\n",
      "letras lugar errado:  []\n",
      "letras corretas:  [('u', 1), ('r', 2), ('o', 3), ('s', 4)]\n",
      "letras aceitas:  urouorurosuros\n"
     ]
    }
   ],
   "source": [
    "dicionario_2 = {0: ('letter wrong', 'd'), 1: ('letter right', 'u'), 2: ('letter right', 'r'), 3: ('letter right', 'o'), 4: ('letter right', 's')}\n",
    "df_2, letras_aceitas_2, letras_erradas_2, letras_lugar_errado_2, letras_corretas_2 = filtra_df_2(dicionario_2, df_2, letras_aceitas_2)\n",
    "print('--------- 2 coluna ---------')\n",
    "print('letras erradas: ', letras_erradas_2)\n",
    "print('letras lugar errado: ', letras_lugar_errado_2)\n",
    "print('letras corretas: ', letras_corretas_2)\n",
    "print('letras aceitas: ',letras_aceitas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b0446a7f-c5d3-4772-996d-3cd351fbfc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "puros\n"
     ]
    }
   ],
   "source": [
    "print(sorteia_palavra(df_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "257d6871-7a63-440f-ae03-c2d089ad28a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- 2 coluna ---------\n",
      "letras erradas:  [('p', 0, False)]\n",
      "letras lugar errado:  []\n",
      "letras corretas:  [('u', 1), ('r', 2), ('o', 3), ('s', 4)]\n",
      "letras aceitas:  urouorurosurosuros\n"
     ]
    }
   ],
   "source": [
    "dicionario_2 = {0: ('letter wrong', 'p'), 1: ('letter right', 'u'), 2: ('letter right', 'r'), 3: ('letter right', 'o'), 4: ('letter right', 's')}\n",
    "df_2, letras_aceitas_2, letras_erradas_2, letras_lugar_errado_2, letras_corretas_2 = filtra_df_2(dicionario_2, df_2, letras_aceitas_2)\n",
    "print('--------- 2 coluna ---------')\n",
    "print('letras erradas: ', letras_erradas_2)\n",
    "print('letras lugar errado: ', letras_lugar_errado_2)\n",
    "print('letras corretas: ', letras_corretas_2)\n",
    "print('letras aceitas: ',letras_aceitas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a3e2312f-edaf-42b5-9f9b-568e6d568c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "furos\n"
     ]
    }
   ],
   "source": [
    "print(sorteia_palavra(df_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "16e8974d-ae30-4531-82fd-4c3f43715521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- 2 coluna ---------\n",
      "letras erradas:  [('f', 0, False)]\n",
      "letras lugar errado:  []\n",
      "letras corretas:  [('u', 1), ('r', 2), ('o', 3), ('s', 4)]\n",
      "letras aceitas:  urouorurosurosurosuros\n"
     ]
    }
   ],
   "source": [
    "dicionario_2 = {0: ('letter wrong', 'f'), 1: ('letter right', 'u'), 2: ('letter right', 'r'), 3: ('letter right', 'o'), 4: ('letter right', 's')}\n",
    "df_2, letras_aceitas_2, letras_erradas_2, letras_lugar_errado_2, letras_corretas_2 = filtra_df_2(dicionario_2, df_2, letras_aceitas_2)\n",
    "print('--------- 2 coluna ---------')\n",
    "print('letras erradas: ', letras_erradas_2)\n",
    "print('letras lugar errado: ', letras_lugar_errado_2)\n",
    "print('letras corretas: ', letras_corretas_2)\n",
    "print('letras aceitas: ',letras_aceitas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d865564f-2acf-4a7e-964f-9591b8703525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "juros\n"
     ]
    }
   ],
   "source": [
    "print(sorteia_palavra(df_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61213e8e-020c-495e-8fbf-92341e1686d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1469e49-116b-4966-a012-5ae2bbad5a86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d72f8eb-61a9-4164-aedb-04018b969d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>n_vogais</th>\n",
       "      <th>vogais_unicas</th>\n",
       "      <th>letra_0</th>\n",
       "      <th>letra_1</th>\n",
       "      <th>letra_2</th>\n",
       "      <th>letra_3</th>\n",
       "      <th>letra_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5135</th>\n",
       "      <td>veste</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>v</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     palavra  n_vogais  vogais_unicas letra_0 letra_1 letra_2 letra_3 letra_4\n",
       "5135   veste         2              1       v       e       s       t       e"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicionario_2 = {0: ('letter right', 'v'), 1: ('letter right', 'e'), 2: ('letter wrong', 'n'), 3: ('letter right', 't'), 4: ('letter right', 'e')}\n",
    "df_2, letras_aceitas_2, letras_erradas_2, letras_lugar_errado_2, letras_corretas_2 = filtra_df_2(dicionario_2, df_2, letras_aceitas_2)\n",
    "df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625641c2-bbe2-4ee7-b293-86ec26d1f96a",
   "metadata": {},
   "source": [
    "# Teste de resolução do quarteto termo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37053b10-42df-404f-bde9-757b0cd90115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- 1 coluna ---------\n",
      "letras erradas:  [('u', 1, False), ('e', 3, False), ('o', 4, False)]\n",
      "letras lugar errado:  [('a', 0), ('r', 2)]\n",
      "letras corretas:  []\n",
      "letras aceitas:  ar\n",
      "--------- 2 coluna ---------\n",
      "letras erradas:  [('r', 2, False), ('e', 3, False)]\n",
      "letras lugar errado:  [('a', 0), ('u', 1), ('o', 4)]\n",
      "letras corretas:  []\n",
      "letras aceitas:  auo\n",
      "--------- 3 coluna ---------\n",
      "letras erradas:  [('a', 0, False), ('u', 1, False), ('e', 3, False)]\n",
      "letras lugar errado:  [('r', 2), ('o', 4)]\n",
      "letras corretas:  []\n",
      "letras aceitas:  ro\n",
      "--------- 4 coluna ---------\n",
      "letras erradas:  [('a', 0, False), ('u', 1, False), ('r', 2, False), ('e', 3, False)]\n",
      "letras lugar errado:  []\n",
      "letras corretas:  [('o', 4)]\n",
      "letras aceitas:  o\n"
     ]
    }
   ],
   "source": [
    "caminho = 'br-utf8.csv'\n",
    "\n",
    "df = carrega_dataframe_csv(caminho)\n",
    "df.head(5)\n",
    "\n",
    "letras_aceitas = ''\n",
    "letras_aceitas_2 = ''\n",
    "letras_aceitas_3 = ''\n",
    "letras_aceitas_4 = ''\n",
    "\n",
    "\n",
    "dicionario = {0: ('letter place', 'a'), 1: ('letter wrong', 'u'), 2: ('letter place', 'r'), 3: ('letter wrong', 'e'), 4: ('letter wrong', 'o')}\n",
    "dicionario_2 = {0: ('letter place', 'a'), 1: ('letter place', 'u'), 2: ('letter wrong', 'r'), 3: ('letter wrong', 'e'), 4: ('letter place', 'o')}\n",
    "dicionario_3 = {0: ('letter wrong', 'a'), 1: ('letter wrong', 'u'), 2: ('letter place', 'r'), 3: ('letter wrong', 'e'), 4: ('letter place', 'o')}\n",
    "dicionario_4 = {0: ('letter wrong', 'a'), 1: ('letter wrong', 'u'), 2: ('letter wrong', 'r'), 3: ('letter wrong', 'e'), 4: ('letter right', 'o')}\n",
    "\n",
    "\n",
    "df_2 = df.copy()\n",
    "df_3 = df.copy()\n",
    "df_4 = df.copy()\n",
    "\n",
    "df, letras_aceitas, letras_erradas, letras_lugar_errado, letras_corretas = filtra_df_2(dicionario, df, letras_aceitas)\n",
    "df_2, letras_aceitas_2, letras_erradas_2, letras_lugar_errado_2, letras_corretas_2 = filtra_df_2(dicionario_2, df_2, letras_aceitas_2)\n",
    "df_3, letras_aceitas_3, letras_erradas_3, letras_lugar_errado_3, letras_corretas_3 = filtra_df_2(dicionario_3, df_3, letras_aceitas_3)\n",
    "df_4, letras_aceitas_4, letras_erradas_4, letras_lugar_errado_4, letras_corretas_4 = filtra_df_2(dicionario_4, df_4, letras_aceitas_4)\n",
    "\n",
    "print('--------- 1 coluna ---------')\n",
    "print('letras erradas: ', letras_erradas)\n",
    "print('letras lugar errado: ', letras_lugar_errado)\n",
    "print('letras corretas: ', letras_corretas)\n",
    "print('letras aceitas: ',letras_aceitas)\n",
    "\n",
    "print('--------- 2 coluna ---------')\n",
    "print('letras erradas: ', letras_erradas_2)\n",
    "print('letras lugar errado: ', letras_lugar_errado_2)\n",
    "print('letras corretas: ', letras_corretas_2)\n",
    "print('letras aceitas: ',letras_aceitas_2)\n",
    "\n",
    "print('--------- 3 coluna ---------')\n",
    "print('letras erradas: ', letras_erradas_3)\n",
    "print('letras lugar errado: ', letras_lugar_errado_3)\n",
    "print('letras corretas: ', letras_corretas_3)\n",
    "print('letras aceitas: ',letras_aceitas_3)\n",
    "\n",
    "print('--------- 4 coluna ---------')\n",
    "print('letras erradas: ', letras_erradas_4)\n",
    "print('letras lugar errado: ', letras_lugar_errado_4)\n",
    "print('letras corretas: ', letras_corretas_4)\n",
    "print('letras aceitas: ',letras_aceitas_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ab69acb-cc9c-485a-ab6b-830f1c379fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primeiro  195\n",
      "segundo  41\n",
      "terceiro  27\n",
      "quarto  162\n"
     ]
    }
   ],
   "source": [
    "print('primeiro ',len(df.palavra))\n",
    "print('segundo ',len(df_2.palavra))\n",
    "print('terceiro ',len(df_3.palavra))\n",
    "print('quarto ',len(df_4.palavra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78f75bda-502a-43b8-86c8-cbfd3b2296a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rolos\n"
     ]
    }
   ],
   "source": [
    "print(sorteia_palavra(df_3.palavra.values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ecd050c3-e04a-42a0-bac6-fb0ab4ef937a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fruis\n"
     ]
    }
   ],
   "source": [
    "print(sorteia_palavra(df.palavra.values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "817d79f2-76bc-47f4-855e-7384f801a7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "letras erradas:  [('o', 1, False), ('l', 2, False), ('o', 3, False), ('s', 4, False)]\n",
      "letras lugar errado:  [('r', 0)]\n",
      "letras corretas:  []\n",
      "letras aceitas:  arr\n",
      "--------- 2 coluna ---------\n",
      "letras erradas:  [('r', 0, False), ('l', 2, False), ('o', 3, True), ('s', 4, False)]\n",
      "letras lugar errado:  []\n",
      "letras corretas:  [('o', 1)]\n",
      "letras aceitas:  auoo\n",
      "--------- 3 coluna ---------\n",
      "letras erradas:  [('o', 1, True), ('l', 2, False)]\n",
      "letras lugar errado:  []\n",
      "letras corretas:  [('r', 0), ('o', 3), ('s', 4)]\n",
      "letras aceitas:  roros\n",
      "--------- 4 coluna ---------\n",
      "letras erradas:  [('r', 0, False), ('l', 2, False), ('o', 3, True)]\n",
      "letras lugar errado:  [('o', 1), ('s', 4)]\n",
      "letras corretas:  []\n",
      "letras aceitas:  oos\n"
     ]
    }
   ],
   "source": [
    "dicionario = {0: ('letter place', 'r'), 1: ('letter wrong', 'o'), 2: ('letter wrong', 'l'), 3: ('letter wrong', 'o'), 4: ('letter wrong', 's')}\n",
    "dicionario_2 = {0: ('letter wrong', 'r'), 1: ('letter right', 'o'), 2: ('letter wrong', 'l'), 3: ('letter wrong', 'o'), 4: ('letter wrong', 's')}\n",
    "dicionario_3 = {0: ('letter right', 'r'), 1: ('letter wrong', 'o'), 2: ('letter wrong', 'l'), 3: ('letter right', 'o'), 4: ('letter right', 's')}\n",
    "dicionario_4 = {0: ('letter wrong', 'r'), 1: ('letter place', 'o'), 2: ('letter wrong', 'l'), 3: ('letter wrong', 'o'), 4: ('letter place', 's')}\n",
    "\n",
    "df, letras_aceitas, letras_erradas, letras_lugar_errado, letras_corretas = filtra_df_2(dicionario, df, letras_aceitas)\n",
    "df_2, letras_aceitas_2, letras_erradas_2, letras_lugar_errado_2, letras_corretas_2 = filtra_df_2(dicionario_2, df_2, letras_aceitas_2)\n",
    "df_3, letras_aceitas_3, letras_erradas_3, letras_lugar_errado_3, letras_corretas_3 = filtra_df_2(dicionario_3, df_3, letras_aceitas_3)\n",
    "df_4, letras_aceitas_4, letras_erradas_4, letras_lugar_errado_4, letras_corretas_4 = filtra_df_2(dicionario_4, df_4, letras_aceitas_4)\n",
    "\n",
    "print('letras erradas: ', letras_erradas)\n",
    "print('letras lugar errado: ', letras_lugar_errado)\n",
    "print('letras corretas: ', letras_corretas)\n",
    "print('letras aceitas: ',letras_aceitas)\n",
    "\n",
    "print('--------- 2 coluna ---------')\n",
    "print('letras erradas: ', letras_erradas_2)\n",
    "print('letras lugar errado: ', letras_lugar_errado_2)\n",
    "print('letras corretas: ', letras_corretas_2)\n",
    "print('letras aceitas: ',letras_aceitas_2)\n",
    "\n",
    "print('--------- 3 coluna ---------')\n",
    "print('letras erradas: ', letras_erradas_3)\n",
    "print('letras lugar errado: ', letras_lugar_errado_3)\n",
    "print('letras corretas: ', letras_corretas_3)\n",
    "print('letras aceitas: ',letras_aceitas_3)\n",
    "\n",
    "print('--------- 4 coluna ---------')\n",
    "print('letras erradas: ', letras_erradas_4)\n",
    "print('letras lugar errado: ', letras_lugar_errado_4)\n",
    "print('letras corretas: ', letras_corretas_4)\n",
    "print('letras aceitas: ',letras_aceitas_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5744fb0c-d21d-4ee8-a364-dcee115d8a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primeiro  107\n",
      "segundo  4\n",
      "terceiro  5\n",
      "quarto  25\n"
     ]
    }
   ],
   "source": [
    "print('primeiro ',len(df.palavra))\n",
    "print('segundo ',len(df_2.palavra))\n",
    "print('terceiro ',len(df_3.palavra))\n",
    "print('quarto ',len(df_4.palavra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a418e5af-0973-4c5f-8421-897d47bf0bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "touca\n"
     ]
    }
   ],
   "source": [
    "print(sorteia_palavra(df_2.palavra.values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df4e02ee-5cff-4c93-a3ed-3a786c16defe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "letras erradas:  [('t', 0, False), ('o', 1, False), ('u', 2, False), ('c', 3, False)]\n",
      "letras lugar errado:  []\n",
      "letras corretas:  [('a', 4)]\n",
      "letras aceitas:  arra\n",
      "--------- 2 coluna ---------\n",
      "letras erradas:  [('t', 0, False)]\n",
      "letras lugar errado:  []\n",
      "letras corretas:  [('o', 1), ('u', 2), ('c', 3), ('a', 4)]\n",
      "letras aceitas:  auooouca\n",
      "--------- 3 coluna ---------\n",
      "letras erradas:  [('t', 0, False), ('u', 2, False), ('a', 4, False)]\n",
      "letras lugar errado:  [('o', 1), ('c', 3)]\n",
      "letras corretas:  []\n",
      "letras aceitas:  rorosoc\n",
      "--------- 4 coluna ---------\n",
      "letras erradas:  [('t', 0, False), ('u', 2, False), ('c', 3, False), ('a', 4, False)]\n",
      "letras lugar errado:  [('o', 1)]\n",
      "letras corretas:  []\n",
      "letras aceitas:  ooso\n"
     ]
    }
   ],
   "source": [
    "dicionario = {0: ('letter wrong', 't'), 1: ('letter wrong', 'o'), 2: ('letter wrong', 'u'), 3: ('letter wrong', 'c'), 4: ('letter right', 'a')}\n",
    "dicionario_2 = {0: ('letter wrong', 't'), 1: ('letter right', 'o'), 2: ('letter right', 'u'), 3: ('letter right', 'c'), 4: ('letter right', 'a')}\n",
    "dicionario_3 = {0: ('letter wrong', 't'), 1: ('letter place', 'o'), 2: ('letter wrong', 'u'), 3: ('letter place', 'c'), 4: ('letter wrong', 'a')}\n",
    "dicionario_4 = {0: ('letter wrong', 't'), 1: ('letter place', 'o'), 2: ('letter wrong', 'u'), 3: ('letter wrong', 'c'), 4: ('letter wrong', 'a')}\n",
    "\n",
    "df, letras_aceitas, letras_erradas, letras_lugar_errado, letras_corretas = filtra_df_2(dicionario, df, letras_aceitas)\n",
    "df_2, letras_aceitas_2, letras_erradas_2, letras_lugar_errado_2, letras_corretas_2 = filtra_df_2(dicionario_2, df_2, letras_aceitas_2)\n",
    "df_3, letras_aceitas_3, letras_erradas_3, letras_lugar_errado_3, letras_corretas_3 = filtra_df_2(dicionario_3, df_3, letras_aceitas_3)\n",
    "df_4, letras_aceitas_4, letras_erradas_4, letras_lugar_errado_4, letras_corretas_4 = filtra_df_2(dicionario_4, df_4, letras_aceitas_4)\n",
    "\n",
    "print('letras erradas: ', letras_erradas)\n",
    "print('letras lugar errado: ', letras_lugar_errado)\n",
    "print('letras corretas: ', letras_corretas)\n",
    "print('letras aceitas: ',letras_aceitas)\n",
    "\n",
    "print('--------- 2 coluna ---------')\n",
    "print('letras erradas: ', letras_erradas_2)\n",
    "print('letras lugar errado: ', letras_lugar_errado_2)\n",
    "print('letras corretas: ', letras_corretas_2)\n",
    "print('letras aceitas: ',letras_aceitas_2)\n",
    "\n",
    "print('--------- 3 coluna ---------')\n",
    "print('letras erradas: ', letras_erradas_3)\n",
    "print('letras lugar errado: ', letras_lugar_errado_3)\n",
    "print('letras corretas: ', letras_corretas_3)\n",
    "print('letras aceitas: ',letras_aceitas_3)\n",
    "\n",
    "print('--------- 4 coluna ---------')\n",
    "print('letras erradas: ', letras_erradas_4)\n",
    "print('letras lugar errado: ', letras_lugar_errado_4)\n",
    "print('letras corretas: ', letras_corretas_4)\n",
    "print('letras aceitas: ',letras_aceitas_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3201fb8-65c5-4e67-8129-6ecf81a0f75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primeiro  32\n",
      "segundo  1\n",
      "terceiro  1\n",
      "quarto  9\n"
     ]
    }
   ],
   "source": [
    "print('primeiro ',len(df.palavra))\n",
    "print('segundo ',len(df_2.palavra))\n",
    "print('terceiro ',len(df_3.palavra))\n",
    "print('quarto ',len(df_4.palavra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ba204aeb-4512-4efb-ac0b-19f5526cd619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pouca\n",
      "ricos\n"
     ]
    }
   ],
   "source": [
    "print(sorteia_palavra(df_2.palavra.values.tolist()))\n",
    "print(sorteia_palavra(df_3.palavra.values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca26cfe3-8e97-444f-8049-797c15c16f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- 1 coluna ---------\n",
      "letras erradas:  [('p', 0, False), ('o', 1, False), ('u', 2, False), ('c', 3, False)]\n",
      "letras lugar errado:  []\n",
      "letras corretas:  [('a', 4)]\n",
      "letras aceitas:  arraa\n",
      "--------- 2 coluna ---------\n",
      "letras erradas:  []\n",
      "letras lugar errado:  []\n",
      "letras corretas:  [('p', 0), ('o', 1), ('u', 2), ('c', 3), ('a', 4)]\n",
      "letras aceitas:  auoooucapouca\n",
      "--------- 3 coluna ---------\n",
      "letras erradas:  [('p', 0, False), ('u', 2, False), ('a', 4, False)]\n",
      "letras lugar errado:  [('o', 1), ('c', 3)]\n",
      "letras corretas:  []\n",
      "letras aceitas:  rorosococ\n",
      "--------- 4 coluna ---------\n",
      "letras erradas:  [('p', 0, False), ('u', 2, False), ('c', 3, False), ('a', 4, False)]\n",
      "letras lugar errado:  [('o', 1)]\n",
      "letras corretas:  []\n",
      "letras aceitas:  oosoo\n"
     ]
    }
   ],
   "source": [
    "dicionario = {0: ('letter wrong', 'p'), 1: ('letter wrong', 'o'), 2: ('letter wrong', 'u'), 3: ('letter wrong', 'c'), 4: ('letter right', 'a')}\n",
    "dicionario_2 = {0: ('letter right', 'p'), 1: ('letter right', 'o'), 2: ('letter right', 'u'), 3: ('letter right', 'c'), 4: ('letter right', 'a')}\n",
    "dicionario_3 = {0: ('letter wrong', 'p'), 1: ('letter place', 'o'), 2: ('letter wrong', 'u'), 3: ('letter place', 'c'), 4: ('letter wrong', 'a')}\n",
    "dicionario_4 = {0: ('letter wrong', 'p'), 1: ('letter place', 'o'), 2: ('letter wrong', 'u'), 3: ('letter wrong', 'c'), 4: ('letter wrong', 'a')}\n",
    "\n",
    "df, letras_aceitas, letras_erradas, letras_lugar_errado, letras_corretas = filtra_df_2(dicionario, df, letras_aceitas)\n",
    "df_2, letras_aceitas_2, letras_erradas_2, letras_lugar_errado_2, letras_corretas_2 = filtra_df_2(dicionario_2, df_2, letras_aceitas_2)\n",
    "df_3, letras_aceitas_3, letras_erradas_3, letras_lugar_errado_3, letras_corretas_3 = filtra_df_2(dicionario_3, df_3, letras_aceitas_3)\n",
    "df_4, letras_aceitas_4, letras_erradas_4, letras_lugar_errado_4, letras_corretas_4 = filtra_df_2(dicionario_4, df_4, letras_aceitas_4)\n",
    "\n",
    "print('--------- 1 coluna ---------')\n",
    "print('letras erradas: ', letras_erradas)\n",
    "print('letras lugar errado: ', letras_lugar_errado)\n",
    "print('letras corretas: ', letras_corretas)\n",
    "print('letras aceitas: ',letras_aceitas)\n",
    "\n",
    "print('--------- 2 coluna ---------')\n",
    "print('letras erradas: ', letras_erradas_2)\n",
    "print('letras lugar errado: ', letras_lugar_errado_2)\n",
    "print('letras corretas: ', letras_corretas_2)\n",
    "print('letras aceitas: ',letras_aceitas_2)\n",
    "\n",
    "print('--------- 3 coluna ---------')\n",
    "print('letras erradas: ', letras_erradas_3)\n",
    "print('letras lugar errado: ', letras_lugar_errado_3)\n",
    "print('letras corretas: ', letras_corretas_3)\n",
    "print('letras aceitas: ',letras_aceitas_3)\n",
    "\n",
    "print('--------- 4 coluna ---------')\n",
    "print('letras erradas: ', letras_erradas_4)\n",
    "print('letras lugar errado: ', letras_lugar_errado_4)\n",
    "print('letras corretas: ', letras_corretas_4)\n",
    "print('letras aceitas: ',letras_aceitas_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b5a675d-5041-41d9-82c6-c4c925fe91af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primeiro  26\n",
      "segundo  1\n",
      "terceiro  1\n",
      "quarto  7\n"
     ]
    }
   ],
   "source": [
    "print('primeiro ',len(df.palavra))\n",
    "print('segundo ',len(df_2.palavra))\n",
    "print('terceiro ',len(df_3.palavra))\n",
    "print('quarto ',len(df_4.palavra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2ced58cc-b0d7-4b60-bfe6-25a30f07fad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ricos\n"
     ]
    }
   ],
   "source": [
    "print(sorteia_palavra(df_3.palavra.values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6512b2d1-c8cc-4f6a-9de7-b46203642504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- 1 coluna ---------\n",
      "letras erradas:  [('i', 1, False), ('c', 2, False), ('o', 3, False), ('s', 4, False)]\n",
      "letras lugar errado:  [('r', 0)]\n",
      "letras corretas:  []\n",
      "letras aceitas:  arraar\n",
      "--------- 4 coluna ---------\n",
      "letras erradas:  [('r', 0, False), ('c', 2, False)]\n",
      "letras lugar errado:  [('o', 3), ('s', 4)]\n",
      "letras corretas:  [('i', 1)]\n",
      "letras aceitas:  oosooios\n"
     ]
    }
   ],
   "source": [
    "dicionario = {0: ('letter place', 'r'), 1: ('letter wrong', 'i'), 2: ('letter wrong', 'c'), 3: ('letter wrong', 'o'), 4: ('letter wrong', 's')}\n",
    "#dicionario_2 = {0: ('letter right', 'p'), 1: ('letter right', 'o'), 2: ('letter right', 'u'), 3: ('letter right', 'c'), 4: ('letter right', 'a')}\n",
    "#dicionario_3 = {0: ('letter wrong', 'p'), 1: ('letter place', 'o'), 2: ('letter wrong', 'u'), 3: ('letter place', 'c'), 4: ('letter wrong', 'a')}\n",
    "dicionario_4 = {0: ('letter wrong', 'r'), 1: ('letter right', 'i'), 2: ('letter wrong', 'c'), 3: ('letter place', 'o'), 4: ('letter place', 's')}\n",
    "\n",
    "df, letras_aceitas, letras_erradas, letras_lugar_errado, letras_corretas = filtra_df_2(dicionario, df, letras_aceitas)\n",
    "#df_2, letras_aceitas_2, letras_erradas_2, letras_lugar_errado_2, letras_corretas_2 = filtra_df_2(dicionario_2, df_2, letras_aceitas_2)\n",
    "#df_3, letras_aceitas_3, letras_erradas_3, letras_lugar_errado_3, letras_corretas_3 = filtra_df_2(dicionario_3, df_3, letras_aceitas_3)\n",
    "df_4, letras_aceitas_4, letras_erradas_4, letras_lugar_errado_4, letras_corretas_4 = filtra_df_2(dicionario_4, df_4, letras_aceitas_4)\n",
    "\n",
    "print('--------- 1 coluna ---------')\n",
    "print('letras erradas: ', letras_erradas)\n",
    "print('letras lugar errado: ', letras_lugar_errado)\n",
    "print('letras corretas: ', letras_corretas)\n",
    "print('letras aceitas: ',letras_aceitas)\n",
    "\n",
    "# print('--------- 2 coluna ---------')\n",
    "# print('letras erradas: ', letras_erradas_2)\n",
    "# print('letras lugar errado: ', letras_lugar_errado_2)\n",
    "# print('letras corretas: ', letras_corretas_2)\n",
    "# print('letras aceitas: ',letras_aceitas_2)\n",
    "\n",
    "# print('--------- 3 coluna ---------')\n",
    "# print('letras erradas: ', letras_erradas_3)\n",
    "# print('letras lugar errado: ', letras_lugar_errado_3)\n",
    "# print('letras corretas: ', letras_corretas_3)\n",
    "# print('letras aceitas: ',letras_aceitas_3)\n",
    "\n",
    "print('--------- 4 coluna ---------')\n",
    "print('letras erradas: ', letras_erradas_4)\n",
    "print('letras lugar errado: ', letras_lugar_errado_4)\n",
    "print('letras corretas: ', letras_corretas_4)\n",
    "print('letras aceitas: ',letras_aceitas_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2505ce51-7a1c-4a36-8532-f37b2b6a9354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segundo  14\n",
      "terceiro  6\n"
     ]
    }
   ],
   "source": [
    "print('segundo ',len(df.palavra))\n",
    "print('terceiro ',len(df_4.palavra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e7a1ea1b-9e25-4579-be98-e1ddbb6b6df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fisgo\n"
     ]
    }
   ],
   "source": [
    "print(sorteia_palavra(df_4.palavra.values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "14acfe9d-d9a9-4f2b-a82d-1aef71036d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- 1 coluna ---------\n",
      "letras erradas:  [('f', 0, False), ('i', 1, False), ('s', 2, False), ('g', 3, False), ('o', 4, False)]\n",
      "letras lugar errado:  []\n",
      "letras corretas:  []\n",
      "letras aceitas:  arraar\n",
      "--------- 4 coluna ---------\n",
      "letras erradas:  [('f', 0, False), ('g', 3, False)]\n",
      "letras lugar errado:  []\n",
      "letras corretas:  [('i', 1), ('s', 2), ('o', 4)]\n",
      "letras aceitas:  oosooiosiso\n"
     ]
    }
   ],
   "source": [
    "dicionario = {0: ('letter wrong', 'f'), 1: ('letter wrong', 'i'), 2: ('letter wrong', 's'), 3: ('letter wrong', 'g'), 4: ('letter wrong', 'o')}\n",
    "#dicionario_2 = {0: ('letter right', 'p'), 1: ('letter right', 'o'), 2: ('letter right', 'u'), 3: ('letter right', 'c'), 4: ('letter right', 'a')}\n",
    "#dicionario_3 = {0: ('letter wrong', 'p'), 1: ('letter place', 'o'), 2: ('letter wrong', 'u'), 3: ('letter place', 'c'), 4: ('letter wrong', 'a')}\n",
    "dicionario_4 = {0: ('letter wrong', 'f'), 1: ('letter right', 'i'), 2: ('letter right', 's'), 3: ('letter wrong', 'g'), 4: ('letter right', 'o')}\n",
    "\n",
    "df, letras_aceitas, letras_erradas, letras_lugar_errado, letras_corretas = filtra_df_2(dicionario, df, letras_aceitas)\n",
    "#df_2, letras_aceitas_2, letras_erradas_2, letras_lugar_errado_2, letras_corretas_2 = filtra_df_2(dicionario_2, df_2, letras_aceitas_2)\n",
    "#df_3, letras_aceitas_3, letras_erradas_3, letras_lugar_errado_3, letras_corretas_3 = filtra_df_2(dicionario_3, df_3, letras_aceitas_3)\n",
    "df_4, letras_aceitas_4, letras_erradas_4, letras_lugar_errado_4, letras_corretas_4 = filtra_df_2(dicionario_4, df_4, letras_aceitas_4)\n",
    "\n",
    "print('--------- 1 coluna ---------')\n",
    "print('letras erradas: ', letras_erradas)\n",
    "print('letras lugar errado: ', letras_lugar_errado)\n",
    "print('letras corretas: ', letras_corretas)\n",
    "print('letras aceitas: ',letras_aceitas)\n",
    "\n",
    "# print('--------- 2 coluna ---------')\n",
    "# print('letras erradas: ', letras_erradas_2)\n",
    "# print('letras lugar errado: ', letras_lugar_errado_2)\n",
    "# print('letras corretas: ', letras_corretas_2)\n",
    "# print('letras aceitas: ',letras_aceitas_2)\n",
    "\n",
    "# print('--------- 3 coluna ---------')\n",
    "# print('letras erradas: ', letras_erradas_3)\n",
    "# print('letras lugar errado: ', letras_lugar_errado_3)\n",
    "# print('letras corretas: ', letras_corretas_3)\n",
    "# print('letras aceitas: ',letras_aceitas_3)\n",
    "\n",
    "print('--------- 4 coluna ---------')\n",
    "print('letras erradas: ', letras_erradas_4)\n",
    "print('letras lugar errado: ', letras_lugar_errado_4)\n",
    "print('letras corretas: ', letras_corretas_4)\n",
    "print('letras aceitas: ',letras_aceitas_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0bb12102-62aa-405c-bb32-6242b963e72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primeiro  5\n",
      "quarto  3\n"
     ]
    }
   ],
   "source": [
    "print('primeiro ',len(df.palavra))\n",
    "print('quarto ',len(df_4.palavra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e8f3a52e-0a92-47d3-8ec3-46404b51518c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nisso\n"
     ]
    }
   ],
   "source": [
    "print(sorteia_palavra(df_4.palavra.values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ce0de140-91e8-4485-9c2c-63879c586d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- 1 coluna ---------\n",
      "letras erradas:  [('n', 0, False), ('i', 1, False), ('s', 2, False), ('s', 3, False), ('o', 4, False)]\n",
      "letras lugar errado:  []\n",
      "letras corretas:  []\n",
      "letras aceitas:  arraar\n",
      "--------- 4 coluna ---------\n",
      "letras erradas:  [('n', 0, False)]\n",
      "letras lugar errado:  []\n",
      "letras corretas:  [('i', 1), ('s', 2), ('s', 3), ('o', 4)]\n",
      "letras aceitas:  oosooiosisoisso\n"
     ]
    }
   ],
   "source": [
    "dicionario = {0: ('letter wrong', 'n'), 1: ('letter wrong', 'i'), 2: ('letter wrong', 's'), 3: ('letter wrong', 's'), 4: ('letter wrong', 'o')}\n",
    "#dicionario_2 = {0: ('letter right', 'p'), 1: ('letter right', 'o'), 2: ('letter right', 'u'), 3: ('letter right', 'c'), 4: ('letter right', 'a')}\n",
    "#dicionario_3 = {0: ('letter wrong', 'p'), 1: ('letter place', 'o'), 2: ('letter wrong', 'u'), 3: ('letter place', 'c'), 4: ('letter wrong', 'a')}\n",
    "dicionario_4 = {0: ('letter wrong', 'n'), 1: ('letter right', 'i'), 2: ('letter right', 's'), 3: ('letter right', 's'), 4: ('letter right', 'o')}\n",
    "\n",
    "df, letras_aceitas, letras_erradas, letras_lugar_errado, letras_corretas = filtra_df_2(dicionario, df, letras_aceitas)\n",
    "#df_2, letras_aceitas_2, letras_erradas_2, letras_lugar_errado_2, letras_corretas_2 = filtra_df_2(dicionario_2, df_2, letras_aceitas_2)\n",
    "#df_3, letras_aceitas_3, letras_erradas_3, letras_lugar_errado_3, letras_corretas_3 = filtra_df_2(dicionario_3, df_3, letras_aceitas_3)\n",
    "df_4, letras_aceitas_4, letras_erradas_4, letras_lugar_errado_4, letras_corretas_4 = filtra_df_2(dicionario_4, df_4, letras_aceitas_4)\n",
    "\n",
    "print('--------- 1 coluna ---------')\n",
    "print('letras erradas: ', letras_erradas)\n",
    "print('letras lugar errado: ', letras_lugar_errado)\n",
    "print('letras corretas: ', letras_corretas)\n",
    "print('letras aceitas: ',letras_aceitas)\n",
    "\n",
    "# print('--------- 2 coluna ---------')\n",
    "# print('letras erradas: ', letras_erradas_2)\n",
    "# print('letras lugar errado: ', letras_lugar_errado_2)\n",
    "# print('letras corretas: ', letras_corretas_2)\n",
    "# print('letras aceitas: ',letras_aceitas_2)\n",
    "\n",
    "# print('--------- 3 coluna ---------')\n",
    "# print('letras erradas: ', letras_erradas_3)\n",
    "# print('letras lugar errado: ', letras_lugar_errado_3)\n",
    "# print('letras corretas: ', letras_corretas_3)\n",
    "# print('letras aceitas: ',letras_aceitas_3)\n",
    "\n",
    "print('--------- 4 coluna ---------')\n",
    "print('letras erradas: ', letras_erradas_4)\n",
    "print('letras lugar errado: ', letras_lugar_errado_4)\n",
    "print('letras corretas: ', letras_corretas_4)\n",
    "print('letras aceitas: ',letras_aceitas_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "637381a4-afbd-48a8-ae04-695e9eae20e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primeiro  5\n",
      "quarto  1\n"
     ]
    }
   ],
   "source": [
    "print('primeiro ',len(df.palavra))\n",
    "print('quarto ',len(df_4.palavra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0212ad92-1548-4d7d-ab7a-aa92a1c7612e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disso\n"
     ]
    }
   ],
   "source": [
    "print(sorteia_palavra(df_4.palavra.values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d7971448-0680-4385-a7e1-34a66d764e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- 1 coluna ---------\n",
      "letras erradas:  [('d', 0, False), ('i', 1, False), ('s', 2, False), ('s', 3, False), ('o', 4, False)]\n",
      "letras lugar errado:  []\n",
      "letras corretas:  []\n",
      "letras aceitas:  arraar\n"
     ]
    }
   ],
   "source": [
    "dicionario = {0: ('letter wrong', 'd'), 1: ('letter wrong', 'i'), 2: ('letter wrong', 's'), 3: ('letter wrong', 's'), 4: ('letter wrong', 'o')}\n",
    "#dicionario_2 = {0: ('letter right', 'p'), 1: ('letter right', 'o'), 2: ('letter right', 'u'), 3: ('letter right', 'c'), 4: ('letter right', 'a')}\n",
    "#dicionario_3 = {0: ('letter wrong', 'p'), 1: ('letter place', 'o'), 2: ('letter wrong', 'u'), 3: ('letter place', 'c'), 4: ('letter wrong', 'a')}\n",
    "#dicionario_4 = {0: ('letter wrong', 'n'), 1: ('letter right', 'i'), 2: ('letter right', 's'), 3: ('letter right', 's'), 4: ('letter right', 'o')}\n",
    "\n",
    "df, letras_aceitas, letras_erradas, letras_lugar_errado, letras_corretas = filtra_df_2(dicionario, df, letras_aceitas)\n",
    "#df_2, letras_aceitas_2, letras_erradas_2, letras_lugar_errado_2, letras_corretas_2 = filtra_df_2(dicionario_2, df_2, letras_aceitas_2)\n",
    "#df_3, letras_aceitas_3, letras_erradas_3, letras_lugar_errado_3, letras_corretas_3 = filtra_df_2(dicionario_3, df_3, letras_aceitas_3)\n",
    "#df_4, letras_aceitas_4, letras_erradas_4, letras_lugar_errado_4, letras_corretas_4 = filtra_df_2(dicionario_4, df_4, letras_aceitas_4)\n",
    "\n",
    "print('--------- 1 coluna ---------')\n",
    "print('letras erradas: ', letras_erradas)\n",
    "print('letras lugar errado: ', letras_lugar_errado)\n",
    "print('letras corretas: ', letras_corretas)\n",
    "print('letras aceitas: ',letras_aceitas)\n",
    "\n",
    "# print('--------- 2 coluna ---------')\n",
    "# print('letras erradas: ', letras_erradas_2)\n",
    "# print('letras lugar errado: ', letras_lugar_errado_2)\n",
    "# print('letras corretas: ', letras_corretas_2)\n",
    "# print('letras aceitas: ',letras_aceitas_2)\n",
    "\n",
    "# print('--------- 3 coluna ---------')\n",
    "# print('letras erradas: ', letras_erradas_3)\n",
    "# print('letras lugar errado: ', letras_lugar_errado_3)\n",
    "# print('letras corretas: ', letras_corretas_3)\n",
    "# print('letras aceitas: ',letras_aceitas_3)\n",
    "\n",
    "# print('--------- 4 coluna ---------')\n",
    "# print('letras erradas: ', letras_erradas_4)\n",
    "# print('letras lugar errado: ', letras_lugar_errado_4)\n",
    "# print('letras corretas: ', letras_corretas_4)\n",
    "# print('letras aceitas: ',letras_aceitas_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1a41e772-36e9-4b80-bd71-d68ad033eb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primeiro  3\n",
      "brava\n"
     ]
    }
   ],
   "source": [
    "print('primeiro ',len(df.palavra))\n",
    "print(sorteia_palavra(df.palavra.values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7a43e0e4-f7a0-4e1b-9cbc-9fe4a06c731a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "846    braba\n",
       "852    brama\n",
       "857    brava\n",
       "Name: palavra, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.palavra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ab83d7-5cda-4f09-b22b-7308dd0fe59c",
   "metadata": {},
   "source": [
    "### Ideia seria ter a resolução de todas as partes do term.ooo pra assim tentar gerar um machine learning disso tudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b981c34-a8e3-4943-87ca-8474dc3ef833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e3c056-5edd-421c-bf3b-153eadd7baa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "78a19f4a-8e59-4128-a2c9-5323d3764a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "0\n",
      "True\n",
      "e\n",
      "3\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>n_vogais</th>\n",
       "      <th>vogais_unicas</th>\n",
       "      <th>letra_0</th>\n",
       "      <th>letra_1</th>\n",
       "      <th>letra_2</th>\n",
       "      <th>letra_3</th>\n",
       "      <th>letra_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bagda</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bangu</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>borba</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>bruno</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>r</td>\n",
       "      <td>u</td>\n",
       "      <td>n</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>carla</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>l</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5412</th>\n",
       "      <td>umida</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>m</td>\n",
       "      <td>i</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5413</th>\n",
       "      <td>umido</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>m</td>\n",
       "      <td>i</td>\n",
       "      <td>d</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5414</th>\n",
       "      <td>unica</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>n</td>\n",
       "      <td>i</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5415</th>\n",
       "      <td>unico</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>n</td>\n",
       "      <td>i</td>\n",
       "      <td>c</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5416</th>\n",
       "      <td>urico</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>r</td>\n",
       "      <td>i</td>\n",
       "      <td>c</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2683 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     palavra  n_vogais  vogais_unicas letra_0 letra_1 letra_2 letra_3 letra_4\n",
       "17     bagda         2              1       b       a       g       d       a\n",
       "18     bangu         2              2       b       a       n       g       u\n",
       "24     borba         2              2       b       o       r       b       a\n",
       "25     bruno         2              2       b       r       u       n       o\n",
       "26     carla         2              1       c       a       r       l       a\n",
       "...      ...       ...            ...     ...     ...     ...     ...     ...\n",
       "5412   umida         3              3       u       m       i       d       a\n",
       "5413   umido         3              3       u       m       i       d       o\n",
       "5414   unica         3              3       u       n       i       c       a\n",
       "5415   unico         3              3       u       n       i       c       o\n",
       "5416   urico         3              3       u       r       i       c       o\n",
       "\n",
       "[2683 rows x 8 columns]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letra_n = [('a',0,True),('e',3,False)]\n",
    "letras_aceitas = 'a'\n",
    "lista = []\n",
    "\n",
    "\n",
    "for letra, indice,status_letras_aceitas in letra_n:\n",
    "    print(letra)\n",
    "    print(indice)\n",
    "    print(status_letras_aceitas)\n",
    "    if status_letras_aceitas == False:\n",
    "        lista.append(letra)\n",
    "    else:\n",
    "        mask = df[f'letra_{indice}'] != letra\n",
    "        df = df.loc[mask,:]\n",
    "\n",
    "    if len(lista) > 0:\n",
    "        mask = ~df.letra_0.isin(lista) & ~df.letra_1.isin(lista) & ~df.letra_2.isin(lista) & ~df.letra_3.isin(lista) & ~df.letra_4.isin(lista)    \n",
    "        df = df.loc[mask,:]\n",
    "        \n",
    "df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "5f3a083b-de0c-4a7c-9df8-9683ee186d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>n_vogais</th>\n",
       "      <th>vogais_unicas</th>\n",
       "      <th>letra_0</th>\n",
       "      <th>letra_1</th>\n",
       "      <th>letra_2</th>\n",
       "      <th>letra_3</th>\n",
       "      <th>letra_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bagda</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bangu</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>carla</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>l</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>catia</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>t</td>\n",
       "      <td>i</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>darci</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>c</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5287</th>\n",
       "      <td>zanza</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>z</td>\n",
       "      <td>a</td>\n",
       "      <td>n</td>\n",
       "      <td>z</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5289</th>\n",
       "      <td>zanzo</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>z</td>\n",
       "      <td>a</td>\n",
       "      <td>n</td>\n",
       "      <td>z</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5290</th>\n",
       "      <td>zarpa</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>z</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>p</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5292</th>\n",
       "      <td>zarpo</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>z</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>p</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5387</th>\n",
       "      <td>iamos</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>i</td>\n",
       "      <td>a</td>\n",
       "      <td>m</td>\n",
       "      <td>o</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>758 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     palavra  n_vogais  vogais_unicas letra_0 letra_1 letra_2 letra_3 letra_4\n",
       "17     bagda         2              1       b       a       g       d       a\n",
       "18     bangu         2              2       b       a       n       g       u\n",
       "26     carla         2              1       c       a       r       l       a\n",
       "33     catia         3              2       c       a       t       i       a\n",
       "36     darci         2              2       d       a       r       c       i\n",
       "...      ...       ...            ...     ...     ...     ...     ...     ...\n",
       "5287   zanza         2              1       z       a       n       z       a\n",
       "5289   zanzo         2              2       z       a       n       z       o\n",
       "5290   zarpa         2              1       z       a       r       p       a\n",
       "5292   zarpo         2              2       z       a       r       p       o\n",
       "5387   iamos         3              3       i       a       m       o       s\n",
       "\n",
       "[758 rows x 8 columns]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.letra_1 == 'a']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28f3dd7-79b1-42b9-8f70-d26ee827e618",
   "metadata": {},
   "source": [
    "## Scraping functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8b6b9c30-e673-43c9-ae3f-46fd3088d7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9a8b0bd1-8c42-4333-94d3-25fb936d1397",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.edge.service import Service\n",
    "#com a mudança pro selenium 4.0, algumas coisas mudaram ao inicializar, por exemplo o uso do Service\n",
    "#checar se há a versão do Selenium instalada nas librarys python!\n",
    "#não consegui instalar via anaconda shell, tive que usar o prompt pra instalar  via (pip install selenium) a biblioteca dentro do C:/user/appdata/local/programs/python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7a868a92-e7e5-4a82-a4ef-ef602a4f9d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inicializand o site\n",
    "def inicializa_termo():\n",
    "    service = Service(executable_path = './edg_drv/msedgedriver.exe') #mudança do selenium 4.0\n",
    "    driver = webdriver.Edge(service=service)\n",
    "\n",
    "    urlpage = 'https://term.ooo/'\n",
    "    response = driver.get(urlpage)\n",
    "    driver.implicitly_wait(5)\n",
    "\n",
    "    x_path = '/html/body/wc-modal'\n",
    "    ajuda_sempre_aberta = driver.find_element('xpath',x_path)\n",
    "    ajuda_sempre_aberta.click()\n",
    "    driver.implicitly_wait(5)\n",
    "    return driver\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3306c326-cb70-4b8e-a032-99ad9fc5d14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#envia palavra\n",
    "from time import sleep\n",
    "\n",
    "def envia_palavra(palavra_sorteada, driver):\n",
    "    x_path_board = '/html/body'\n",
    "    board_inicial = driver.find_element('xpath',x_path_board)\n",
    "    for letra in palavra_sorteada:\n",
    "        board_inicial.send_keys(letra)\n",
    "        #board_inicial.implicitly_wait(3)#testar, se não funcionar voltar para -> driver.implicitly_wait(0.5)\n",
    "        sleep(1)\n",
    "\n",
    "    \n",
    "    board_inicial.send_keys(Keys.ENTER)\n",
    "    #board_inicial.implicitly_wait(5)\n",
    "    sleep(3)\n",
    "    #print('palavra-enviada')#apenas pra finalidades de teste, retirar depois\n",
    "    \n",
    "def apaga_palavra():\n",
    "    x_path_board = '/html/body'\n",
    "    board_inicial = driver.find_element('xpath',x_path_board)\n",
    "\n",
    "    for i in range(5):\n",
    "        board_inicial.send_keys(Keys.BACKSPACE)\n",
    "        sleep(0.5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "520ba9e9-aca9-418a-bacf-354db921ad7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retorna dicionario da tentiva de palavra enviada\n",
    "# elemento_do_board = '[id=\"board0\"]'\n",
    "\n",
    "# shadow = driver.find_element(By.CSS_SELECTOR, elemento_do_board).shadow_root\n",
    "\n",
    "#ainda pensando se vale a pena colocar como variavel global mesmo ou deixar dentro da função\n",
    "\n",
    "def retorna_dicionario_respostas(variavel): #variavel = numero da tentativa\n",
    "\n",
    "    elemento_do_board = '[id=\"board0\"]'\n",
    "\n",
    "    shadow = driver.find_element(By.CSS_SELECTOR, elemento_do_board).shadow_root\n",
    "    letra = ''\n",
    "    resposta = ''\n",
    "    \n",
    "    \n",
    "    lista_da_palavra = [] #inicializa a lista\n",
    "    elemento_primeira_linha_interno_para_shadow = f'[aria-label=\"palavra {variavel}\"]'\n",
    "    inner_shadow = shadow.find_element(By.CSS_SELECTOR, elemento_primeira_linha_interno_para_shadow).shadow_root\n",
    "\n",
    "\n",
    "    for variavel in range(5):\n",
    "        elemento_primeira_letra = f'[termo-pos=\"{str(variavel)}\"]'\n",
    "        elemento_html = inner_shadow.find_element(By.CSS_SELECTOR, elemento_primeira_letra)\n",
    "        resposta = elemento_html.get_attribute('class')\n",
    "        letra = remove_acentos(elemento_html.text.lower())\n",
    "        if resposta != 'letter empty':\n",
    "            lista_da_palavra.append((resposta, letra))\n",
    "\n",
    "\n",
    "    return dict(zip(range(len(lista_da_palavra)), lista_da_palavra))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d02142-7ef9-4837-8a8a-9e408b3868db",
   "metadata": {},
   "source": [
    "aqui foi necessário fazer varios for, pra primeiro:\n",
    "- adicionar as letras aceitas e corretas nos lugares\n",
    "- adicionar as letras em lugares errados\n",
    "- adicionar letras erradas\n",
    "\n",
    "no termo.ooo tem 4 tipos de variaveis, 3 que eles retornam com o envio de letras: \n",
    "\n",
    "    1. letter empty (antes de enviar)\n",
    "    2. letter right \n",
    "    3. letter wrong\n",
    "    4. letter place\n",
    "\n",
    "> isso se deu ao motivo de muitas vezes terem letras repetidas e o site reconhecer uma letra aceita como não aceita!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f98fad-b492-4c30-aa71-6445095ec751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ebbfb4c0-d076-4e07-b86f-526d3b606187",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#função que vai dizer se ta funcionando ou não\n",
    "def get_notificacao(palavra_sorteada, df, file, now, session_id, dicionario,tentativa, letras_aceitas):\n",
    "#def get_notificacao(palavra_sorteada, df):\n",
    "    vencedor = 'wc-notify'\n",
    "    notificacao = driver.find_element(By.CSS_SELECTOR, vencedor)\n",
    "    notificacao = notificacao.text\n",
    "    #print(notificacao)\n",
    "    terminou = True\n",
    "    if notificacao == '':\n",
    "        notificacao = 'palavra aceita' #para input do resultados.txt\n",
    "        terminou = True\n",
    "        \n",
    "        \n",
    "    elif notificacao == 'essa palavra não é aceita':\n",
    "        terminou = False\n",
    "        #file.write(f'{-1},{palavra_sorteada},{notificacao},{data},{session_id},{variavel_randomica},{dicionario}\\n')\n",
    "        #nesse ponto precisei meio que criar ela recursivamente, pra ir filtrando as palavras que não poderiamos colocar!\n",
    "        while terminou == False:\n",
    "            \n",
    "            \n",
    "            #apagando palavra\n",
    "            apaga_palavra()\n",
    "            \n",
    "            \n",
    "            file.write(f'{-1},{palavra_sorteada},{notificacao},{data},{session_id},{variavel_randomica},{dicionario}\\n')\n",
    "            #aqui vai ter uma mini função, que talvez eu encapsule em outro lugar\n",
    "            df = df[df.palavra != palavra_sorteada].reset_index(drop=True)\n",
    "            palavra_sorteada = sorteia_palavra(df.palavra.values.tolist())\n",
    "            \n",
    "            #palavra_sorteada = sorteia_palavra(df.palavra)\n",
    "\n",
    "            envia_palavra(palavra_sorteada)\n",
    "\n",
    "            #pegar informações da palavra enviada\n",
    "            dicionario = retorna_dicionario_respostas(tentativa)\n",
    "            df, letras_aceitas = filtra_df(dicionario, df, letras_aceitas)\n",
    "#             print('-------- dentro do get_noficacao ------')\n",
    "#             print('palavra_sorteada: ',palavra_sorteada)\n",
    "#             print()\n",
    "#             print('dicionario: ', dicionario)\n",
    "#             print()\n",
    "#             print('letras_aceitas: ',letras_aceitas)\n",
    "#             print('tentativa: ', tentativa)\n",
    "#             print('-------- fim do get_noficacao ------')\n",
    "#             df.to_csv('debugando.csv')\n",
    "            #df, letras_aceitas = filtra_df(dicionario, df, letras_aceitas)\n",
    "            #df.to_csv('debugando.csv')\n",
    "            \n",
    "            #terminou, df, notificacao, palavra_sorteada = get_notificacao(palavra_sorteada, df, file, now, session_id,dicionario,tentativa, letras_aceitas)\n",
    "            terminou, df, notificacao, palavra_sorteada, letras_aceitas, tentativa = get_notificacao(palavra_sorteada, df, file, now, session_id, dicionario,tentativa, letras_aceitas)\n",
    "            #tentativa += 1 # foi o jeito de corrigir o erro, não sei como só isso resolveu, verificar deep dps\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "    else:\n",
    "        terminou = False\n",
    "        \n",
    "    return terminou, df, notificacao, palavra_sorteada, letras_aceitas, tentativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e8804b7a-2f01-4c43-99c8-78073cd19da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_attempt():\n",
    "    #melhores_palavras_para_vogais = df[df.palavra == 'aureo']\n",
    "    #return sorteia_palavra(melhores_palavras_para_vogais.palavra.values.tolist())\n",
    "    return 'aureo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e9c5eef2-57e4-46e7-9f3c-54361ef50648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_attempt():\n",
    "    return 'clips'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4cf40bec-9395-4ab3-b797-76e9412a007b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtra_df(dicionario, df, letras_aceitas):\n",
    "#         envia_palavra(palavra_sorteada)\n",
    "\n",
    "#         #pegar informações da palavra enviada\n",
    "#         dicionario = retorna_dicionario_respostas(tentativa)\n",
    "\n",
    "        #retornar resultado das letras\n",
    "        letras_erradas, letras_lugar_errado, letras_corretas, letras_aceitas = descompacta_dicionario(dicionario, letras_aceitas)\n",
    "\n",
    "        df = palavras_com_letra_posicao_errada(letras_lugar_errado, df)\n",
    "        df = letra_na_posicao(letras_corretas, df)\n",
    "        df = letras_nao_aceitas(letras_erradas, df, letras_aceitas)\n",
    "        \n",
    "        return df, letras_aceitas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ca99dd4f-510d-4588-8ec3-b3d323a674bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# função para execução de tudo\n",
    "\n",
    "def roda_tudo(driver, df, letras_aceitas):\n",
    "    file = open('resultados.txt', 'a')\n",
    "    terminou = True\n",
    "    tentativa = 0\n",
    "\n",
    "    now = datetime.now()\n",
    "    data = now.strftime(\"%d/%m/%Y\")\n",
    "    session_id = driver.session_id\n",
    "\n",
    "    # só verificando o seed que foi gerado pra caso precisar replicar\n",
    "    variavel_randomica = random.randint(0, 1000)\n",
    "    a = random.seed(variavel_randomica)\n",
    "    print(variavel_randomica)\n",
    "\n",
    "    # print('first')\n",
    "    # pegando a primeira palavra\n",
    "    palavra_sorteada = first_attempt()\n",
    "\n",
    "    envia_palavra(palavra_sorteada, driver)\n",
    "\n",
    "    # pegar informações da palavra enviada\n",
    "    dicionario = retorna_dicionario_respostas(tentativa, driver)\n",
    "\n",
    "    # print(palavra_sorteada)\n",
    "    # df, letras_aceitas = filtra_df(dicionario, df, letras_aceitas)\n",
    "\n",
    "    df, letras_aceitas, letras_erradas, letras_lugar_errado, letras_corretas = filtra_df_2(dicionario, df,\n",
    "                                                                                           letras_aceitas)\n",
    "\n",
    "    # driver.implicitly_wait(10)\n",
    "    sleep(1)\n",
    "    print('------------------------------------')\n",
    "    print('palavra sorteada: ', palavra_sorteada)\n",
    "    print(dicionario)\n",
    "    print('tentativa: ', tentativa)\n",
    "    print('letras erradas: ', letras_erradas)\n",
    "    print('letras lugar errado: ', letras_lugar_errado)\n",
    "    print('letras corretas: ', letras_corretas)\n",
    "    print('letras aceitas: ', letras_aceitas)\n",
    "    #df.to_csv('debugando.csv')\n",
    "\n",
    "    terminou, df, notificacao, palavra_sorteada, letras_aceitas, tentativa = get_notificacao(palavra_sorteada, df,\n",
    "                                                                                             file, now, session_id,\n",
    "                                                                                             dicionario, tentativa,\n",
    "                                                                                             letras_aceitas, driver)\n",
    "    tentativa += 1\n",
    "\n",
    "\n",
    "    #teste de segunda tentativa\n",
    "\n",
    "    palavra_sorteada = second_attempt()\n",
    "\n",
    "    envia_palavra(palavra_sorteada, driver)\n",
    "\n",
    "    # pegar informações da palavra enviada\n",
    "    dicionario = retorna_dicionario_respostas(tentativa, driver)\n",
    "\n",
    "\n",
    "    df, letras_aceitas, letras_erradas, letras_lugar_errado, letras_corretas = filtra_df_2(dicionario, df,\n",
    "                                                                                           letras_aceitas)\n",
    "\n",
    "    # driver.implicitly_wait(10)\n",
    "    sleep(1)\n",
    "    print('------------------------------------')\n",
    "    print('palavra sorteada: ', palavra_sorteada)\n",
    "    print(dicionario)\n",
    "    print('tentativa: ', tentativa)\n",
    "    print('letras erradas: ', letras_erradas)\n",
    "    print('letras lugar errado: ', letras_lugar_errado)\n",
    "    print('letras corretas: ', letras_corretas)\n",
    "    print('letras aceitas: ', letras_aceitas)\n",
    "\n",
    "    tentativa += 1\n",
    "\n",
    "    while terminou == True:\n",
    "        # driver.implicitly_wait(5)\n",
    "        # for tentativa in range(5):\n",
    "        # print(tentativa)\n",
    "\n",
    "\n",
    "\n",
    "        palavra_sorteada = sorteia_palavra(df)\n",
    "        #palavra_sorteada = sorteia_palavra(df.palavra.values.tolist())\n",
    "        # print(palavra_sorteada)\n",
    "\n",
    "        envia_palavra(palavra_sorteada, driver)\n",
    "\n",
    "        # pegar informações da palavra enviada\n",
    "        dicionario = retorna_dicionario_respostas(tentativa, driver)\n",
    "\n",
    "        # print(palavra_sorteada)\n",
    "        # df.to_csv('debugando.csv')\n",
    "        df, letras_aceitas, letras_erradas, letras_lugar_errado, letras_corretas = filtra_df_2(dicionario, df,\n",
    "                                                                                               letras_aceitas)\n",
    "        # driver.implicitly_wait(30)\n",
    "        sleep(1)\n",
    "\n",
    "        # terminou, df, notificacao, palavra_sorteada, letras_aceitas, tentativa = get_notificacao(palavra_sorteada, df, file, now, session_id, dicionario,tentativa, letras_aceitas)\n",
    "        print('------------------------------------')\n",
    "        print('palavra sorteada: ', palavra_sorteada)\n",
    "        print(dicionario)\n",
    "\n",
    "        print('tentativa: ', tentativa)\n",
    "        print('letras erradas: ', letras_erradas)\n",
    "        print('letras lugar errado: ', letras_lugar_errado)\n",
    "        print('letras corretas: ', letras_corretas)\n",
    "\n",
    "        print('letras aceitas: ', letras_aceitas)\n",
    "        terminou, df, notificacao, palavra_sorteada, letras_aceitas, tentativa = get_notificacao(palavra_sorteada, df,\n",
    "                                                                                                 file, now, session_id,\n",
    "                                                                                                 dicionario, tentativa,\n",
    "                                                                                                 letras_aceitas, driver)\n",
    "\n",
    "        # file.write('tentativa,palavra,resultado,data,session_id\\n')\n",
    "        file.write(\n",
    "            f'{tentativa},{palavra_sorteada},{notificacao},{data},{session_id},{variavel_randomica},{dicionario}\\n')\n",
    "        tentativa += 1\n",
    "\n",
    "        if tentativa > 6:\n",
    "            terminou = False\n",
    "\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "263414cb-2957-40c7-ab9c-eb3c405dba23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "envia_palavra() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-131-160f098daf05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcarrega_dataframe_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcaminho\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdriver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minicializa_termo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mroda_tudo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mletras_aceitas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-128-55dfbc9e902f>\u001b[0m in \u001b[0;36mroda_tudo\u001b[1;34m(driver, df, letras_aceitas)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mpalavra_sorteada\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfirst_attempt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0menvia_palavra\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpalavra_sorteada\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m# pegar informações da palavra enviada\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: envia_palavra() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "#chama as funções\n",
    "letras_aceitas = ''\n",
    "\n",
    "caminho = 'br-utf8_prob.csv'\n",
    "\n",
    "df = carrega_dataframe_csv(caminho)\n",
    "driver = inicializa_termo()\n",
    "roda_tudo(driver, df, letras_aceitas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce83434-60ff-4ebb-8a8e-74cc2e14a5e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d478d6a-d379-4853-858c-d1bca9bc5c51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c81b624-1101-46c0-a0f0-c2217a82c52c",
   "metadata": {},
   "source": [
    "# BLOCO FINAL\n",
    "## Teste de funções e interação com o site"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a56a4c-f5be-4f8a-9f54-1f95bc55c581",
   "metadata": {},
   "source": [
    "259 variavel_randomica que estava dando erro ontem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "73cddb24-3330-4ba1-86a9-7ed8fa0648d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n",
      "------------------------------------\n",
      "palavra sorteada:  aureo\n",
      "{0: ('letter place', 'a'), 1: ('letter wrong', 'u'), 2: ('letter place', 'r'), 3: ('letter wrong', 'e'), 4: ('letter place', 'o')}\n",
      "tentativa:  0\n",
      "letras erradas:  [('u', 1), ('e', 3)]\n",
      "letras lugar errado:  [('a', 0), ('r', 2), ('o', 4)]\n",
      "letras corretas:  []\n",
      "letras aceitas:  aro\n",
      "------------------------------------\n",
      "palavra sorteada:  rosca\n",
      "{0: ('letter place', 'r'), 1: ('letter place', 'o'), 2: ('letter wrong', 's'), 3: ('letter wrong', 'c'), 4: ('letter place', 'a')}\n",
      "tentativa:  1\n",
      "letras erradas:  [('s', 2), ('c', 3)]\n",
      "letras lugar errado:  [('r', 0), ('o', 1), ('a', 4)]\n",
      "letras corretas:  []\n",
      "letras aceitas:  aroroa\n",
      "------------------------------------\n",
      "palavra sorteada:  topar\n",
      "{0: ('letter wrong', 't'), 1: ('letter place', 'o'), 2: ('letter place', 'p'), 3: ('letter place', 'a'), 4: ('letter right', 'r')}\n",
      "tentativa:  2\n",
      "letras erradas:  [('t', 0)]\n",
      "letras lugar errado:  [('o', 1), ('p', 2), ('a', 3)]\n",
      "letras corretas:  [('r', 4)]\n",
      "letras aceitas:  aroroaropa\n",
      "------------------------------------\n",
      "palavra sorteada:  optar\n",
      "{0: ('letter place', 'o'), 1: ('letter place', 'p'), 2: ('letter wrong', 't'), 3: ('letter place', 'a'), 4: ('letter right', 'r')}\n",
      "tentativa:  3\n",
      "letras erradas:  [('t', 2)]\n",
      "letras lugar errado:  [('o', 0), ('p', 1), ('a', 3)]\n",
      "letras corretas:  [('r', 4)]\n",
      "letras aceitas:  aroroaroparopa\n",
      "------------------------------------\n",
      "palavra sorteada:  pavor\n",
      "{0: ('letter right done', 'p'), 1: ('letter right done', 'a'), 2: ('letter right done', 'v'), 3: ('letter right done', 'o'), 4: ('letter right done', 'r')}\n",
      "tentativa:  4\n",
      "letras erradas:  []\n",
      "letras lugar errado:  []\n",
      "letras corretas:  []\n",
      "letras aceitas:  aroroaroparopa\n"
     ]
    }
   ],
   "source": [
    "letras_aceitas = ''\n",
    "\n",
    "file = open('resultados.txt', 'a')\n",
    "\n",
    "caminho = 'br-utf8.csv'\n",
    "\n",
    "df = carrega_dataframe_csv(caminho)\n",
    "\n",
    "driver = inicializa_termo()\n",
    "\n",
    "\n",
    "terminou = True\n",
    "tentativa = 0\n",
    "\n",
    "now = datetime.now()\n",
    "data = now.strftime(\"%d/%m/%Y\")\n",
    "session_id = driver.session_id\n",
    "\n",
    "#só verificando o seed que foi gerado pra caso precisar replicar\n",
    "variavel_randomica = random.randint(0,1000)\n",
    "variavel_randomica = 92\n",
    "a = random.seed(variavel_randomica)\n",
    "print(variavel_randomica)\n",
    "\n",
    "#print('first')\n",
    "#pegando a primeira palavra\n",
    "palavra_sorteada = first_attempt(df)\n",
    "\n",
    "envia_palavra(palavra_sorteada)\n",
    "\n",
    "#pegar informações da palavra enviada\n",
    "dicionario = retorna_dicionario_respostas(tentativa)\n",
    "\n",
    "#print(palavra_sorteada)\n",
    "#df, letras_aceitas = filtra_df(dicionario, df, letras_aceitas)\n",
    "\n",
    "df, letras_aceitas, letras_erradas, letras_lugar_errado, letras_corretas = filtra_df_2(dicionario, df, letras_aceitas)\n",
    "\n",
    "#driver.implicitly_wait(10)\n",
    "sleep(1)\n",
    "print('------------------------------------')\n",
    "print('palavra sorteada: ',palavra_sorteada) \n",
    "print(dicionario)\n",
    "print('tentativa: ',tentativa)\n",
    "print('letras erradas: ', letras_erradas)\n",
    "print('letras lugar errado: ', letras_lugar_errado)\n",
    "print('letras corretas: ', letras_corretas)\n",
    "print('letras aceitas: ',letras_aceitas)\n",
    "\n",
    "tentativa += 1\n",
    "\n",
    "while terminou == True:\n",
    "    #driver.implicitly_wait(5)\n",
    "    #for tentativa in range(5):\n",
    "    #print(tentativa)\n",
    "\n",
    "    palavra_sorteada = sorteia_palavra(df.palavra.values.tolist())\n",
    "    #print(palavra_sorteada)\n",
    "\n",
    "    envia_palavra(palavra_sorteada)\n",
    "\n",
    "    #pegar informações da palavra enviada\n",
    "    dicionario = retorna_dicionario_respostas(tentativa)\n",
    "\n",
    "    #print(palavra_sorteada)\n",
    "    #df.to_csv('debugando.csv')\n",
    "    df, letras_aceitas, letras_erradas, letras_lugar_errado, letras_corretas = filtra_df_2(dicionario, df, letras_aceitas)\n",
    "    #driver.implicitly_wait(30)\n",
    "    sleep(1)\n",
    "\n",
    "        #terminou, df, notificacao, palavra_sorteada, letras_aceitas, tentativa = get_notificacao(palavra_sorteada, df, file, now, session_id, dicionario,tentativa, letras_aceitas)\n",
    "    print('------------------------------------')\n",
    "    print('palavra sorteada: ',palavra_sorteada) \n",
    "    print(dicionario)\n",
    "    \n",
    "    print('tentativa: ',tentativa)\n",
    "    print('letras erradas: ', letras_erradas)\n",
    "    print('letras lugar errado: ', letras_lugar_errado)\n",
    "    print('letras corretas: ', letras_corretas)\n",
    "    \n",
    "    print('letras aceitas: ',letras_aceitas)\n",
    "    terminou, df, notificacao, palavra_sorteada, letras_aceitas, tentativa = get_notificacao(palavra_sorteada, df, file, now, session_id, dicionario,tentativa, letras_aceitas)\n",
    "    \n",
    "    #file.write('tentativa,palavra,resultado,data,session_id\\n')\n",
    "    file.write(f'{tentativa},{palavra_sorteada},{notificacao},{data},{session_id},{variavel_randomica},{dicionario}\\n')\n",
    "    tentativa += 1\n",
    "    \n",
    "    if tentativa > 6:\n",
    "        terminou = False\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff852a0-7c29-4ee8-b6d0-0091a4599ce6",
   "metadata": {},
   "source": [
    "-----------------\n",
    "teste 2\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "e322f5db-4d7e-4111-9f5c-743fb5018310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "820\n",
      "------------------------------------\n",
      "palavra sorteada:  aureo\n",
      "{0: ('letter place', 'a'), 1: ('letter wrong', 'u'), 2: ('letter place', 'r'), 3: ('letter wrong', 'e'), 4: ('letter place', 'o')}\n",
      "tentativa:  0\n",
      "letras erradas:  [('u', 1), ('e', 3)]\n",
      "letras lugar errado:  [('a', 0), ('r', 2), ('o', 4)]\n",
      "letras corretas:  []\n",
      "letras aceitas:  aro\n",
      "------------------------------------\n",
      "palavra sorteada:  fuzis\n",
      "{0: ('letter wrong', 'f'), 1: ('letter wrong', 'u'), 2: ('letter wrong', 'z'), 3: ('letter wrong', 'i'), 4: ('letter wrong', 's')}\n",
      "tentativa:  1\n",
      "letras erradas:  [('f', 0), ('u', 1), ('z', 2), ('i', 3), ('s', 4)]\n",
      "letras lugar errado:  []\n",
      "letras corretas:  []\n",
      "letras aceitas:  aro\n",
      "------------------------------------\n",
      "palavra sorteada:  rocas\n",
      "{0: ('letter place', 'r'), 1: ('letter place', 'o'), 2: ('letter wrong', 'c'), 3: ('letter place', 'a'), 4: ('letter wrong', 's')}\n",
      "tentativa:  2\n",
      "letras erradas:  [('c', 2), ('s', 4)]\n",
      "letras lugar errado:  [('r', 0), ('o', 1), ('a', 3)]\n",
      "letras corretas:  []\n",
      "letras aceitas:  aroroa\n",
      "------------------------------------\n",
      "palavra sorteada:  tosar\n",
      "{0: ('letter wrong', 't'), 1: ('letter place', 'o'), 2: ('letter wrong', 's'), 3: ('letter place', 'a'), 4: ('letter right', 'r')}\n",
      "tentativa:  3\n",
      "letras erradas:  [('t', 0), ('s', 2)]\n",
      "letras lugar errado:  [('o', 1), ('a', 3)]\n",
      "letras corretas:  [('r', 4)]\n",
      "letras aceitas:  aroroaroa\n",
      "------------------------------------\n",
      "palavra sorteada:  sabor\n",
      "{0: ('letter wrong', 's'), 1: ('letter right', 'a'), 2: ('letter wrong', 'b'), 3: ('letter right', 'o'), 4: ('letter right', 'r')}\n",
      "tentativa:  4\n",
      "letras erradas:  [('s', 0), ('b', 2)]\n",
      "letras lugar errado:  []\n",
      "letras corretas:  [('a', 1), ('o', 3), ('r', 4)]\n",
      "letras aceitas:  aroroaroaaor\n",
      "------------------------------------\n",
      "palavra sorteada:  fator\n",
      "{0: ('letter wrong', 'f'), 1: ('letter right', 'a'), 2: ('letter wrong', 't'), 3: ('letter right', 'o'), 4: ('letter right', 'r')}\n",
      "tentativa:  5\n",
      "letras erradas:  [('f', 0), ('t', 2)]\n",
      "letras lugar errado:  []\n",
      "letras corretas:  [('a', 1), ('o', 3), ('r', 4)]\n",
      "letras aceitas:  aroroaroaaoraor\n"
     ]
    }
   ],
   "source": [
    "letras_aceitas = ''\n",
    "\n",
    "file = open('resultados.txt', 'a')\n",
    "\n",
    "caminho = 'br-utf8.csv'\n",
    "\n",
    "df = carrega_dataframe_csv(caminho)\n",
    "\n",
    "driver = inicializa_termo()\n",
    "\n",
    "\n",
    "terminou = True\n",
    "tentativa = 0\n",
    "\n",
    "now = datetime.now()\n",
    "data = now.strftime(\"%d/%m/%Y\")\n",
    "session_id = driver.session_id\n",
    "\n",
    "#só verificando o seed que foi gerado pra caso precisar replicar\n",
    "variavel_randomica = random.randint(0,1000)\n",
    "variavel_randomica = 820\n",
    "a = random.seed(variavel_randomica)\n",
    "print(variavel_randomica)\n",
    "\n",
    "#print('first')\n",
    "#pegando a primeira palavra\n",
    "palavra_sorteada = first_attempt(df)\n",
    "\n",
    "envia_palavra(palavra_sorteada)\n",
    "\n",
    "#pegar informações da palavra enviada\n",
    "dicionario = retorna_dicionario_respostas(tentativa)\n",
    "\n",
    "#print(palavra_sorteada)\n",
    "#df, letras_aceitas = filtra_df(dicionario, df, letras_aceitas)\n",
    "\n",
    "df, letras_aceitas, letras_erradas, letras_lugar_errado, letras_corretas = filtra_df_2(dicionario, df, letras_aceitas)\n",
    "\n",
    "#driver.implicitly_wait(10)\n",
    "sleep(1)\n",
    "print('------------------------------------')\n",
    "print('palavra sorteada: ',palavra_sorteada) \n",
    "print(dicionario)\n",
    "print('tentativa: ',tentativa)\n",
    "print('letras erradas: ', letras_erradas)\n",
    "print('letras lugar errado: ', letras_lugar_errado)\n",
    "print('letras corretas: ', letras_corretas)\n",
    "print('letras aceitas: ',letras_aceitas)\n",
    "df.to_csv('debugando.csv')\n",
    "\n",
    "tentativa += 1\n",
    "\n",
    "while terminou == True:\n",
    "    #driver.implicitly_wait(5)\n",
    "    #for tentativa in range(5):\n",
    "    #print(tentativa)\n",
    "\n",
    "    palavra_sorteada = sorteia_palavra(df.palavra.values.tolist())\n",
    "    #print(palavra_sorteada)\n",
    "\n",
    "    envia_palavra(palavra_sorteada)\n",
    "\n",
    "    #pegar informações da palavra enviada\n",
    "    dicionario = retorna_dicionario_respostas(tentativa)\n",
    "\n",
    "    #print(palavra_sorteada)\n",
    "    #df.to_csv('debugando.csv')\n",
    "    df, letras_aceitas, letras_erradas, letras_lugar_errado, letras_corretas = filtra_df_2(dicionario, df, letras_aceitas)\n",
    "    #driver.implicitly_wait(30)\n",
    "    sleep(1)\n",
    "\n",
    "        #terminou, df, notificacao, palavra_sorteada, letras_aceitas, tentativa = get_notificacao(palavra_sorteada, df, file, now, session_id, dicionario,tentativa, letras_aceitas)\n",
    "    print('------------------------------------')\n",
    "    print('palavra sorteada: ',palavra_sorteada) \n",
    "    print(dicionario)\n",
    "    \n",
    "    print('tentativa: ',tentativa)\n",
    "    print('letras erradas: ', letras_erradas)\n",
    "    print('letras lugar errado: ', letras_lugar_errado)\n",
    "    print('letras corretas: ', letras_corretas)\n",
    "    \n",
    "    print('letras aceitas: ',letras_aceitas)\n",
    "    terminou, df, notificacao, palavra_sorteada, letras_aceitas, tentativa = get_notificacao(palavra_sorteada, df, file, now, session_id, dicionario,tentativa, letras_aceitas)\n",
    "    \n",
    "    #file.write('tentativa,palavra,resultado,data,session_id\\n')\n",
    "    file.write(f'{tentativa},{palavra_sorteada},{notificacao},{data},{session_id},{variavel_randomica},{dicionario}\\n')\n",
    "    tentativa += 1\n",
    "    \n",
    "    if tentativa > 6:\n",
    "        terminou = False\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ddff5581-8561-4cd4-9fac-f21bc967547e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251\n",
      "------------------------------------\n",
      "palavra sorteada:  aureo\n",
      "{0: ('letter place', 'a'), 1: ('letter wrong', 'u'), 2: ('letter place', 'r'), 3: ('letter wrong', 'e'), 4: ('letter place', 'o')}\n",
      "tentativa:  0\n",
      "letras erradas:  [('u', 1, False), ('e', 3, False)]\n",
      "letras lugar errado:  [('a', 0), ('r', 2), ('o', 4)]\n",
      "letras corretas:  []\n",
      "letras aceitas:  aro\n",
      "------------------------------------\n",
      "palavra sorteada:  sogra\n",
      "{0: ('letter wrong', 's'), 1: ('letter place', 'o'), 2: ('letter wrong', 'g'), 3: ('letter place', 'r'), 4: ('letter place', 'a')}\n",
      "tentativa:  1\n",
      "letras erradas:  [('s', 0, False), ('g', 2, False)]\n",
      "letras lugar errado:  [('o', 1), ('r', 3), ('a', 4)]\n",
      "letras corretas:  []\n",
      "letras aceitas:  aroora\n",
      "------------------------------------\n",
      "palavra sorteada:  ornai\n",
      "{0: ('letter place', 'o'), 1: ('letter place', 'r'), 2: ('letter wrong', 'n'), 3: ('letter place', 'a'), 4: ('letter wrong', 'i')}\n",
      "tentativa:  2\n",
      "letras erradas:  [('n', 2, False), ('i', 4, False)]\n",
      "letras lugar errado:  [('o', 0), ('r', 1), ('a', 3)]\n",
      "letras corretas:  []\n",
      "letras aceitas:  arooraora\n",
      "------------------------------------\n",
      "palavra sorteada:  vapor\n",
      "{0: ('letter place', 'v'), 1: ('letter right', 'a'), 2: ('letter place', 'p'), 3: ('letter right', 'o'), 4: ('letter right', 'r')}\n",
      "tentativa:  3\n",
      "letras erradas:  []\n",
      "letras lugar errado:  [('v', 0), ('p', 2)]\n",
      "letras corretas:  [('a', 1), ('o', 3), ('r', 4)]\n",
      "letras aceitas:  arooraoraaorvp\n",
      "------------------------------------\n",
      "palavra sorteada:  pavor\n",
      "{0: ('letter right done', 'p'), 1: ('letter right done', 'a'), 2: ('letter right done', 'v'), 3: ('letter right done', 'o'), 4: ('letter right done', 'r')}\n",
      "tentativa:  4\n",
      "letras erradas:  []\n",
      "letras lugar errado:  []\n",
      "letras corretas:  []\n",
      "letras aceitas:  arooraoraaorvp\n"
     ]
    }
   ],
   "source": [
    "letras_aceitas = ''\n",
    "\n",
    "file = open('resultados.txt', 'a')\n",
    "\n",
    "caminho = 'br-utf8.csv'\n",
    "\n",
    "df = carrega_dataframe_csv(caminho)\n",
    "\n",
    "driver = inicializa_termo()\n",
    "\n",
    "\n",
    "terminou = True\n",
    "tentativa = 0\n",
    "\n",
    "now = datetime.now()\n",
    "data = now.strftime(\"%d/%m/%Y\")\n",
    "session_id = driver.session_id\n",
    "\n",
    "#só verificando o seed que foi gerado pra caso precisar replicar\n",
    "variavel_randomica = random.randint(0,1000)\n",
    "\n",
    "a = random.seed(variavel_randomica)\n",
    "print(variavel_randomica)\n",
    "\n",
    "#print('first')\n",
    "#pegando a primeira palavra\n",
    "palavra_sorteada = first_attempt(df)\n",
    "\n",
    "envia_palavra(palavra_sorteada)\n",
    "\n",
    "#pegar informações da palavra enviada\n",
    "dicionario = retorna_dicionario_respostas(tentativa)\n",
    "\n",
    "#print(palavra_sorteada)\n",
    "#df, letras_aceitas = filtra_df(dicionario, df, letras_aceitas)\n",
    "\n",
    "df, letras_aceitas, letras_erradas, letras_lugar_errado, letras_corretas = filtra_df_2(dicionario, df, letras_aceitas)\n",
    "\n",
    "#driver.implicitly_wait(10)\n",
    "sleep(1)\n",
    "print('------------------------------------')\n",
    "print('palavra sorteada: ',palavra_sorteada) \n",
    "print(dicionario)\n",
    "print('tentativa: ',tentativa)\n",
    "print('letras erradas: ', letras_erradas)\n",
    "print('letras lugar errado: ', letras_lugar_errado)\n",
    "print('letras corretas: ', letras_corretas)\n",
    "print('letras aceitas: ',letras_aceitas)\n",
    "df.to_csv('debugando.csv')\n",
    "\n",
    "tentativa += 1\n",
    "\n",
    "while terminou == True:\n",
    "    #driver.implicitly_wait(5)\n",
    "    #for tentativa in range(5):\n",
    "    #print(tentativa)\n",
    "\n",
    "    palavra_sorteada = sorteia_palavra(df.palavra.values.tolist())\n",
    "    #print(palavra_sorteada)\n",
    "\n",
    "    envia_palavra(palavra_sorteada)\n",
    "\n",
    "    #pegar informações da palavra enviada\n",
    "    dicionario = retorna_dicionario_respostas(tentativa)\n",
    "\n",
    "    #print(palavra_sorteada)\n",
    "    #df.to_csv('debugando.csv')\n",
    "    df, letras_aceitas, letras_erradas, letras_lugar_errado, letras_corretas = filtra_df_2(dicionario, df, letras_aceitas)\n",
    "    #driver.implicitly_wait(30)\n",
    "    sleep(1)\n",
    "\n",
    "        #terminou, df, notificacao, palavra_sorteada, letras_aceitas, tentativa = get_notificacao(palavra_sorteada, df, file, now, session_id, dicionario,tentativa, letras_aceitas)\n",
    "    print('------------------------------------')\n",
    "    print('palavra sorteada: ',palavra_sorteada) \n",
    "    print(dicionario)\n",
    "\n",
    "    print('tentativa: ',tentativa)\n",
    "    print('letras erradas: ', letras_erradas)\n",
    "    print('letras lugar errado: ', letras_lugar_errado)\n",
    "    print('letras corretas: ', letras_corretas)\n",
    "\n",
    "    print('letras aceitas: ',letras_aceitas)\n",
    "    terminou, df, notificacao, palavra_sorteada, letras_aceitas, tentativa = get_notificacao(palavra_sorteada, df, file, now, session_id, dicionario,tentativa, letras_aceitas)\n",
    "\n",
    "    #file.write('tentativa,palavra,resultado,data,session_id\\n')\n",
    "    file.write(f'{tentativa},{palavra_sorteada},{notificacao},{data},{session_id},{variavel_randomica},{dicionario}\\n')\n",
    "    tentativa += 1\n",
    "\n",
    "    if tentativa > 6:\n",
    "        terminou = False\n",
    "\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51cbb08f-9d9c-4b09-a50e-41148395a088",
   "metadata": {},
   "outputs": [],
   "source": [
    "letras_aceitas = ''\n",
    "\n",
    "file = open('resultados.txt', 'a')\n",
    "\n",
    "caminho = 'br-utf8.csv'\n",
    "\n",
    "df = carrega_dataframe_csv(caminho)\n",
    "\n",
    "driver = inicializa_termo()\n",
    "\n",
    "def roda_tudo(driver,df,letras_aceitas):\n",
    "    terminou = True\n",
    "    tentativa = 0\n",
    "\n",
    "    now = datetime.now()\n",
    "    data = now.strftime(\"%d/%m/%Y\")\n",
    "    session_id = driver.session_id\n",
    "\n",
    "    #só verificando o seed que foi gerado pra caso precisar replicar\n",
    "    variavel_randomica = random.randint(0,1000)\n",
    "\n",
    "    a = random.seed(variavel_randomica)\n",
    "    print(variavel_randomica)\n",
    "\n",
    "    #print('first')\n",
    "    #pegando a primeira palavra\n",
    "    palavra_sorteada = first_attempt(df)\n",
    "\n",
    "    envia_palavra(palavra_sorteada)\n",
    "\n",
    "    #pegar informações da palavra enviada\n",
    "    dicionario = retorna_dicionario_respostas(tentativa)\n",
    "\n",
    "    #print(palavra_sorteada)\n",
    "    #df, letras_aceitas = filtra_df(dicionario, df, letras_aceitas)\n",
    "\n",
    "    df, letras_aceitas, letras_erradas, letras_lugar_errado, letras_corretas = filtra_df_2(dicionario, df, letras_aceitas)\n",
    "\n",
    "    #driver.implicitly_wait(10)\n",
    "    sleep(1)\n",
    "    print('------------------------------------')\n",
    "    print('palavra sorteada: ',palavra_sorteada) \n",
    "    print(dicionario)\n",
    "    print('tentativa: ',tentativa)\n",
    "    print('letras erradas: ', letras_erradas)\n",
    "    print('letras lugar errado: ', letras_lugar_errado)\n",
    "    print('letras corretas: ', letras_corretas)\n",
    "    print('letras aceitas: ',letras_aceitas)\n",
    "    df.to_csv('debugando.csv')\n",
    "\n",
    "    tentativa += 1\n",
    "\n",
    "    while terminou == True:\n",
    "        #driver.implicitly_wait(5)\n",
    "        #for tentativa in range(5):\n",
    "        #print(tentativa)\n",
    "\n",
    "        palavra_sorteada = sorteia_palavra(df.palavra.values.tolist())\n",
    "        #print(palavra_sorteada)\n",
    "\n",
    "        envia_palavra(palavra_sorteada)\n",
    "\n",
    "        #pegar informações da palavra enviada\n",
    "        dicionario = retorna_dicionario_respostas(tentativa)\n",
    "\n",
    "        #print(palavra_sorteada)\n",
    "        #df.to_csv('debugando.csv')\n",
    "        df, letras_aceitas, letras_erradas, letras_lugar_errado, letras_corretas = filtra_df_2(dicionario, df, letras_aceitas)\n",
    "        #driver.implicitly_wait(30)\n",
    "        sleep(1)\n",
    "\n",
    "            #terminou, df, notificacao, palavra_sorteada, letras_aceitas, tentativa = get_notificacao(palavra_sorteada, df, file, now, session_id, dicionario,tentativa, letras_aceitas)\n",
    "        print('------------------------------------')\n",
    "        print('palavra sorteada: ',palavra_sorteada) \n",
    "        print(dicionario)\n",
    "\n",
    "        print('tentativa: ',tentativa)\n",
    "        print('letras erradas: ', letras_erradas)\n",
    "        print('letras lugar errado: ', letras_lugar_errado)\n",
    "        print('letras corretas: ', letras_corretas)\n",
    "\n",
    "        print('letras aceitas: ',letras_aceitas)\n",
    "        terminou, df, notificacao, palavra_sorteada, letras_aceitas, tentativa = get_notificacao(palavra_sorteada, df, file, now, session_id, dicionario,tentativa, letras_aceitas)\n",
    "\n",
    "        #file.write('tentativa,palavra,resultado,data,session_id\\n')\n",
    "        file.write(f'{tentativa},{palavra_sorteada},{notificacao},{data},{session_id},{variavel_randomica},{dicionario}\\n')\n",
    "        tentativa += 1\n",
    "\n",
    "        if tentativa > 6:\n",
    "            terminou = False\n",
    "\n",
    "    file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f20ea65-fcbe-4ade-bcbe-41ceb26ca7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252\n",
      "------------------------------------\n",
      "palavra sorteada:  aureo\n",
      "{0: ('letter place', 'a'), 1: ('letter wrong', 'u'), 2: ('letter place', 'r'), 3: ('letter wrong', 'e'), 4: ('letter place', 'o')}\n",
      "tentativa:  0\n",
      "letras erradas:  [('u', 1, False), ('e', 3, False)]\n",
      "letras lugar errado:  [('a', 0), ('r', 2), ('o', 4)]\n",
      "letras corretas:  []\n",
      "letras aceitas:  aro\n",
      "------------------------------------\n",
      "palavra sorteada:  broas\n",
      "{0: ('letter wrong', 'b'), 1: ('letter place', 'r'), 2: ('letter place', 'o'), 3: ('letter place', 'a'), 4: ('letter wrong', 's')}\n",
      "tentativa:  1\n",
      "letras erradas:  [('b', 0, False), ('s', 4, False)]\n",
      "letras lugar errado:  [('r', 1), ('o', 2), ('a', 3)]\n",
      "letras corretas:  []\n",
      "letras aceitas:  aroroa\n",
      "------------------------------------\n",
      "palavra sorteada:  major\n",
      "{0: ('letter wrong', 'm'), 1: ('letter right', 'a'), 2: ('letter wrong', 'j'), 3: ('letter right', 'o'), 4: ('letter right', 'r')}\n",
      "tentativa:  2\n",
      "letras erradas:  [('m', 0, False), ('j', 2, False)]\n",
      "letras lugar errado:  []\n",
      "letras corretas:  [('a', 1), ('o', 3), ('r', 4)]\n",
      "letras aceitas:  aroroaaor\n",
      "------------------------------------\n",
      "palavra sorteada:  valor\n",
      "{0: ('letter place', 'v'), 1: ('letter right', 'a'), 2: ('letter wrong', 'l'), 3: ('letter right', 'o'), 4: ('letter right', 'r')}\n",
      "tentativa:  3\n",
      "letras erradas:  [('l', 2, False)]\n",
      "letras lugar errado:  [('v', 0)]\n",
      "letras corretas:  [('a', 1), ('o', 3), ('r', 4)]\n",
      "letras aceitas:  aroroaaoraorv\n",
      "------------------------------------\n",
      "palavra sorteada:  favor\n",
      "{0: ('letter wrong', 'f'), 1: ('letter right', 'a'), 2: ('letter right', 'v'), 3: ('letter right', 'o'), 4: ('letter right', 'r')}\n",
      "tentativa:  4\n",
      "letras erradas:  [('f', 0, False)]\n",
      "letras lugar errado:  []\n",
      "letras corretas:  [('a', 1), ('v', 2), ('o', 3), ('r', 4)]\n",
      "letras aceitas:  aroroaaoraorvavor\n",
      "------------------------------------\n",
      "palavra sorteada:  pavor\n",
      "{0: ('letter right done', 'p'), 1: ('letter right done', 'a'), 2: ('letter right done', 'v'), 3: ('letter right done', 'o'), 4: ('letter right done', 'r')}\n",
      "tentativa:  5\n",
      "letras erradas:  []\n",
      "letras lugar errado:  []\n",
      "letras corretas:  []\n",
      "letras aceitas:  aroroaaoraorvavor\n"
     ]
    }
   ],
   "source": [
    "roda_tudo(driver,df,letras_aceitas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08884810-2973-4ee1-848b-a6d9a62f17c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296c5fb7-7707-4cec-b49b-231a1d65f0bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2fccae6d-3e1c-4b43-8e84-d1e98603e38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "820\n"
     ]
    }
   ],
   "source": [
    "letras_aceitas = ''\n",
    "\n",
    "file = open('resultados.txt', 'a')\n",
    "\n",
    "caminho = 'br-utf8.csv'\n",
    "\n",
    "df = carrega_dataframe_csv(caminho)\n",
    "\n",
    "driver = inicializa_termo()\n",
    "\n",
    "\n",
    "terminou = True\n",
    "tentativa = 0\n",
    "\n",
    "now = datetime.now()\n",
    "data = now.strftime(\"%d/%m/%Y\")\n",
    "session_id = driver.session_id\n",
    "\n",
    "#só verificando o seed que foi gerado pra caso precisar replicar\n",
    "variavel_randomica = random.randint(0,1000)\n",
    "a = random.seed(variavel_randomica)\n",
    "print(variavel_randomica)\n",
    "\n",
    "\n",
    "palavra_sorteada = first_attempt(df)\n",
    "\n",
    "envia_palavra(palavra_sorteada)\n",
    "\n",
    "#pegar informações da palavra enviada\n",
    "dicionario = retorna_dicionario_respostas(tentativa)\n",
    "\n",
    "#\n",
    "\n",
    "df, letras_aceitas, letras_erradas, letras_lugar_errado, letras_corretas = filtra_df_2(dicionario, df, letras_aceitas)\n",
    "\n",
    "\n",
    "sleep(1)\n",
    "\n",
    "tentativa += 1\n",
    "\n",
    "while terminou == True:\n",
    "\n",
    "\n",
    "    palavra_sorteada = sorteia_palavra(df.palavra.values.tolist())\n",
    "\n",
    "\n",
    "    envia_palavra(palavra_sorteada)\n",
    "\n",
    "    #pegar informações da palavra enviada\n",
    "    dicionario = retorna_dicionario_respostas(tentativa)\n",
    "\n",
    "    df, letras_aceitas, letras_erradas, letras_lugar_errado, letras_corretas = filtra_df_2(dicionario, df, letras_aceitas)\n",
    "\n",
    "    sleep(1)\n",
    "\n",
    "        #terminou, df, notificacao, palavra_sorteada, letras_aceitas, tentativa = get_notificacao(palavra_sorteada, df, file, now, session_id, dicionario,tentativa, letras_aceitas)\n",
    "    terminou, df, notificacao, palavra_sorteada, letras_aceitas, tentativa = get_notificacao(palavra_sorteada, df, file, now, session_id, dicionario,tentativa, letras_aceitas)\n",
    "    \n",
    "    #file.write('tentativa,palavra,resultado,data,session_id\\n')\n",
    "    file.write(f'{tentativa},{palavra_sorteada},{notificacao},{data},{session_id},{variavel_randomica},{dicionario}\\n')\n",
    "    tentativa += 1\n",
    "    \n",
    "    if tentativa > 6:\n",
    "        terminou = False\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2169130-dc55-47ca-86d6-e66095e2437c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a2901f-27d4-4684-bf5d-4d6207b90083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79299015-90f5-4a00-841a-a2f77b25eaef",
   "metadata": {},
   "source": [
    "# Melhora na escolha de palavra\n",
    "\n",
    "usando um pouco dos conceitos de NLP para carregar as palavras de alguns livros disponibilizados publicamente:\n",
    "- Dom Casmurro\n",
    "- D. Quixote\n",
    "- Iracema\n",
    "- Os Sertoes\n",
    "- Primo Basilio\n",
    "- Poemas Fernando Pessoa\n",
    "    \n",
    "Com esses livros tentei gerar uma variavel de probabilidade das palavras mais utilizadas para assim filtrar pela com maior probabilidade de uso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5080e062-db1c-4c9a-84b2-ebd21469844f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['carro',\n",
       " 'parte',\n",
       " 'desta',\n",
       " 'assim',\n",
       " 'ainda',\n",
       " 'quase',\n",
       " 'falar',\n",
       " 'coisa',\n",
       " 'abrir',\n",
       " 'ainda',\n",
       " 'enfim',\n",
       " 'baeta',\n",
       " 'verde',\n",
       " 'senao',\n",
       " 'mumia',\n",
       " 'foram',\n",
       " 'muito',\n",
       " 'saude',\n",
       " 'conta',\n",
       " 'muito',\n",
       " 'juizo',\n",
       " 'muito',\n",
       " 'razao',\n",
       " 'modos',\n",
       " 'abuso',\n",
       " 'outro',\n",
       " 'solon',\n",
       " 'senao',\n",
       " 'outra',\n",
       " 'falou',\n",
       " 'tanta',\n",
       " 'todos',\n",
       " 'juizo',\n",
       " 'tocar',\n",
       " 'falsa',\n",
       " 'assim',\n",
       " 'lance',\n",
       " 'lance',\n",
       " 'vindo',\n",
       " 'corte',\n",
       " 'entre',\n",
       " 'disse',\n",
       " 'certo',\n",
       " 'turco',\n",
       " 'sabia',\n",
       " 'nuvem',\n",
       " 'temor',\n",
       " 'quase',\n",
       " 'todos',\n",
       " 'malta',\n",
       " 'tempo',\n",
       " 'estas',\n",
       " 'horas',\n",
       " 'muito',\n",
       " 'longe',\n",
       " 'ouviu',\n",
       " 'estas',\n",
       " 'disse',\n",
       " 'entre',\n",
       " 'pobre',\n",
       " 'mesmo',\n",
       " 'lista',\n",
       " 'disse',\n",
       " 'muito',\n",
       " 'outra',\n",
       " 'coisa',\n",
       " 'senao',\n",
       " 'todos',\n",
       " 'maior',\n",
       " 'parte',\n",
       " 'reino',\n",
       " 'facil',\n",
       " 'justo',\n",
       " 'breve',\n",
       " 'caber',\n",
       " 'vossa',\n",
       " 'merce',\n",
       " 'tarda',\n",
       " 'disse',\n",
       " 'agora',\n",
       " 'outro',\n",
       " 'minha',\n",
       " 'vossa',\n",
       " 'merce',\n",
       " 'roque',\n",
       " 'homem',\n",
       " 'algum',\n",
       " 'disse',\n",
       " 'disse',\n",
       " 'tenho',\n",
       " 'homem',\n",
       " 'fosse',\n",
       " 'disse',\n",
       " 'neste',\n",
       " 'pagar',\n",
       " 'vossa',\n",
       " 'merce',\n",
       " 'minha',\n",
       " 'corpo',\n",
       " 'certo',\n",
       " 'corte',\n",
       " 'todos',\n",
       " 'ainda',\n",
       " 'senao',\n",
       " 'duzia',\n",
       " 'podia',\n",
       " 'entre',\n",
       " 'algum',\n",
       " 'poder',\n",
       " 'turco',\n",
       " 'coisa',\n",
       " 'todos',\n",
       " 'quero',\n",
       " 'dizer',\n",
       " 'outro',\n",
       " 'algum',\n",
       " 'gaula',\n",
       " 'turco',\n",
       " 'algum',\n",
       " 'deles',\n",
       " 'ganho',\n",
       " 'algum',\n",
       " 'bravo',\n",
       " 'menos',\n",
       " 'animo',\n",
       " 'matem',\n",
       " 'desca',\n",
       " 'turco',\n",
       " 'puder',\n",
       " 'outra',\n",
       " 'nisto',\n",
       " 'breve',\n",
       " 'molde',\n",
       " 'sinto',\n",
       " 'desta',\n",
       " 'homem',\n",
       " 'falta',\n",
       " 'juizo',\n",
       " 'ainda',\n",
       " 'fosse',\n",
       " 'louco',\n",
       " 'juizo',\n",
       " 'muito',\n",
       " 'tirar',\n",
       " 'vivia',\n",
       " 'juizo',\n",
       " 'razao',\n",
       " 'fosse',\n",
       " 'doido',\n",
       " 'morte',\n",
       " 'doido',\n",
       " 'visse',\n",
       " 'juizo',\n",
       " 'assim',\n",
       " 'homem',\n",
       " 'ainda',\n",
       " 'doido',\n",
       " 'posto',\n",
       " 'vezes',\n",
       " 'serem',\n",
       " 'podia',\n",
       " 'fazer',\n",
       " 'doido',\n",
       " 'tempo',\n",
       " 'nunca',\n",
       " 'doido',\n",
       " 'disse',\n",
       " 'coisa',\n",
       " 'antes',\n",
       " 'doido',\n",
       " 'entre',\n",
       " 'disse',\n",
       " 'doido',\n",
       " 'maior',\n",
       " 'tinha',\n",
       " 'muita',\n",
       " 'merce',\n",
       " 'nosso',\n",
       " 'mudar',\n",
       " 'bruto',\n",
       " 'homem',\n",
       " 'falou',\n",
       " 'visse',\n",
       " 'nesta',\n",
       " 'pediu',\n",
       " 'visse',\n",
       " 'fazia',\n",
       " 'ainda',\n",
       " 'doido',\n",
       " 'levar',\n",
       " 'vendo',\n",
       " 'ordem',\n",
       " 'ainda',\n",
       " 'assim',\n",
       " 'homem',\n",
       " 'louco',\n",
       " 'pediu',\n",
       " 'jaula',\n",
       " 'doido',\n",
       " 'ainda',\n",
       " 'nesse',\n",
       " 'irmao',\n",
       " 'minha',\n",
       " 'juizo',\n",
       " 'estou',\n",
       " 'tenha',\n",
       " 'nosso',\n",
       " 'terei',\n",
       " 'saber',\n",
       " 'todas',\n",
       " 'saude',\n",
       " 'morte',\n",
       " 'todas',\n",
       " 'estas',\n",
       " 'outro',\n",
       " 'doido',\n",
       " 'jaula',\n",
       " 'velha',\n",
       " 'juizo',\n",
       " 'irmao',\n",
       " 'tenho',\n",
       " 'tempo',\n",
       " 'merce',\n",
       " 'diabo',\n",
       " 'doido',\n",
       " 'vossa',\n",
       " 'volta',\n",
       " 'estou',\n",
       " 'disse',\n",
       " 'louco',\n",
       " 'muito',\n",
       " 'terra',\n",
       " 'tirar',\n",
       " 'desta',\n",
       " 'homem',\n",
       " 'tenho',\n",
       " 'fique',\n",
       " 'todos',\n",
       " 'sabes',\n",
       " 'fazer',\n",
       " 'tenho',\n",
       " 'raios',\n",
       " 'posso',\n",
       " 'mundo',\n",
       " 'coisa',\n",
       " 'quero',\n",
       " 'desde',\n",
       " 'livre',\n",
       " 'juizo',\n",
       " 'louco',\n",
       " 'tanto',\n",
       " 'chuva',\n",
       " 'terra',\n",
       " 'penso',\n",
       " 'ouvir',\n",
       " 'vozes',\n",
       " 'louco',\n",
       " 'nosso',\n",
       " 'vossa',\n",
       " 'merce',\n",
       " 'louco',\n",
       " 'chuva',\n",
       " 'aguas',\n",
       " 'todas',\n",
       " 'vezes',\n",
       " 'fique',\n",
       " 'vossa',\n",
       " 'merce',\n",
       " 'outro',\n",
       " 'vagar',\n",
       " 'vossa',\n",
       " 'merce',\n",
       " 'deste',\n",
       " 'ficou',\n",
       " 'ficou',\n",
       " 'entao',\n",
       " 'conto',\n",
       " 'disse',\n",
       " 'molde',\n",
       " 'podia',\n",
       " 'entre',\n",
       " 'vossa',\n",
       " 'merce',\n",
       " 'saiba',\n",
       " 'fazem',\n",
       " 'valor',\n",
       " 'valor',\n",
       " 'aguas',\n",
       " 'tenha',\n",
       " 'sendo',\n",
       " 'canso',\n",
       " 'fazer',\n",
       " 'mundo',\n",
       " 'ordem',\n",
       " 'pompa',\n",
       " 'nossa',\n",
       " 'idade',\n",
       " 'gozar',\n",
       " 'cargo',\n",
       " 'antes',\n",
       " 'ricas',\n",
       " 'telas',\n",
       " 'malha',\n",
       " 'armam',\n",
       " 'durma',\n",
       " 'rigor',\n",
       " 'ponto',\n",
       " 'tirar',\n",
       " 'lanca',\n",
       " 'dizer',\n",
       " 'praia',\n",
       " 'vezes',\n",
       " 'beira',\n",
       " 'batel',\n",
       " 'ondas',\n",
       " 'pondo',\n",
       " 'peito',\n",
       " 'lugar',\n",
       " 'terra',\n",
       " 'agora',\n",
       " 'porem',\n",
       " 'vicio',\n",
       " 'armas',\n",
       " 'senao',\n",
       " 'gaula',\n",
       " 'gaula',\n",
       " 'felix',\n",
       " 'marte',\n",
       " 'bravo',\n",
       " 'todos',\n",
       " 'estes',\n",
       " 'dizer',\n",
       " 'foram',\n",
       " 'estes',\n",
       " 'muita',\n",
       " 'turco',\n",
       " 'quero',\n",
       " 'ficar',\n",
       " 'minha',\n",
       " 'estou',\n",
       " 'saiba',\n",
       " 'muito',\n",
       " 'disse',\n",
       " 'assim',\n",
       " 'ajude',\n",
       " 'vossa',\n",
       " 'merce',\n",
       " 'ainda',\n",
       " 'disse',\n",
       " 'agora',\n",
       " 'ainda',\n",
       " 'quase',\n",
       " 'ficar',\n",
       " 'disse',\n",
       " 'assim',\n",
       " 'dizer',\n",
       " 'andar',\n",
       " 'posso',\n",
       " 'vossa',\n",
       " 'merce',\n",
       " 'neste',\n",
       " 'mundo',\n",
       " 'carne',\n",
       " 'antes',\n",
       " 'dizer',\n",
       " 'outro',\n",
       " 'caido',\n",
       " 'mundo',\n",
       " 'vezes',\n",
       " 'tirar',\n",
       " 'quase',\n",
       " 'comum',\n",
       " 'vezes',\n",
       " 'minha',\n",
       " 'certa',\n",
       " 'estou',\n",
       " 'dizer',\n",
       " 'olhos',\n",
       " 'gaula',\n",
       " 'homem',\n",
       " 'corpo',\n",
       " 'rosto',\n",
       " 'barba',\n",
       " 'negra',\n",
       " 'olhar',\n",
       " 'entre',\n",
       " 'curto',\n",
       " 'depor',\n",
       " 'penso',\n",
       " 'todos',\n",
       " 'ideia',\n",
       " 'tenho',\n",
       " 'foram',\n",
       " 'pelas',\n",
       " 'podem',\n",
       " 'tirar',\n",
       " 'vossa',\n",
       " 'merce',\n",
       " 'seria',\n",
       " 'nisto',\n",
       " 'mundo',\n",
       " 'santa',\n",
       " 'atomo',\n",
       " 'houve',\n",
       " 'tinha',\n",
       " 'foram',\n",
       " 'dizer',\n",
       " 'teria',\n",
       " 'ainda',\n",
       " 'devia',\n",
       " 'muito',\n",
       " 'desta',\n",
       " 'vezes',\n",
       " 'telha',\n",
       " 'claro',\n",
       " 'assim',\n",
       " 'disse',\n",
       " 'ouvir',\n",
       " 'dizer',\n",
       " 'pares',\n",
       " 'todos',\n",
       " 'dizer',\n",
       " 'larga',\n",
       " 'olhos',\n",
       " 'pouco',\n",
       " 'amigo',\n",
       " 'gente',\n",
       " 'todos',\n",
       " 'estes',\n",
       " 'nomes',\n",
       " 'largo',\n",
       " 'rosto',\n",
       " 'corpo',\n",
       " 'vista',\n",
       " 'curto',\n",
       " 'muito',\n",
       " 'homem',\n",
       " 'vossa',\n",
       " 'merce',\n",
       " 'devia',\n",
       " 'antes',\n",
       " 'tanto',\n",
       " 'mundo',\n",
       " 'cheio',\n",
       " 'louro',\n",
       " 'amigo',\n",
       " 'catai',\n",
       " 'cetro',\n",
       " 'outro',\n",
       " 'vates',\n",
       " 'dizer',\n",
       " 'poeta',\n",
       " 'outro',\n",
       " 'unico',\n",
       " 'poeta',\n",
       " 'houve',\n",
       " 'poeta',\n",
       " 'algum',\n",
       " 'entre',\n",
       " 'creio',\n",
       " 'pelas',\n",
       " 'damas',\n",
       " 'agora',\n",
       " 'mundo',\n",
       " 'disse',\n",
       " 'nisto',\n",
       " 'davam',\n",
       " 'patio',\n",
       " 'todos',\n",
       " 'ruido',\n",
       " 'trata',\n",
       " 'panca',\n",
       " 'conta',\n",
       " 'panca',\n",
       " 'porta',\n",
       " 'nesta',\n",
       " 'vossa',\n",
       " 'irmao',\n",
       " 'essas',\n",
       " 'levou',\n",
       " 'esses',\n",
       " 'tirou',\n",
       " 'minha',\n",
       " 'ainda',\n",
       " 'estou',\n",
       " 'ilhas',\n",
       " 'ilhas',\n",
       " 'coisa',\n",
       " 'comer',\n",
       " 'comer',\n",
       " 'reger',\n",
       " 'corte',\n",
       " 'vossa',\n",
       " 'ilhas',\n",
       " 'ilhos',\n",
       " 'gosto',\n",
       " 'ouvir',\n",
       " 'algum',\n",
       " 'ponto',\n",
       " 'fosse',\n",
       " 'muito',\n",
       " 'disse',\n",
       " 'saude',\n",
       " 'vendo',\n",
       " 'disse',\n",
       " 'menos',\n",
       " 'nosso',\n",
       " 'outra',\n",
       " 'andar',\n",
       " 'ponho',\n",
       " 'nisso',\n",
       " 'tanto',\n",
       " 'tiram',\n",
       " 'ambos',\n",
       " 'mesma',\n",
       " 'pedra',\n",
       " 'coisa',\n",
       " 'assim',\n",
       " 'muito',\n",
       " 'saber',\n",
       " 'tenho',\n",
       " 'disse',\n",
       " 'muito',\n",
       " 'dizer',\n",
       " 'tirei',\n",
       " 'muito',\n",
       " 'fomos',\n",
       " 'ambos',\n",
       " 'mesma',\n",
       " 'mesma',\n",
       " 'sorte',\n",
       " 'vezes',\n",
       " 'unica',\n",
       " 'razao',\n",
       " 'vossa',\n",
       " 'merce',\n",
       " 'dizem',\n",
       " 'caput',\n",
       " 'dolet',\n",
       " 'outra',\n",
       " 'senao',\n",
       " 'minha',\n",
       " 'quero',\n",
       " 'dizer',\n",
       " 'todos',\n",
       " 'assim',\n",
       " 'sendo',\n",
       " 'parte',\n",
       " 'visto',\n",
       " 'tocar',\n",
       " 'assim',\n",
       " 'devia',\n",
       " 'disse',\n",
       " 'minha',\n",
       " 'vossa',\n",
       " 'merce',\n",
       " 'pelos',\n",
       " 'males',\n",
       " 'devia',\n",
       " 'males',\n",
       " 'deles',\n",
       " 'dizer',\n",
       " 'agora',\n",
       " 'dizes',\n",
       " 'corpo',\n",
       " 'agora',\n",
       " 'tempo',\n",
       " 'limpo',\n",
       " 'amigo',\n",
       " 'dizem',\n",
       " 'lugar',\n",
       " 'vulgo',\n",
       " 'dizem',\n",
       " 'valor',\n",
       " 'minha',\n",
       " 'pensa',\n",
       " 'tomei',\n",
       " 'ordem',\n",
       " 'quero',\n",
       " 'tiver',\n",
       " 'dizer',\n",
       " 'coisa',\n",
       " 'leais',\n",
       " 'dizer',\n",
       " 'outro',\n",
       " 'quero',\n",
       " 'ferro',\n",
       " 'nossa',\n",
       " 'aviso',\n",
       " 'digas',\n",
       " 'muito',\n",
       " 'vossa',\n",
       " 'merce',\n",
       " 'sejam',\n",
       " 'podes',\n",
       " 'falar',\n",
       " 'coisa',\n",
       " 'posso',\n",
       " 'vulgo',\n",
       " 'vossa',\n",
       " 'merce',\n",
       " 'louco',\n",
       " 'menos',\n",
       " 'dizem',\n",
       " 'vossa',\n",
       " 'merce',\n",
       " 'tomou',\n",
       " 'cepas',\n",
       " 'terra',\n",
       " 'trapo',\n",
       " 'atras',\n",
       " 'outro',\n",
       " 'dizem',\n",
       " 'meias',\n",
       " 'verde',\n",
       " 'disse',\n",
       " 'sabes',\n",
       " 'nunca',\n",
       " 'armas',\n",
       " 'tempo',\n",
       " 'valor',\n",
       " 'vossa',\n",
       " 'merce',\n",
       " 'dizem',\n",
       " 'louco',\n",
       " 'assim',\n",
       " 'vossa',\n",
       " 'merce',\n",
       " 'disse',\n",
       " 'veras',\n",
       " 'terra',\n",
       " 'julio',\n",
       " 'cesar',\n",
       " 'muito',\n",
       " 'limpo',\n",
       " 'magno',\n",
       " 'dizem',\n",
       " 'vezes',\n",
       " 'conta',\n",
       " 'irmao',\n",
       " 'gaula',\n",
       " 'entre',\n",
       " 'podem',\n",
       " 'foram',\n",
       " 'ponto',\n",
       " 'corpo',\n",
       " 'falta',\n",
       " 'ainda',\n",
       " 'agora',\n",
       " 'vossa',\n",
       " 'merce',\n",
       " 'saber',\n",
       " 'certo',\n",
       " 'trago',\n",
       " 'todas',\n",
       " 'noite',\n",
       " 'filho',\n",
       " 'feito',\n",
       " 'vossa',\n",
       " 'merce',\n",
       " 'conta',\n",
       " 'panca',\n",
       " 'benzi',\n",
       " 'saber',\n",
       " 'algum',\n",
       " 'sabio',\n",
       " 'autor',\n",
       " 'nossa',\n",
       " 'esses',\n",
       " 'sabio',\n",
       " 'chama',\n",
       " 'mouro',\n",
       " 'disse',\n",
       " 'assim',\n",
       " 'dizer',\n",
       " 'erras',\n",
       " 'nesse',\n",
       " 'arabe',\n",
       " 'dizer',\n",
       " 'muito',\n",
       " 'vossa',\n",
       " 'merce',\n",
       " 'traga',\n",
       " 'nisso',\n",
       " 'muito',\n",
       " 'gosto',\n",
       " 'disse',\n",
       " 'coisa',\n",
       " 'saiba',\n",
       " 'pouco',\n",
       " 'houve',\n",
       " 'entre',\n",
       " 'todos',\n",
       " 'houve',\n",
       " 'entre',\n",
       " 'panca',\n",
       " 'ficou',\n",
       " 'vinha',\n",
       " 'ouvir',\n",
       " 'livro',\n",
       " 'podia',\n",
       " 'ainda',\n",
       " 'folha',\n",
       " 'altas',\n",
       " 'algum',\n",
       " 'sabio',\n",
       " 'amigo',\n",
       " 'amigo',\n",
       " 'acima',\n",
       " 'ainda',\n",
       " 'dizia',\n",
       " 'entre',\n",
       " 'nunca',\n",
       " 'fosse',\n",
       " 'sendo',\n",
       " 'havia',\n",
       " 'tanto',\n",
       " 'autor',\n",
       " 'mouro',\n",
       " 'podia',\n",
       " 'todos',\n",
       " 'temia',\n",
       " 'assim',\n",
       " 'muita',\n",
       " 'muito',\n",
       " 'otimo',\n",
       " 'teria',\n",
       " 'vinte',\n",
       " 'nariz',\n",
       " 'chato',\n",
       " 'amigo',\n",
       " 'assim',\n",
       " 'vossa',\n",
       " 'merce',\n",
       " 'pedro',\n",
       " 'visto',\n",
       " 'senao',\n",
       " 'vossa',\n",
       " 'merce',\n",
       " 'terra',\n",
       " 'arabe',\n",
       " 'nosso',\n",
       " 'disse',\n",
       " 'entao',\n",
       " 'haver',\n",
       " 'mouro',\n",
       " 'sabio',\n",
       " 'disse',\n",
       " 'tenho',\n",
       " 'estao',\n",
       " 'senao',\n",
       " 'ainda',\n",
       " 'corre',\n",
       " 'haver',\n",
       " 'nacao',\n",
       " 'maior',\n",
       " 'homem',\n",
       " 'andar',\n",
       " 'pelas',\n",
       " 'bocas',\n",
       " 'mundo',\n",
       " 'claro',\n",
       " 'sendo',\n",
       " 'morte',\n",
       " 'nisso',\n",
       " 'vossa',\n",
       " 'merce',\n",
       " 'palma',\n",
       " 'todos',\n",
       " 'mouro',\n",
       " 'vossa',\n",
       " 'merce',\n",
       " 'animo',\n",
       " 'assim',\n",
       " 'vossa',\n",
       " 'merce',\n",
       " 'muito',\n",
       " 'minha',\n",
       " 'nunca',\n",
       " 'minha',\n",
       " 'disse',\n",
       " 'neste',\n",
       " 'nesse',\n",
       " 'ponto',\n",
       " 'pouco',\n",
       " 'vossa',\n",
       " 'merce',\n",
       " 'nessa',\n",
       " 'nisso',\n",
       " 'vento',\n",
       " 'vossa',\n",
       " 'merce',\n",
       " 'morto',\n",
       " 'todas',\n",
       " 'outro',\n",
       " 'entra',\n",
       " 'nosso',\n",
       " 'ideia',\n",
       " 'fazer',\n",
       " 'eguas',\n",
       " 'ficou',\n",
       " 'sabio',\n",
       " 'coisa',\n",
       " 'manta',\n",
       " 'manta',\n",
       " 'ainda',\n",
       " 'disse',\n",
       " 'mundo',\n",
       " 'tenha',\n",
       " 'altos',\n",
       " 'quais',\n",
       " 'nunca',\n",
       " 'podem',\n",
       " 'estar',\n",
       " 'dizem',\n",
       " 'leram',\n",
       " 'deram',\n",
       " 'notou',\n",
       " 'acoes',\n",
       " 'mudam',\n",
       " 'fundo',\n",
       " 'pinta',\n",
       " 'assim',\n",
       " 'coisa',\n",
       " 'poeta',\n",
       " 'outra',\n",
       " 'poeta',\n",
       " 'foram',\n",
       " 'foram',\n",
       " 'tirar',\n",
       " 'coisa',\n",
       " 'mouro',\n",
       " 'dizer',\n",
       " 'disse',\n",
       " 'certo',\n",
       " 'entre',\n",
       " 'nunca',\n",
       " 'merce',\n",
       " 'corpo',\n",
       " 'mesmo',\n",
       " 'falta',\n",
       " 'deram',\n",
       " 'disse',\n",
       " 'ainda',\n",
       " 'tenho',\n",
       " 'dizem',\n",
       " 'amigo',\n",
       " 'temos',\n",
       " 'outro',\n",
       " 'disse',\n",
       " 'nisso',\n",
       " 'estes',\n",
       " 'falar',\n",
       " 'posto',\n",
       " 'meter',\n",
       " 'podia',\n",
       " 'ainda',\n",
       " 'mundo',\n",
       " 'disse',\n",
       " 'habil',\n",
       " 'idade',\n",
       " 'tenho',\n",
       " 'idade',\n",
       " 'falta',\n",
       " 'folha',\n",
       " 'assim',\n",
       " 'disse',\n",
       " 'ilhas',\n",
       " 'tenho',\n",
       " 'visto',\n",
       " 'solas',\n",
       " 'prata',\n",
       " 'esses',\n",
       " 'ilhas',\n",
       " 'menos',\n",
       " 'ilhas',\n",
       " 'menos',\n",
       " 'saber',\n",
       " 'ticas',\n",
       " 'gosto',\n",
       " 'saber',\n",
       " 'autor',\n",
       " 'bulha',\n",
       " 'seria',\n",
       " 'ponha',\n",
       " 'moche',\n",
       " 'notam',\n",
       " 'autor',\n",
       " 'estar',\n",
       " 'lugar',\n",
       " 'merce',\n",
       " 'filho',\n",
       " 'perro',\n",
       " 'alhos',\n",
       " 'agora',\n",
       " 'sabio',\n",
       " 'autor',\n",
       " 'minha',\n",
       " 'algum',\n",
       " 'tento',\n",
       " 'juizo',\n",
       " 'ubeda',\n",
       " 'vezes',\n",
       " 'pouco',\n",
       " 'assim',\n",
       " 'minha',\n",
       " 'clara',\n",
       " 'mocos',\n",
       " 'casta',\n",
       " 'algum',\n",
       " 'rocim',\n",
       " 'magro',\n",
       " 'foram',\n",
       " 'larga',\n",
       " 'outro',\n",
       " 'menos',\n",
       " 'agora',\n",
       " 'visto',\n",
       " 'menos',\n",
       " 'forma',\n",
       " 'disse',\n",
       " 'valem',\n",
       " 'fazem',\n",
       " 'moeda',\n",
       " 'falsa',\n",
       " 'autor',\n",
       " 'tanto',\n",
       " 'dizer',\n",
       " 'rifao',\n",
       " 'palha',\n",
       " 'podia',\n",
       " 'fazer',\n",
       " 'maior',\n",
       " 'todas',\n",
       " 'obras',\n",
       " 'sejam',\n",
       " 'juizo',\n",
       " 'dizer',\n",
       " 'parvo',\n",
       " 'coisa',\n",
       " 'livro',\n",
       " 'tenha',\n",
       " 'coisa',\n",
       " 'vezes',\n",
       " 'ganho',\n",
       " 'pelos',\n",
       " 'menos',\n",
       " 'disso',\n",
       " 'vagar',\n",
       " 'obras',\n",
       " 'erros',\n",
       " 'tanto',\n",
       " 'maior',\n",
       " 'maior',\n",
       " 'parte',\n",
       " 'vezes',\n",
       " 'gosto',\n",
       " 'mundo',\n",
       " 'disse',\n",
       " 'erros',\n",
       " 'assim',\n",
       " 'menos',\n",
       " 'podem',\n",
       " 'bonus',\n",
       " 'muito',\n",
       " 'menos',\n",
       " 'possa',\n",
       " 'muito',\n",
       " 'sejam',\n",
       " 'vezes',\n",
       " 'rosto',\n",
       " 'assim',\n",
       " 'risco',\n",
       " 'expoe',\n",
       " 'livro',\n",
       " 'sendo',\n",
       " 'forma',\n",
       " 'todos',\n",
       " 'lerem',\n",
       " 'trata',\n",
       " 'disse',\n",
       " 'falta',\n",
       " 'autor',\n",
       " 'coisa',\n",
       " 'pouco',\n",
       " 'mesmo',\n",
       " 'saber',\n",
       " 'dizem',\n",
       " 'dizer',\n",
       " 'serra',\n",
       " 'nunca',\n",
       " 'falou',\n",
       " 'neles',\n",
       " 'saber',\n",
       " 'estou',\n",
       " 'agora',\n",
       " 'acudo',\n",
       " 'pinga',\n",
       " 'capaz',\n",
       " 'estou',\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "local = 'livros.txt'\n",
    "def abrir_arquivo(local):\n",
    "    with open(local, 'r', encoding = 'utf8') as f:\n",
    "        palavras = f.read()\n",
    "    f.close()\n",
    "    lista_tokens = nltk.tokenize.word_tokenize(palavras)\n",
    "    lista_palavras = []\n",
    "    for i in lista_tokens:\n",
    "        if i.isalpha():\n",
    "            if len(i) == 5:\n",
    "                lista_palavras.append(remove_acentos(i.lower()))\n",
    "            \n",
    "    f.close()\n",
    "    return lista_palavras\n",
    "\n",
    "lista_palavras = abrir_arquivo(local)\n",
    "lista_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "493c3abc-3392-42f5-a27e-5d34ccfdf981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('minha', 847),\n",
       " ('todos', 813),\n",
       " ('disse', 800),\n",
       " ('ainda', 788),\n",
       " ('muito', 742),\n",
       " ('assim', 716),\n",
       " ('sobre', 616),\n",
       " ('vossa', 590),\n",
       " ('entre', 589),\n",
       " ('mesmo', 526)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def probabilidade(palavra):\n",
    "    return frequencia[palavra]/total_de_palavras\n",
    "\n",
    "frequencia = nltk.FreqDist(lista_palavras)\n",
    "total_de_palavras = len(lista_palavras)\n",
    "frequencia.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b9b1c2f0-129f-4ad1-b194-7356af38430c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9026"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lista_palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef6c431a-ad4b-493a-9554-2453356594cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>n_vogais</th>\n",
       "      <th>vogais_unicas</th>\n",
       "      <th>letra_0</th>\n",
       "      <th>letra_1</th>\n",
       "      <th>letra_2</th>\n",
       "      <th>letra_3</th>\n",
       "      <th>letra_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aarao</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>a</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abner</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acaia</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>i</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acker</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>k</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aires</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>i</td>\n",
       "      <td>r</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5414</th>\n",
       "      <td>unica</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>n</td>\n",
       "      <td>i</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5415</th>\n",
       "      <td>unico</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>n</td>\n",
       "      <td>i</td>\n",
       "      <td>c</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5416</th>\n",
       "      <td>urico</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>r</td>\n",
       "      <td>i</td>\n",
       "      <td>c</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5417</th>\n",
       "      <td>uteis</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "      <td>i</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5418</th>\n",
       "      <td>utero</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5419 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     palavra  n_vogais  vogais_unicas letra_0 letra_1 letra_2 letra_3 letra_4\n",
       "0      aarao         4              2       a       a       r       a       o\n",
       "1      abner         2              2       a       b       n       e       r\n",
       "2      acaia         4              2       a       c       a       i       a\n",
       "3      acker         2              2       a       c       k       e       r\n",
       "4      aires         3              3       a       i       r       e       s\n",
       "...      ...       ...            ...     ...     ...     ...     ...     ...\n",
       "5414   unica         3              3       u       n       i       c       a\n",
       "5415   unico         3              3       u       n       i       c       o\n",
       "5416   urico         3              3       u       r       i       c       o\n",
       "5417   uteis         3              3       u       t       e       i       s\n",
       "5418   utero         3              3       u       t       e       r       o\n",
       "\n",
       "[5419 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caminho = 'br-utf8.csv'\n",
    "df = carrega_dataframe_csv(caminho)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16973ee7-6b99-4ba2-bdc4-284d3b2d3aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>n_vogais</th>\n",
       "      <th>vogais_unicas</th>\n",
       "      <th>letra_0</th>\n",
       "      <th>letra_1</th>\n",
       "      <th>letra_2</th>\n",
       "      <th>letra_3</th>\n",
       "      <th>letra_4</th>\n",
       "      <th>probabilidade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aarao</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>a</td>\n",
       "      <td>o</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abner</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acaia</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>i</td>\n",
       "      <td>a</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acker</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>k</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aires</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>i</td>\n",
       "      <td>r</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  palavra  n_vogais  vogais_unicas letra_0 letra_1 letra_2 letra_3 letra_4  \\\n",
       "0   aarao         4              2       a       a       r       a       o   \n",
       "1   abner         2              2       a       b       n       e       r   \n",
       "2   acaia         4              2       a       c       a       i       a   \n",
       "3   acker         2              2       a       c       k       e       r   \n",
       "4   aires         3              3       a       i       r       e       s   \n",
       "\n",
       "   probabilidade  \n",
       "0       0.000000  \n",
       "1       0.000000  \n",
       "2       0.000000  \n",
       "3       0.000000  \n",
       "4       0.000037  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['probabilidade'] = df.palavra.apply(lambda x: probabilidade(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36392896-9e43-4fe3-8c89-a4fb718be960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>n_vogais</th>\n",
       "      <th>vogais_unicas</th>\n",
       "      <th>letra_0</th>\n",
       "      <th>letra_1</th>\n",
       "      <th>letra_2</th>\n",
       "      <th>letra_3</th>\n",
       "      <th>letra_4</th>\n",
       "      <th>probabilidade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3048</th>\n",
       "      <td>minha</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>m</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>h</td>\n",
       "      <td>a</td>\n",
       "      <td>0.015834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4767</th>\n",
       "      <td>todos</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "      <td>o</td>\n",
       "      <td>d</td>\n",
       "      <td>o</td>\n",
       "      <td>s</td>\n",
       "      <td>0.015199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>disse</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>d</td>\n",
       "      <td>i</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>e</td>\n",
       "      <td>0.014956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>ainda</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "      <td>0.014731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3170</th>\n",
       "      <td>muito</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>m</td>\n",
       "      <td>u</td>\n",
       "      <td>i</td>\n",
       "      <td>t</td>\n",
       "      <td>o</td>\n",
       "      <td>0.013871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2302</th>\n",
       "      <td>geriu</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>g</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "      <td>i</td>\n",
       "      <td>u</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2303</th>\n",
       "      <td>germe</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>g</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "      <td>m</td>\n",
       "      <td>e</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2305</th>\n",
       "      <td>gesso</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>g</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>o</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2306</th>\n",
       "      <td>gesta</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>g</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5418</th>\n",
       "      <td>utero</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "      <td>o</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5419 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     palavra  n_vogais  vogais_unicas letra_0 letra_1 letra_2 letra_3 letra_4  \\\n",
       "3048   minha         2              2       m       i       n       h       a   \n",
       "4767   todos         2              1       t       o       d       o       s   \n",
       "1567   disse         2              2       d       i       s       s       e   \n",
       "298    ainda         3              2       a       i       n       d       a   \n",
       "3170   muito         3              3       m       u       i       t       o   \n",
       "...      ...       ...            ...     ...     ...     ...     ...     ...   \n",
       "2302   geriu         3              3       g       e       r       i       u   \n",
       "2303   germe         2              1       g       e       r       m       e   \n",
       "2305   gesso         2              2       g       e       s       s       o   \n",
       "2306   gesta         2              2       g       e       s       t       a   \n",
       "5418   utero         3              3       u       t       e       r       o   \n",
       "\n",
       "      probabilidade  \n",
       "3048       0.015834  \n",
       "4767       0.015199  \n",
       "1567       0.014956  \n",
       "298        0.014731  \n",
       "3170       0.013871  \n",
       "...             ...  \n",
       "2302       0.000000  \n",
       "2303       0.000000  \n",
       "2305       0.000000  \n",
       "2306       0.000000  \n",
       "5418       0.000000  \n",
       "\n",
       "[5419 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['probabilidade'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c72fa28-e310-4478-b8c5-93eee8691eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>n_vogais</th>\n",
       "      <th>vogais_unicas</th>\n",
       "      <th>letra_0</th>\n",
       "      <th>letra_1</th>\n",
       "      <th>letra_2</th>\n",
       "      <th>letra_3</th>\n",
       "      <th>letra_4</th>\n",
       "      <th>probabilidade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5367</th>\n",
       "      <td>aureo</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>a</td>\n",
       "      <td>u</td>\n",
       "      <td>r</td>\n",
       "      <td>e</td>\n",
       "      <td>o</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     palavra  n_vogais  vogais_unicas letra_0 letra_1 letra_2 letra_3 letra_4  \\\n",
       "5367   aureo         4              4       a       u       r       e       o   \n",
       "\n",
       "      probabilidade  \n",
       "5367       0.000037  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.palavra == 'aureo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5272f5e6-11d0-4c9e-8fc6-c4af629c8dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def conta_consoantes(palavra):\n",
    "    \n",
    "    contador = 0\n",
    "    vogais = 'bcdfghjklmnpqrstvxywz'\n",
    "    allowed = frozenset(vogais)\n",
    "    \n",
    "    for letra in palavra:\n",
    "        if letra in vogais:\n",
    "            contador += 1\n",
    "    consoantes_unicas = len(allowed.intersection(palavra))\n",
    "    \n",
    "    return consoantes_unicas, contador\n",
    "\n",
    "\n",
    "conta_consoantes('perde')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35c47074-ab1a-4c94-86ca-f1a0615ea8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conta_consoantes('arroz')[0]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae3957cc-f551-4452-9f01-4f7d7cb56fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>n_vogais</th>\n",
       "      <th>vogais_unicas</th>\n",
       "      <th>letra_0</th>\n",
       "      <th>letra_1</th>\n",
       "      <th>letra_2</th>\n",
       "      <th>letra_3</th>\n",
       "      <th>letra_4</th>\n",
       "      <th>probabilidade</th>\n",
       "      <th>n_consoantes</th>\n",
       "      <th>consoantes_unicas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aarao</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>a</td>\n",
       "      <td>o</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abner</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acaia</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>i</td>\n",
       "      <td>a</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acker</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>k</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aires</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>i</td>\n",
       "      <td>r</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5414</th>\n",
       "      <td>unica</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>n</td>\n",
       "      <td>i</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5415</th>\n",
       "      <td>unico</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>n</td>\n",
       "      <td>i</td>\n",
       "      <td>c</td>\n",
       "      <td>o</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5416</th>\n",
       "      <td>urico</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>r</td>\n",
       "      <td>i</td>\n",
       "      <td>c</td>\n",
       "      <td>o</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5417</th>\n",
       "      <td>uteis</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "      <td>i</td>\n",
       "      <td>s</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5418</th>\n",
       "      <td>utero</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "      <td>o</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5419 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     palavra  n_vogais  vogais_unicas letra_0 letra_1 letra_2 letra_3 letra_4  \\\n",
       "0      aarao         4              2       a       a       r       a       o   \n",
       "1      abner         2              2       a       b       n       e       r   \n",
       "2      acaia         4              2       a       c       a       i       a   \n",
       "3      acker         2              2       a       c       k       e       r   \n",
       "4      aires         3              3       a       i       r       e       s   \n",
       "...      ...       ...            ...     ...     ...     ...     ...     ...   \n",
       "5414   unica         3              3       u       n       i       c       a   \n",
       "5415   unico         3              3       u       n       i       c       o   \n",
       "5416   urico         3              3       u       r       i       c       o   \n",
       "5417   uteis         3              3       u       t       e       i       s   \n",
       "5418   utero         3              3       u       t       e       r       o   \n",
       "\n",
       "      probabilidade  n_consoantes  consoantes_unicas  \n",
       "0          0.000000             1                  1  \n",
       "1          0.000000             3                  3  \n",
       "2          0.000000             1                  1  \n",
       "3          0.000000             3                  3  \n",
       "4          0.000037             2                  2  \n",
       "...             ...           ...                ...  \n",
       "5414       0.001701             2                  2  \n",
       "5415       0.002150             2                  2  \n",
       "5416       0.000000             2                  2  \n",
       "5417       0.000112             2                  2  \n",
       "5418       0.000000             2                  2  \n",
       "\n",
       "[5419 rows x 11 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['n_consoantes'] = df.palavra.apply(lambda x: conta_consoantes(x)[1])\n",
    "df['consoantes_unicas'] = df.palavra.apply(lambda x: conta_consoantes(x)[0])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3cea8f4-9608-412c-b307-69ed74b11c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>n_vogais</th>\n",
       "      <th>vogais_unicas</th>\n",
       "      <th>letra_0</th>\n",
       "      <th>letra_1</th>\n",
       "      <th>letra_2</th>\n",
       "      <th>letra_3</th>\n",
       "      <th>letra_4</th>\n",
       "      <th>probabilidade</th>\n",
       "      <th>n_consoantes</th>\n",
       "      <th>consoantes_unicas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3048</th>\n",
       "      <td>minha</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>m</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>h</td>\n",
       "      <td>a</td>\n",
       "      <td>0.015834</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     palavra  n_vogais  vogais_unicas letra_0 letra_1 letra_2 letra_3 letra_4  \\\n",
       "3048   minha         2              2       m       i       n       h       a   \n",
       "\n",
       "      probabilidade  n_consoantes  consoantes_unicas  \n",
       "3048       0.015834             3                  3  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.probabilidade == max(df.probabilidade)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ed431fe1-d8c8-4a31-8fd2-71717ac13b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>n_vogais</th>\n",
       "      <th>vogais_unicas</th>\n",
       "      <th>letra_0</th>\n",
       "      <th>letra_1</th>\n",
       "      <th>letra_2</th>\n",
       "      <th>letra_3</th>\n",
       "      <th>letra_4</th>\n",
       "      <th>probabilidade</th>\n",
       "      <th>n_consoantes</th>\n",
       "      <th>consoantes_unicas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4863</th>\n",
       "      <td>trens</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>s</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     palavra  n_vogais  vogais_unicas letra_0 letra_1 letra_2 letra_3 letra_4  \\\n",
       "4863   trens         1              1       t       r       e       n       s   \n",
       "\n",
       "      probabilidade  n_consoantes  consoantes_unicas  \n",
       "4863       0.000037             4                  4  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_teste = df.copy()\n",
    "\n",
    "\n",
    "mask2 = df.consoantes_unicas == max(df.consoantes_unicas)\n",
    "df_teste = df_teste[mask2]\n",
    "\n",
    "mask1 = df_teste.probabilidade == max(df_teste.probabilidade)\n",
    "df_teste[mask1]\n",
    "#df.loc[mask1 & mask2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8c5b9742-956f-441c-a73c-4be14dbdf778",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorteia_palavra(df):\n",
    "    if len(df) == 1:\n",
    "        return df.palavra.values.tolist()[0]\n",
    "    else:\n",
    "        mask_letras_diferentes = df.n_letras_diferentes == max(df.n_letras_diferentes)\n",
    "        df = df[mask_letras_diferentes]\n",
    "        mask_consoantes = df.consoantes_unicas == max(df.consoantes_unicas)\n",
    "        df = df[mask_consoantes]\n",
    "        return df.palavra[df.probabilidade == max(df.probabilidade)].values.tolist()[0]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "973b37e9-80b3-4f0d-9925-fe953ef7fd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trens\n"
     ]
    }
   ],
   "source": [
    "print(sorteia_palavra(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4122feea-b082-4777-8280-6068c14bc512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>n_vogais</th>\n",
       "      <th>vogais_unicas</th>\n",
       "      <th>letra_0</th>\n",
       "      <th>letra_1</th>\n",
       "      <th>letra_2</th>\n",
       "      <th>letra_3</th>\n",
       "      <th>letra_4</th>\n",
       "      <th>probabilidade</th>\n",
       "      <th>n_consoantes</th>\n",
       "      <th>consoantes_unicas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>beber</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    palavra  n_vogais  vogais_unicas letra_0 letra_1 letra_2 letra_3 letra_4  \\\n",
       "748   beber         2              1       b       e       b       e       r   \n",
       "\n",
       "     probabilidade  n_consoantes  consoantes_unicas  \n",
       "748       0.000262             3                  2  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.palavra == 'beber']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "df07e8e9-ae39-4793-a70c-3dfd478d5668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>n_vogais</th>\n",
       "      <th>vogais_unicas</th>\n",
       "      <th>letra_0</th>\n",
       "      <th>letra_1</th>\n",
       "      <th>letra_2</th>\n",
       "      <th>letra_3</th>\n",
       "      <th>letra_4</th>\n",
       "      <th>probabilidade</th>\n",
       "      <th>n_consoantes</th>\n",
       "      <th>consoantes_unicas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4044</th>\n",
       "      <td>rever</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>r</td>\n",
       "      <td>e</td>\n",
       "      <td>v</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     palavra  n_vogais  vogais_unicas letra_0 letra_1 letra_2 letra_3 letra_4  \\\n",
       "4044   rever         2              1       r       e       v       e       r   \n",
       "\n",
       "      probabilidade  n_consoantes  consoantes_unicas  \n",
       "4044            0.0             3                  2  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.palavra == 'rever']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce56aac-01ce-4f6b-b84d-3a3f82daa76e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b645839-57de-456a-b04f-4b3b7f660b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "teste = df[df.probabilidade == max(df.probabilidade)]\n",
    "print(len(teste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dd621492-cbc1-4eb2-8cbf-a7e1e3d48dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minha\n"
     ]
    }
   ],
   "source": [
    "df.palavra.values.tolist()\n",
    "print(teste.palavra.values.tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dbb57145-6068-4c4a-9d2a-872c3f5a6ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trens'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorteia_palavra(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f9df84d4-2a5b-4974-b710-ac61ab9dbd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('br-utf8_prob.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9ccc757a-81cf-4abf-8677-f208c4a18b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>n_vogais</th>\n",
       "      <th>vogais_unicas</th>\n",
       "      <th>letra_0</th>\n",
       "      <th>letra_1</th>\n",
       "      <th>letra_2</th>\n",
       "      <th>letra_3</th>\n",
       "      <th>letra_4</th>\n",
       "      <th>probabilidade</th>\n",
       "      <th>n_consoantes</th>\n",
       "      <th>consoantes_unicas</th>\n",
       "      <th>n_letras_diferentes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aarao</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>a</td>\n",
       "      <td>o</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abner</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acaia</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>i</td>\n",
       "      <td>a</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acker</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>k</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aires</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>i</td>\n",
       "      <td>r</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5414</th>\n",
       "      <td>unica</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>n</td>\n",
       "      <td>i</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5415</th>\n",
       "      <td>unico</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>n</td>\n",
       "      <td>i</td>\n",
       "      <td>c</td>\n",
       "      <td>o</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5416</th>\n",
       "      <td>urico</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>r</td>\n",
       "      <td>i</td>\n",
       "      <td>c</td>\n",
       "      <td>o</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5417</th>\n",
       "      <td>uteis</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "      <td>i</td>\n",
       "      <td>s</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5418</th>\n",
       "      <td>utero</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "      <td>o</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5419 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     palavra  n_vogais  vogais_unicas letra_0 letra_1 letra_2 letra_3 letra_4  \\\n",
       "0      aarao         4              2       a       a       r       a       o   \n",
       "1      abner         2              2       a       b       n       e       r   \n",
       "2      acaia         4              2       a       c       a       i       a   \n",
       "3      acker         2              2       a       c       k       e       r   \n",
       "4      aires         3              3       a       i       r       e       s   \n",
       "...      ...       ...            ...     ...     ...     ...     ...     ...   \n",
       "5414   unica         3              3       u       n       i       c       a   \n",
       "5415   unico         3              3       u       n       i       c       o   \n",
       "5416   urico         3              3       u       r       i       c       o   \n",
       "5417   uteis         3              3       u       t       e       i       s   \n",
       "5418   utero         3              3       u       t       e       r       o   \n",
       "\n",
       "      probabilidade  n_consoantes  consoantes_unicas  n_letras_diferentes  \n",
       "0          0.000000             1                  1                    3  \n",
       "1          0.000000             3                  3                    5  \n",
       "2          0.000000             1                  1                    3  \n",
       "3          0.000000             3                  3                    5  \n",
       "4          0.000037             2                  2                    5  \n",
       "...             ...           ...                ...                  ...  \n",
       "5414       0.001701             2                  2                    5  \n",
       "5415       0.002150             2                  2                    5  \n",
       "5416       0.000000             2                  2                    5  \n",
       "5417       0.000112             2                  2                    5  \n",
       "5418       0.000000             2                  2                    5  \n",
       "\n",
       "[5419 rows x 12 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caminho = 'br-utf8_prob.csv'\n",
    "df = carrega_dataframe_csv(caminho)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3d38d942-89ed-4157-a21d-fe9f8bbd733d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>n_vogais</th>\n",
       "      <th>vogais_unicas</th>\n",
       "      <th>letra_0</th>\n",
       "      <th>letra_1</th>\n",
       "      <th>letra_2</th>\n",
       "      <th>letra_3</th>\n",
       "      <th>letra_4</th>\n",
       "      <th>probabilidade</th>\n",
       "      <th>n_consoantes</th>\n",
       "      <th>consoantes_unicas</th>\n",
       "      <th>n_letras_diferentes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aarao</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>a</td>\n",
       "      <td>o</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abner</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acaia</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>i</td>\n",
       "      <td>a</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acker</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>k</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aires</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>i</td>\n",
       "      <td>r</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5414</th>\n",
       "      <td>unica</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>n</td>\n",
       "      <td>i</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5415</th>\n",
       "      <td>unico</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>n</td>\n",
       "      <td>i</td>\n",
       "      <td>c</td>\n",
       "      <td>o</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5416</th>\n",
       "      <td>urico</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>r</td>\n",
       "      <td>i</td>\n",
       "      <td>c</td>\n",
       "      <td>o</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5417</th>\n",
       "      <td>uteis</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "      <td>i</td>\n",
       "      <td>s</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5418</th>\n",
       "      <td>utero</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "      <td>o</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5419 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     palavra  n_vogais  vogais_unicas letra_0 letra_1 letra_2 letra_3 letra_4  \\\n",
       "0      aarao         4              2       a       a       r       a       o   \n",
       "1      abner         2              2       a       b       n       e       r   \n",
       "2      acaia         4              2       a       c       a       i       a   \n",
       "3      acker         2              2       a       c       k       e       r   \n",
       "4      aires         3              3       a       i       r       e       s   \n",
       "...      ...       ...            ...     ...     ...     ...     ...     ...   \n",
       "5414   unica         3              3       u       n       i       c       a   \n",
       "5415   unico         3              3       u       n       i       c       o   \n",
       "5416   urico         3              3       u       r       i       c       o   \n",
       "5417   uteis         3              3       u       t       e       i       s   \n",
       "5418   utero         3              3       u       t       e       r       o   \n",
       "\n",
       "      probabilidade  n_consoantes  consoantes_unicas  n_letras_diferentes  \n",
       "0          0.000000             1                  1                    3  \n",
       "1          0.000000             3                  3                    5  \n",
       "2          0.000000             1                  1                    3  \n",
       "3          0.000000             3                  3                    5  \n",
       "4          0.000037             2                  2                    5  \n",
       "...             ...           ...                ...                  ...  \n",
       "5414       0.001701             2                  2                    5  \n",
       "5415       0.002150             2                  2                    5  \n",
       "5416       0.000000             2                  2                    5  \n",
       "5417       0.000112             2                  2                    5  \n",
       "5418       0.000000             2                  2                    5  \n",
       "\n",
       "[5419 rows x 12 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['n_letras_diferentes'] = df.palavra.apply(lambda x: letras_diferentes(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "19b792f1-f7ef-4cfe-ae62-73ed879a240c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tes\n",
      "(2, 3)\n",
      "(1, 2)\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "def tira_duplicadas_palavra(s): #removendo as duplicadas da string\n",
    "    d = OrderedDict()\n",
    "    for c in s:\n",
    "        if c not in d:\n",
    "            d[c] = 0\n",
    "        d[c] += 1\n",
    "\n",
    "    return ''.join(d.keys())\n",
    "\n",
    "palavra = 'teste'\n",
    "\n",
    "print(tira_duplicadas_palavra(palavra))\n",
    "print(conta_consoantes(palavra))\n",
    "print(conta_vogais(palavra))\n",
    "\n",
    "def letras_diferentes(palavra):\n",
    "    return len(tira_duplicadas_palavra(palavra))\n",
    "\n",
    "print(letras_diferentes(palavra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "314bdd95-61c8-4b8b-b3e9-d02763e037cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>n_vogais</th>\n",
       "      <th>vogais_unicas</th>\n",
       "      <th>letra_0</th>\n",
       "      <th>letra_1</th>\n",
       "      <th>letra_2</th>\n",
       "      <th>letra_3</th>\n",
       "      <th>letra_4</th>\n",
       "      <th>probabilidade</th>\n",
       "      <th>n_consoantes</th>\n",
       "      <th>consoantes_unicas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aarao</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>a</td>\n",
       "      <td>o</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abner</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acker</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>k</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aires</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>i</td>\n",
       "      <td>r</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>alair</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>l</td>\n",
       "      <td>a</td>\n",
       "      <td>i</td>\n",
       "      <td>r</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5419</th>\n",
       "      <td>unica</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>n</td>\n",
       "      <td>i</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5420</th>\n",
       "      <td>unico</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>n</td>\n",
       "      <td>i</td>\n",
       "      <td>c</td>\n",
       "      <td>o</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5421</th>\n",
       "      <td>urico</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>r</td>\n",
       "      <td>i</td>\n",
       "      <td>c</td>\n",
       "      <td>o</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5422</th>\n",
       "      <td>uteis</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "      <td>i</td>\n",
       "      <td>s</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>utero</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "      <td>o</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4515 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     palavra  n_vogais  vogais_unicas letra_0 letra_1 letra_2 letra_3 letra_4  \\\n",
       "0      aarao         4              2       a       a       r       a       o   \n",
       "1      abner         2              2       a       b       n       e       r   \n",
       "3      acker         2              2       a       c       k       e       r   \n",
       "4      aires         3              3       a       i       r       e       s   \n",
       "5      alair         3              2       a       l       a       i       r   \n",
       "...      ...       ...            ...     ...     ...     ...     ...     ...   \n",
       "5419   unica         3              3       u       n       i       c       a   \n",
       "5420   unico         3              3       u       n       i       c       o   \n",
       "5421   urico         3              3       u       r       i       c       o   \n",
       "5422   uteis         3              3       u       t       e       i       s   \n",
       "5423   utero         3              3       u       t       e       r       o   \n",
       "\n",
       "      probabilidade  n_consoantes  consoantes_unicas  \n",
       "0          0.000000             1                  1  \n",
       "1          0.000000             3                  3  \n",
       "3          0.000000             3                  3  \n",
       "4          0.000000             2                  2  \n",
       "5          0.000000             2                  2  \n",
       "...             ...           ...                ...  \n",
       "5419       0.000761             2                  2  \n",
       "5420       0.000856             2                  2  \n",
       "5421       0.000000             2                  2  \n",
       "5422       0.000190             2                  2  \n",
       "5423       0.000000             2                  2  \n",
       "\n",
       "[4515 rows x 11 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consoantes_mais_usadas = 'srndm'\n",
    "\n",
    "lista = []\n",
    "\n",
    "for indice in consoantes_mais_usadas:\n",
    "    lista.append(indice)\n",
    "\n",
    "\n",
    "\n",
    "mask = df.letra_0.isin(lista) | df.letra_1.isin(lista) | df.letra_2.isin(lista) | df.letra_3.isin(lista) | df.letra_4.isin(lista)\n",
    "df = df.loc[mask,:]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790d212d-94c1-49ab-94d1-d01d1ea66d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90c02238-937c-4a02-8ada-ea2d26f1e7cc",
   "metadata": {},
   "source": [
    "# proximo passo seria pegar todas as palavras que mandou pro site e guardar tbm, pra tentar gerar um machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521b66d2-9308-41b2-a0cf-c5d77279ab74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
