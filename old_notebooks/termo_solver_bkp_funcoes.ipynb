{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76a0546c-f598-47c8-a42a-e652ced2eed0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'palavras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-485eaeabf26b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'palavras_termo.txt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mpalavra\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpalavras\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mpalavra\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'done'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'palavras' is not defined"
     ]
    }
   ],
   "source": [
    "#não executar, apenas mandar para o final para adicionar palavras\n",
    "\n",
    "with open('palavras_termo.txt','w', encoding = 'utf8') as f:\n",
    "    for palavra in palavras:\n",
    "        f.write(\"%s\\n\" % palavra)\n",
    "    print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7132831-2596-4988-b452-3e2c7fefe03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d06071b-33eb-4030-b147-ad8e308a11bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "\n",
    "def remove_acentos(string):\n",
    "    normalized = unicodedata.normalize('NFD', string)\n",
    "    return re.sub(r'[\\u0300-\\u036f]', '', normalized).casefold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cef58651-0443-4b2b-b9e6-776a747e551e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def conta_vogais(palavra):\n",
    "    \n",
    "    contador = 0\n",
    "    vogais = 'aeiouAEIOU'\n",
    "    allowed = frozenset('aeiouAEIOU')\n",
    "    \n",
    "    for letra in palavra:\n",
    "        if letra in vogais:\n",
    "            contador += 1\n",
    "    vogais_unicas = len(allowed.intersection(palavra))\n",
    "    \n",
    "    return vogais_unicas, contador\n",
    "\n",
    "\n",
    "conta_vogais('perde')    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7aedb45-776a-4e46-bc2f-b4ba89cd5c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b2c9b38-cec9-4582-83e4-fd8cd28da1ba",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>n_vogais</th>\n",
       "      <th>vogais_unicas</th>\n",
       "      <th>letra_0</th>\n",
       "      <th>letra_1</th>\n",
       "      <th>letra_2</th>\n",
       "      <th>letra_3</th>\n",
       "      <th>letra_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aarao</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>a</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abner</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acaia</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>i</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acker</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>k</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aires</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>i</td>\n",
       "      <td>r</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  palavra  n_vogais  vogais_unicas letra_0 letra_1 letra_2 letra_3 letra_4\n",
       "0   aarao         4              2       a       a       r       a       o\n",
       "1   abner         2              2       a       b       n       e       r\n",
       "2   acaia         4              2       a       c       a       i       a\n",
       "3   acker         2              2       a       c       k       e       r\n",
       "4   aires         3              3       a       i       r       e       s"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavras = []\n",
    "file = open('br-utf8.txt', 'r', encoding = 'utf8')\n",
    "\n",
    "while True:\n",
    "    line = file.readline()\n",
    "    palavra = line.strip().replace('\\n','')\n",
    "    if not line:\n",
    "        break\n",
    "    if len(palavra) == 5:\n",
    "        #print(palavra)\n",
    "        palavras.append(remove_acentos(palavra))\n",
    "        \n",
    "\n",
    "file.close()\n",
    "\n",
    "\n",
    "#nesse caso não tem a palavra lermo, então vamos remover da lista e rodar novamente\n",
    "#criar uma função para quando isso acontecer e criar uma lista das palavras que o termo não aceita!\n",
    "#assim podemos ir melhorando o algoritmo\n",
    "\n",
    "palavras.remove('lermo')\n",
    "palavras.remove('canaa')\n",
    "palavras.remove('propo')\n",
    "palavras.remove('coemo')\n",
    "palavras.remove('doemo')\n",
    "palavras.remove('jobim')\n",
    "palavras.remove('sorta')\n",
    "palavras.remove('suamo')\n",
    "\n",
    "\n",
    "#print(len(palavras))\n",
    "df = pd.DataFrame(palavras)\n",
    "df.drop_duplicates(inplace = True)\n",
    "df.rename(columns = {0:'palavra'}, inplace = True)\n",
    "\n",
    "df['n_vogais'] = df['palavra'].apply(lambda x: conta_vogais(x)[1])\n",
    "df['vogais_unicas'] = df['palavra'].apply(lambda x: conta_vogais(x)[0])\n",
    "\n",
    "\n",
    "df['letra_0'] = df.palavra.str[0]\n",
    "df['letra_1'] = df.palavra.str[1]\n",
    "df['letra_2'] = df.palavra.str[2]\n",
    "df['letra_3'] = df.palavra.str[3]\n",
    "df['letra_4'] = df.palavra.str[4]\n",
    "df.to_csv('br-utf8.csv', index = False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8d265966-b087-4ffe-b0a6-acc92d0eba62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('br-utf8.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298de44e-f959-4301-b5e3-48a02f97d458",
   "metadata": {},
   "source": [
    "# Função de sortear palavra\n",
    "estou usando esse metodo até criar um esquema de pontuação para as palavras\n",
    "\n",
    "(depois necessário criação de CSV com a pontuação e todo a manipulação de dados, para que no final só fique o filtro!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "5779b679-f337-4f5b-9dac-5162af556538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def sorteia_palavra(lista_palavra):\n",
    "    if len(lista_palavra) == 1:\n",
    "        return lista_palavra[0]\n",
    "    else:\n",
    "        return lista_palavra[random.randint(0,(len(lista_palavra)-1))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1b50be42-1f6e-4e41-9826-aaa769d98205",
   "metadata": {},
   "outputs": [],
   "source": [
    "melhores_palavras_para_vogais = df[df.vogais_unicas == 4]\n",
    "#escolher entre essas palavras para começar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096783d1-7512-448f-bc5e-b3777ca768d8",
   "metadata": {},
   "source": [
    "# Startando o termoo no navegador\n",
    "aqui seria onde comecei a entender como fazer a busca pela palavra e tentar criar alguma metrica pra achar letras nas strings\n",
    "\n",
    "\n",
    "como proceder com palavras que tem letras repetidas?\n",
    "\n",
    "aqui podemos fazer uma condição para cada posição estar com a letra certa\n",
    "\n",
    "\n",
    "while pos1 == wrongletter or pos2 == wrongletter or pos3 == wrongletter or pos4 == wrongletter or pos5 == wrongletter\n",
    "\n",
    "e ir lupando nas tentativas que temos, que aparentemente são 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "624ea126-5249-4682-945a-263416987904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>n_vogais</th>\n",
       "      <th>vogais_unicas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3628</th>\n",
       "      <td>nervo</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     palavra  n_vogais  vogais_unicas\n",
       "3628   nervo         2              2"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.palavra == 'nervo',:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57b1cce-c97a-4d0a-baf4-d8597743f6d5",
   "metadata": {},
   "source": [
    "esse é o pensamento inicial, depois que começar o scraping no site e inserção poderemos saber quando acertarmos a posição da letra. \n",
    "\n",
    "Quando isso acontecer será necessário trocar essa função para adicionar só palavras com letra naquela posição!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06d5c81-a004-4f56-b605-425da49b8d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebd0f0fd-d727-4cdb-884d-5066872b9656",
   "metadata": {},
   "source": [
    "teoricamente aqui conseguimos resolver mais ou menos o termo, agora é pesquisar novas metricas e testar nos outros dias, melhorando o filtro e a seleção, também seria legal rankear as palavras mais comuns e ver se conseguimos gerar um peso de palavras\n",
    "\n",
    "- trabalhar em melhorar as funções e como elas vão conversar entre elas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c9d779-6dad-4e5a-a35a-1b4146739f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed93c68-50a1-4697-8f75-6a0ffa551167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87564c1f-35e5-4071-969e-f525cf9a661f",
   "metadata": {},
   "source": [
    "-----------------------------\n",
    "\n",
    "Palavras excluidas do dicionario baixado da usp:\n",
    "- lermo\n",
    "- canaa\n",
    "- propo\n",
    "- coemo\n",
    "- doemo\n",
    "- jobim\n",
    "- suamo\n",
    "- sorta\n",
    "\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b86e270-c5cd-4cb8-af85-f8e845e3a35e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2eb7fe-ba8d-494e-8200-0dfbd38587d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c56e5132-6226-416d-b799-8cd6282690a1",
   "metadata": {},
   "source": [
    "# Organizando todas as funções!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90599355-6ded-400f-a2cd-211071b1670e",
   "metadata": {},
   "source": [
    "- Carregar o DF\n",
    "- listar as palavras melhroes rankeadas para começar o jogo\n",
    "- iniciar o jogo\n",
    "- escolher uma palavra da lista de mais rankeadas\n",
    "- mandar a primeira palavra para o jogo\n",
    "- retornar dicionario de resultado da primeira palavra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae70994-f1e8-4aed-9495-052ad7fa178b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a56624c9-c69d-473d-b12e-8a3c346152f0",
   "metadata": {},
   "source": [
    "## Core Functions - Analitics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13f12b3c-4503-4681-908f-81ca26e699cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def carrega_dataframe_csv(caminho):\n",
    "    return pd.read_csv(caminho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b821920d-d48e-4ebd-8757-0287af60ef13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def sorteia_palavra(lista_palavra):\n",
    "    if len(lista_palavra) == 1:\n",
    "        return lista_palavra[0]\n",
    "    else:\n",
    "        return lista_palavra[random.randint(0,(len(lista_palavra)-1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91100f28-3d22-46f1-8e59-18b2da0c3677",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recebe lista de letra e posicao correta\n",
    "#lista_exemplo = ['letra',posicao]\n",
    "\n",
    "def letra_na_posicao(lista_letra_correta, df):\n",
    "    \n",
    "    if len(lista_letra_correta) == 0:\n",
    "        return df\n",
    "    else:\n",
    "        for letra, posicao in lista_letra_correta:\n",
    "            if posicao == 0:\n",
    "                mask = df.letra_0 == letra\n",
    "                df = df.loc[mask,:]\n",
    "            elif posicao == 1:\n",
    "                mask = df.letra_1 == letra\n",
    "                df = df.loc[mask,:]\n",
    "            elif posicao == 2:\n",
    "                mask = df.letra_2 == letra\n",
    "                df = df.loc[mask,:]\n",
    "            elif posicao == 3:\n",
    "                mask = df.letra_3 == letra\n",
    "                df = df.loc[mask,:]\n",
    "            elif posicao == 4:\n",
    "                mask = df.letra_4 == letra\n",
    "                df = df.loc[mask,:]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcc4a317-bbd5-4fdb-8c64-9daecacf88f9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#lista_de_letras_com_posicao = [['g',2]] --- exemplo\n",
    "#provavelmente será necessário criar uma função que descompacte o dicionario que retorna do site em uma lista com listas\n",
    "\n",
    "def palavras_com_letra_posicao_errada_antiga(lista_de_letras_com_posicao, df):   \n",
    "    lista = []\n",
    "    for indice1,indice2 in lista_de_letras_com_posicao:\n",
    "        lista.append(indice1)\n",
    "        \n",
    "        condicao = indice2\n",
    "        if condicao == 0:\n",
    "            mask = df.letra_1.isin(lista) | df.letra_2.isin(lista) | df.letra_3.isin(lista) | df.letra_4.isin(lista)\n",
    "            df = df.loc[mask,:]\n",
    "        elif condicao == 1:\n",
    "            mask = df.letra_0.isin(lista) | df.letra_2.isin(lista) | df.letra_3.isin(lista) | df.letra_4.isin(lista) \n",
    "            df = df.loc[mask,:]\n",
    "        elif condicao == 2:\n",
    "            mask = df.letra_0.isin(lista) | df.letra_1.isin(lista) | df.letra_3.isin(lista) | df.letra_4.isin(lista)\n",
    "            df = df.loc[mask,:]\n",
    "        elif condicao == 3:\n",
    "            mask = df.letra_0.isin(lista) | df.letra_1.isin(lista) | df.letra_2.isin(lista) | df.letra_4.isin(lista)\n",
    "            df = df.loc[mask,:]\n",
    "        elif condicao == 4:\n",
    "            mask = df.letra_0.isin(lista) | df.letra_1.isin(lista) | df.letra_2.isin(lista) | df.letra_3.isin(lista)\n",
    "            df = df.loc[mask,:]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c1f52bf-de42-436e-9d69-a84462e7a155",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "#https://www.tutorialspoint.com/program-to-remove-duplicate-characters-from-a-given-string-in-python\n",
    "def tira_duplicadas_palavra(s): #removendo as duplicadas da string\n",
    "    d = OrderedDict()\n",
    "    for c in s:\n",
    "        if c not in d:\n",
    "            d[c] = 0\n",
    "        d[c] += 1\n",
    "\n",
    "    return ''.join(d.keys())\n",
    "\n",
    "def confere_letras_nas_palavras(palavra, letras_desejadas): \n",
    "    #aqui uma simples checagem se as cada letra da palavra está em letras desejadas (letras)\n",
    "    contador = 0\n",
    "    reduzido = tira_duplicadas_palavra(palavra)\n",
    "    \n",
    "    for letra in tira_duplicadas_palavra(palavra):\n",
    "        if (letra in letras_desejadas): #condicional para que se tiver na palavra some 1 ao contador\n",
    "            contador += 1\n",
    "\n",
    "#     'pavor' = tira_duplicadas => 'pavor'\n",
    "#     'aro' = tira duplicadas => 'aro'\n",
    "#     len(aro) = 3\n",
    "#     contador = 3\n",
    "\n",
    "    if (contador == len(tira_duplicadas_palavra(letras_desejadas))): \n",
    "        #se for verdadeiro o tamanho das letras_desejadas com o numero do contador\n",
    "        \n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "        \n",
    "\n",
    "def palavras_com_letra_posicao_errada(lista_de_letras_com_posicao, df):\n",
    "    letras = ''\n",
    "    for letra,posicao in lista_de_letras_com_posicao:\n",
    "        letras += letra\n",
    "\n",
    "        if posicao == 0:\n",
    "            mask = (df.letra_0 != letra)\n",
    "            df = df.loc[mask,:]\n",
    "        elif posicao == 1:\n",
    "            mask = (df.letra_1 != letra)\n",
    "            df = df.loc[mask,:]\n",
    "        elif posicao == 2:\n",
    "            mask = (df.letra_2 != letra)\n",
    "            df = df.loc[mask,:]\n",
    "        elif posicao == 3:\n",
    "            mask = (df.letra_3 != letra)\n",
    "            df = df.loc[mask,:]\n",
    "        elif posicao == 4:\n",
    "            mask = (df.letra_4 != letra)\n",
    "            df = df.loc[mask,:]\n",
    "\n",
    "    return df[df.palavra.apply(lambda x: confere_letras_nas_palavras(x, letras))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "084b0616-3cd4-4ac0-9cc5-3d6971eb1433",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def aaaaaaa(letras, df):\n",
    "    lista = []\n",
    "    \n",
    "    if len(letras) > 1:\n",
    "        for i in letras:\n",
    "            lista.append(i)\n",
    "        mask = ~df.letra_0.isin(lista) & ~df.letra_1.isin(lista) & ~df.letra_2.isin(lista) & ~df.letra_3.isin(lista) & ~df.letra_4.isin(lista)\n",
    "    else:\n",
    "        mask = (df.letra_0 != letras) & (df.letra_1 != letras) & (df.letra_2 != letras) & (df.letra_3 != letras) & (df.letra_4 != letras)\n",
    "\n",
    "    return df.loc[mask,:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3111acc2-8d47-4df2-8408-5d29dbe55f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def letras_nao_aceitas(letras, df, letras_aceitas):\n",
    "    lista = []\n",
    "\n",
    "\n",
    "    for letra, indice,status_letras_aceitas in letras:\n",
    "        if status_letras_aceitas == False:\n",
    "            lista.append(letra)\n",
    "        else:\n",
    "            mask = df[f'letra_{indice}'] != letra\n",
    "            df = df.loc[mask,:]\n",
    "\n",
    "        if len(lista) > 0:\n",
    "            mask = ~df.letra_0.isin(lista) & ~df.letra_1.isin(lista) & ~df.letra_2.isin(lista) & ~df.letra_3.isin(lista) & ~df.letra_4.isin(lista)    \n",
    "            df = df.loc[mask,:]\n",
    "        \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "af0862a3-fc8c-4e4f-ae9e-d6bacdc9a4de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def aaaaaa(letras, df):\n",
    "    for letra, indice in letras:\n",
    "        mask = df[f'letra_{indice}'] != letra\n",
    "        df = df.loc[mask,:]\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "9c986075-5f7a-4d3c-991e-9eeb38e0f8b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>n_vogais</th>\n",
       "      <th>vogais_unicas</th>\n",
       "      <th>letra_0</th>\n",
       "      <th>letra_1</th>\n",
       "      <th>letra_2</th>\n",
       "      <th>letra_3</th>\n",
       "      <th>letra_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aarao</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>a</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abner</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acaia</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>i</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acker</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>k</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aires</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>i</td>\n",
       "      <td>r</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  palavra  n_vogais  vogais_unicas letra_0 letra_1 letra_2 letra_3 letra_4\n",
       "0   aarao         4              2       a       a       r       a       o\n",
       "1   abner         2              2       a       b       n       e       r\n",
       "2   acaia         4              2       a       c       a       i       a\n",
       "3   acker         2              2       a       c       k       e       r\n",
       "4   aires         3              3       a       i       r       e       s"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caminho = 'br-utf8.csv'\n",
    "\n",
    "df = carrega_dataframe_csv(caminho)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "78a19f4a-8e59-4128-a2c9-5323d3764a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "0\n",
      "True\n",
      "e\n",
      "3\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>n_vogais</th>\n",
       "      <th>vogais_unicas</th>\n",
       "      <th>letra_0</th>\n",
       "      <th>letra_1</th>\n",
       "      <th>letra_2</th>\n",
       "      <th>letra_3</th>\n",
       "      <th>letra_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bagda</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bangu</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>borba</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>bruno</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>r</td>\n",
       "      <td>u</td>\n",
       "      <td>n</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>carla</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>l</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5412</th>\n",
       "      <td>umida</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>m</td>\n",
       "      <td>i</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5413</th>\n",
       "      <td>umido</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>m</td>\n",
       "      <td>i</td>\n",
       "      <td>d</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5414</th>\n",
       "      <td>unica</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>n</td>\n",
       "      <td>i</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5415</th>\n",
       "      <td>unico</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>n</td>\n",
       "      <td>i</td>\n",
       "      <td>c</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5416</th>\n",
       "      <td>urico</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>r</td>\n",
       "      <td>i</td>\n",
       "      <td>c</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2683 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     palavra  n_vogais  vogais_unicas letra_0 letra_1 letra_2 letra_3 letra_4\n",
       "17     bagda         2              1       b       a       g       d       a\n",
       "18     bangu         2              2       b       a       n       g       u\n",
       "24     borba         2              2       b       o       r       b       a\n",
       "25     bruno         2              2       b       r       u       n       o\n",
       "26     carla         2              1       c       a       r       l       a\n",
       "...      ...       ...            ...     ...     ...     ...     ...     ...\n",
       "5412   umida         3              3       u       m       i       d       a\n",
       "5413   umido         3              3       u       m       i       d       o\n",
       "5414   unica         3              3       u       n       i       c       a\n",
       "5415   unico         3              3       u       n       i       c       o\n",
       "5416   urico         3              3       u       r       i       c       o\n",
       "\n",
       "[2683 rows x 8 columns]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letra_n = [('a',0,True),('e',3,False)]\n",
    "letras_aceitas = 'a'\n",
    "lista = []\n",
    "\n",
    "\n",
    "for letra, indice,status_letras_aceitas in letra_n:\n",
    "    print(letra)\n",
    "    print(indice)\n",
    "    print(status_letras_aceitas)\n",
    "    if status_letras_aceitas == False:\n",
    "        lista.append(letra)\n",
    "    else:\n",
    "        mask = df[f'letra_{indice}'] != letra\n",
    "        df = df.loc[mask,:]\n",
    "\n",
    "    if len(lista) > 0:\n",
    "        mask = ~df.letra_0.isin(lista) & ~df.letra_1.isin(lista) & ~df.letra_2.isin(lista) & ~df.letra_3.isin(lista) & ~df.letra_4.isin(lista)    \n",
    "        df = df.loc[mask,:]\n",
    "        \n",
    "df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "5f3a083b-de0c-4a7c-9df8-9683ee186d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>n_vogais</th>\n",
       "      <th>vogais_unicas</th>\n",
       "      <th>letra_0</th>\n",
       "      <th>letra_1</th>\n",
       "      <th>letra_2</th>\n",
       "      <th>letra_3</th>\n",
       "      <th>letra_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bagda</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bangu</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>carla</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>l</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>catia</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>t</td>\n",
       "      <td>i</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>darci</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>c</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5287</th>\n",
       "      <td>zanza</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>z</td>\n",
       "      <td>a</td>\n",
       "      <td>n</td>\n",
       "      <td>z</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5289</th>\n",
       "      <td>zanzo</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>z</td>\n",
       "      <td>a</td>\n",
       "      <td>n</td>\n",
       "      <td>z</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5290</th>\n",
       "      <td>zarpa</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>z</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>p</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5292</th>\n",
       "      <td>zarpo</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>z</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>p</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5387</th>\n",
       "      <td>iamos</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>i</td>\n",
       "      <td>a</td>\n",
       "      <td>m</td>\n",
       "      <td>o</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>758 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     palavra  n_vogais  vogais_unicas letra_0 letra_1 letra_2 letra_3 letra_4\n",
       "17     bagda         2              1       b       a       g       d       a\n",
       "18     bangu         2              2       b       a       n       g       u\n",
       "26     carla         2              1       c       a       r       l       a\n",
       "33     catia         3              2       c       a       t       i       a\n",
       "36     darci         2              2       d       a       r       c       i\n",
       "...      ...       ...            ...     ...     ...     ...     ...     ...\n",
       "5287   zanza         2              1       z       a       n       z       a\n",
       "5289   zanzo         2              2       z       a       n       z       o\n",
       "5290   zarpa         2              1       z       a       r       p       a\n",
       "5292   zarpo         2              2       z       a       r       p       o\n",
       "5387   iamos         3              3       i       a       m       o       s\n",
       "\n",
       "[758 rows x 8 columns]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.letra_1 == 'a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "946b96ad-afe0-4e24-9a28-19a6d715d891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>n_vogais</th>\n",
       "      <th>vogais_unicas</th>\n",
       "      <th>letra_0</th>\n",
       "      <th>letra_1</th>\n",
       "      <th>letra_2</th>\n",
       "      <th>letra_3</th>\n",
       "      <th>letra_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3535</th>\n",
       "      <td>pavor</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>p</td>\n",
       "      <td>a</td>\n",
       "      <td>v</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     palavra  n_vogais  vogais_unicas letra_0 letra_1 letra_2 letra_3 letra_4\n",
       "3535   pavor         2              2       p       a       v       o       r"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.palavra == 'pavor']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28f3dd7-79b1-42b9-8f70-d26ee827e618",
   "metadata": {},
   "source": [
    "## Scraping functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b6b9c30-e673-43c9-ae3f-46fd3088d7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.edge.service import Service\n",
    "#com a mudança pro selenium 4.0, algumas coisas mudaram ao inicializar, por exemplo o uso do Service\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6262a14-a714-4c40-9f59-93ea19d2e704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a868a92-e7e5-4a82-a4ef-ef602a4f9d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inicializand o site\n",
    "def inicializa_termo():\n",
    "    service = Service(executable_path = './edg_drv/msedgedriver.exe') #mudança do selenium 4.0\n",
    "    driver = webdriver.Edge(service=service)\n",
    "\n",
    "    urlpage = 'https://term.ooo/'\n",
    "    response = driver.get(urlpage)\n",
    "    driver.implicitly_wait(5)\n",
    "\n",
    "    x_path = '/html/body/wc-modal'\n",
    "    ajuda_sempre_aberta = driver.find_element('xpath',x_path)\n",
    "    ajuda_sempre_aberta.click()\n",
    "    driver.implicitly_wait(5)\n",
    "    return driver\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3306c326-cb70-4b8e-a032-99ad9fc5d14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#envia palavra\n",
    "from time import sleep\n",
    "\n",
    "def envia_palavra(palavra_sorteada):\n",
    "    x_path_board = '/html/body'\n",
    "    board_inicial = driver.find_element('xpath',x_path_board)\n",
    "    for letra in palavra_sorteada:\n",
    "        board_inicial.send_keys(letra)\n",
    "        #board_inicial.implicitly_wait(3)#testar, se não funcionar voltar para -> driver.implicitly_wait(0.5)\n",
    "        sleep(1)\n",
    "\n",
    "    \n",
    "    board_inicial.send_keys(Keys.ENTER)\n",
    "    #board_inicial.implicitly_wait(5)\n",
    "    sleep(3)\n",
    "    #print('palavra-enviada')#apenas pra finalidades de teste, retirar depois\n",
    "    \n",
    "def apaga_palavra():\n",
    "    x_path_board = '/html/body'\n",
    "    board_inicial = driver.find_element('xpath',x_path_board)\n",
    "\n",
    "    for i in range(5):\n",
    "        board_inicial.send_keys(Keys.BACKSPACE)\n",
    "        sleep(0.5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "520ba9e9-aca9-418a-bacf-354db921ad7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retorna dicionario da tentiva de palavra enviada\n",
    "# elemento_do_board = '[id=\"board0\"]'\n",
    "\n",
    "# shadow = driver.find_element(By.CSS_SELECTOR, elemento_do_board).shadow_root\n",
    "\n",
    "#ainda pensando se vale a pena colocar como variavel global mesmo ou deixar dentro da função\n",
    "\n",
    "def retorna_dicionario_respostas(variavel): #variavel = numero da tentativa\n",
    "\n",
    "    elemento_do_board = '[id=\"board0\"]'\n",
    "\n",
    "    shadow = driver.find_element(By.CSS_SELECTOR, elemento_do_board).shadow_root\n",
    "    letra = ''\n",
    "    resposta = ''\n",
    "    \n",
    "    \n",
    "    lista_da_palavra = [] #inicializa a lista\n",
    "    elemento_primeira_linha_interno_para_shadow = f'[aria-label=\"palavra {variavel}\"]'\n",
    "    inner_shadow = shadow.find_element(By.CSS_SELECTOR, elemento_primeira_linha_interno_para_shadow).shadow_root\n",
    "\n",
    "\n",
    "    for variavel in range(5):\n",
    "        elemento_primeira_letra = f'[termo-pos=\"{str(variavel)}\"]'\n",
    "        elemento_html = inner_shadow.find_element(By.CSS_SELECTOR, elemento_primeira_letra)\n",
    "        resposta = elemento_html.get_attribute('class')\n",
    "        letra = remove_acentos(elemento_html.text.lower())\n",
    "        if resposta != 'letter empty':\n",
    "            lista_da_palavra.append((resposta, letra))\n",
    "\n",
    "\n",
    "    return dict(zip(range(len(lista_da_palavra)), lista_da_palavra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "89d62c35-87ec-4653-8a4d-bb7e056b9d57",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def descompacta_dicionario_antigo(dicionario, letras_aceitas):\n",
    "\n",
    "    letras_erradas = ''\n",
    "    letras_lugar_errado = []\n",
    "    letras_corretas = []\n",
    "\n",
    "    for item in dicionario:\n",
    "        letra = remove_acentos(dicionario[item][1]).lower()\n",
    "        condicao = letra in letras_aceitas\n",
    "        if dicionario[item][0] == 'letter wrong' and not(condicao):\n",
    "            letras_erradas += str(dicionario[item][1])\n",
    "        elif dicionario[item][0] == 'letter place':\n",
    "            letras_aceitas += letra\n",
    "            letras_lugar_errado.append([dicionario[item][1], item])\n",
    "        elif dicionario[item][0] == 'letter right':\n",
    "            letras_aceitas += letra\n",
    "            letras_corretas.append([dicionario[item][1], item])\n",
    "            \n",
    "    return letras_erradas, letras_lugar_errado, letras_corretas, letras_aceitas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d02142-7ef9-4837-8a8a-9e408b3868db",
   "metadata": {},
   "source": [
    "aqui foi necessário fazer varios for, pra primeiro:\n",
    "- adicionar as letras aceitas e corretas nos lugares\n",
    "- adicionar as letras em lugares errados\n",
    "- adicionar letras erradas\n",
    "\n",
    "isso se deu ao motivo de muitas vezes terem letras repetidas e o site reconhecer uma letra aceita como não aceita!\n",
    "\n",
    "\n",
    "### isso pode parar de ocorrer se eu parar de lidar com as letras erradas e trabalhar do mesmo jeito das outras!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3155ad91-b9b5-40a7-a958-91778a4eb962",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aqui foi necessário fazer varios for, pra primeiro\n",
    "\n",
    "def descompacta_dicionario(dicionario, letras_aceitas):\n",
    "\n",
    "    letras_erradas = []\n",
    "    letras_lugar_errado = []\n",
    "    letras_corretas = []\n",
    "\n",
    "    #primeiro sempre adicionando as letras corretas!\n",
    "    for item in dicionario:\n",
    "        letra = remove_acentos(dicionario[item][1]).lower()\n",
    "        condicao = letra in letras_aceitas\n",
    "        if dicionario[item][0] == 'letter right':\n",
    "            letras_aceitas += letra\n",
    "            letras_corretas.append((dicionario[item][1], item))\n",
    "\n",
    "    #adicionando as letras corretas mas em posição errada!\n",
    "    for item in dicionario:\n",
    "        letra = remove_acentos(dicionario[item][1]).lower()\n",
    "        condicao = letra in letras_aceitas        \n",
    "        if dicionario[item][0] == 'letter place':\n",
    "            letras_aceitas += letra\n",
    "            letras_lugar_errado.append((dicionario[item][1], item))\n",
    "            \n",
    "    #e só por fim adicionar as letras erradas a equação    \n",
    "    for item in dicionario:\n",
    "        letra = remove_acentos(dicionario[item][1]).lower()\n",
    "        condicao = letra in letras_aceitas\n",
    "        if dicionario[item][0] == 'letter wrong':\n",
    "            if dicionario[item][1] in letras_aceitas:\n",
    "                letras_erradas.append((dicionario[item][1], item, True))\n",
    "                #retornando true se a letra errada está na lista de letras aceitas\n",
    "            else: \n",
    "                letras_erradas.append((dicionario[item][1], item, False))\n",
    "                #retornando false se a letra errada está na lista de letras aceitas\n",
    "    #será necessário criar uma condição só pra letra não aceita + letra aceita por causa do erro do site!\n",
    "            \n",
    "            \n",
    "            \n",
    "    return letras_erradas, letras_lugar_errado, letras_corretas, letras_aceitas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "9803f91e-0713-4301-aa44-855cc9f42e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('u', 1), ('e', 3)]\n",
      "[('a', 0), ('r', 2), ('o', 4)]\n",
      "[]\n",
      "aro\n"
     ]
    }
   ],
   "source": [
    "letras_aceitas = ''\n",
    "\n",
    "dicionario = {0: ('letter place', 'a'), 1: ('letter wrong', 'u'), 2: ('letter place', 'r'), 3: ('letter wrong', 'e'), 4: ('letter place', 'o')}\n",
    "\n",
    "letras_erradas, letras_lugar_errado, letras_corretas, letras_aceitas = descompacta_dicionario(dicionario, letras_aceitas)\n",
    "\n",
    "print(letras_erradas)\n",
    "print(letras_lugar_errado)\n",
    "print(letras_corretas)\n",
    "print(letras_aceitas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "c5151bb9-e610-48d0-9b18-47bcdca4b18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('u', 1), ('e', 3)]\n",
      "[('a', 0), ('r', 2), ('o', 4)]\n",
      "[]\n",
      "aroaro\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>n_vogais</th>\n",
       "      <th>vogais_unicas</th>\n",
       "      <th>letra_0</th>\n",
       "      <th>letra_1</th>\n",
       "      <th>letra_2</th>\n",
       "      <th>letra_3</th>\n",
       "      <th>letra_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bagda</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bangu</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>borba</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>carla</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>l</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>catia</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>t</td>\n",
       "      <td>i</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5402</th>\n",
       "      <td>orfao</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>f</td>\n",
       "      <td>a</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5403</th>\n",
       "      <td>orfas</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>f</td>\n",
       "      <td>a</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5404</th>\n",
       "      <td>orgao</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>g</td>\n",
       "      <td>a</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5407</th>\n",
       "      <td>otica</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>o</td>\n",
       "      <td>t</td>\n",
       "      <td>i</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5409</th>\n",
       "      <td>otima</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>o</td>\n",
       "      <td>t</td>\n",
       "      <td>i</td>\n",
       "      <td>m</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1738 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     palavra  n_vogais  vogais_unicas letra_0 letra_1 letra_2 letra_3 letra_4\n",
       "17     bagda         2              1       b       a       g       d       a\n",
       "18     bangu         2              2       b       a       n       g       u\n",
       "24     borba         2              2       b       o       r       b       a\n",
       "26     carla         2              1       c       a       r       l       a\n",
       "33     catia         3              2       c       a       t       i       a\n",
       "...      ...       ...            ...     ...     ...     ...     ...     ...\n",
       "5402   orfao         3              2       o       r       f       a       o\n",
       "5403   orfas         2              2       o       r       f       a       s\n",
       "5404   orgao         3              2       o       r       g       a       o\n",
       "5407   otica         3              3       o       t       i       c       a\n",
       "5409   otima         3              3       o       t       i       m       a\n",
       "\n",
       "[1738 rows x 8 columns]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_teste, letras_aceitas, letras_erradas, letras_lugar_errado, letras_corretas = filtra_df_2(dicionario, df, letras_aceitas)\n",
    "print(letras_erradas)\n",
    "print(letras_lugar_errado)\n",
    "print(letras_corretas)\n",
    "print(letras_aceitas)\n",
    "\n",
    "df_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "fc4eb63e-fa72-4254-8af7-6179873201c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 0), ('r', 2), ('o', 4)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>n_vogais</th>\n",
       "      <th>vogais_unicas</th>\n",
       "      <th>letra_0</th>\n",
       "      <th>letra_1</th>\n",
       "      <th>letra_2</th>\n",
       "      <th>letra_3</th>\n",
       "      <th>letra_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aarao</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>a</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acaia</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>i</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>alair</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>l</td>\n",
       "      <td>a</td>\n",
       "      <td>i</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>amapa</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>m</td>\n",
       "      <td>a</td>\n",
       "      <td>p</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>babel</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>e</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5403</th>\n",
       "      <td>orfas</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>f</td>\n",
       "      <td>a</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5404</th>\n",
       "      <td>orgao</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>g</td>\n",
       "      <td>a</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5405</th>\n",
       "      <td>ossea</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>o</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>e</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5407</th>\n",
       "      <td>otica</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>o</td>\n",
       "      <td>t</td>\n",
       "      <td>i</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5409</th>\n",
       "      <td>otima</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>o</td>\n",
       "      <td>t</td>\n",
       "      <td>i</td>\n",
       "      <td>m</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2676 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     palavra  n_vogais  vogais_unicas letra_0 letra_1 letra_2 letra_3 letra_4\n",
       "0      aarao         4              2       a       a       r       a       o\n",
       "2      acaia         4              2       a       c       a       i       a\n",
       "5      alair         3              2       a       l       a       i       r\n",
       "10     amapa         3              1       a       m       a       p       a\n",
       "16     babel         2              2       b       a       b       e       l\n",
       "...      ...       ...            ...     ...     ...     ...     ...     ...\n",
       "5403   orfas         2              2       o       r       f       a       s\n",
       "5404   orgao         3              2       o       r       g       a       o\n",
       "5405   ossea         3              3       o       s       s       e       a\n",
       "5407   otica         3              3       o       t       i       c       a\n",
       "5409   otima         3              3       o       t       i       m       a\n",
       "\n",
       "[2676 rows x 8 columns]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(letras_lugar_errado)\n",
    "df_teste = palavras_com_letra_posicao_errada(letras_lugar_errado, df)\n",
    "df_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b56cf5c-b4eb-401c-9cfa-dd88f51281de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtra_df_2(dicionario, df, letras_aceitas):\n",
    "#         envia_palavra(palavra_sorteada)\n",
    "\n",
    "#         #pegar informações da palavra enviada\n",
    "#         dicionario = retorna_dicionario_respostas(tentativa)\n",
    "\n",
    "        #retornar resultado das letras\n",
    "        letras_erradas, letras_lugar_errado, letras_corretas, letras_aceitas = descompacta_dicionario(dicionario, letras_aceitas)\n",
    "        \n",
    "        df = letras_nao_aceitas(letras_erradas, df, letras_aceitas)\n",
    "        df = palavras_com_letra_posicao_errada(letras_lugar_errado, df)\n",
    "        df = letra_na_posicao(letras_corretas, df)\n",
    "        \n",
    "        \n",
    "        return df, letras_aceitas, letras_erradas, letras_lugar_errado, letras_corretas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "df75a697-e52e-44c6-b742-a5d4b47b388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "de1e8a0b-1ab8-4336-8af6-7e50d4114eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 0), ('r', 2), ('o', 4)]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letras_lugar_errado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "ba559256-5fa4-406b-85cd-e0a3353f7a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "0\n",
      "r\n",
      "2\n",
      "o\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>n_vogais</th>\n",
       "      <th>vogais_unicas</th>\n",
       "      <th>letra_0</th>\n",
       "      <th>letra_1</th>\n",
       "      <th>letra_2</th>\n",
       "      <th>letra_3</th>\n",
       "      <th>letra_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>babel</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>e</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bagda</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bangu</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>belem</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "      <td>e</td>\n",
       "      <td>l</td>\n",
       "      <td>e</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ceara</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "      <td>e</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5407</th>\n",
       "      <td>otica</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>o</td>\n",
       "      <td>t</td>\n",
       "      <td>i</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5409</th>\n",
       "      <td>otima</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>o</td>\n",
       "      <td>t</td>\n",
       "      <td>i</td>\n",
       "      <td>m</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5412</th>\n",
       "      <td>umida</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>m</td>\n",
       "      <td>i</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5414</th>\n",
       "      <td>unica</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>n</td>\n",
       "      <td>i</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5417</th>\n",
       "      <td>uteis</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "      <td>i</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3402 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     palavra  n_vogais  vogais_unicas letra_0 letra_1 letra_2 letra_3 letra_4\n",
       "16     babel         2              2       b       a       b       e       l\n",
       "17     bagda         2              1       b       a       g       d       a\n",
       "18     bangu         2              2       b       a       n       g       u\n",
       "19     belem         2              1       b       e       l       e       m\n",
       "27     ceara         3              2       c       e       a       r       a\n",
       "...      ...       ...            ...     ...     ...     ...     ...     ...\n",
       "5407   otica         3              3       o       t       i       c       a\n",
       "5409   otima         3              3       o       t       i       m       a\n",
       "5412   umida         3              3       u       m       i       d       a\n",
       "5414   unica         3              3       u       n       i       c       a\n",
       "5417   uteis         3              3       u       t       e       i       s\n",
       "\n",
       "[3402 rows x 8 columns]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_teste = df.copy()\n",
    "\n",
    "lista = []\n",
    "letras = ''\n",
    "for letra,posicao in letras_lugar_errado:\n",
    "    print(letra)\n",
    "    print(posicao)\n",
    "    lista.append(letra)\n",
    "    letras += letra\n",
    "\n",
    "    condicao = posicao\n",
    "    if condicao == 0:\n",
    "        mask = df_teste.letra_0 != letra\n",
    "        df_teste = df_teste.loc[mask,:]\n",
    "    elif condicao == 1:\n",
    "        mask = df_teste.letra_1 != letra\n",
    "        df_teste = df_teste.loc[mask,:]\n",
    "    elif condicao == 2:\n",
    "        mask = df_teste.letra_2 != letra\n",
    "        df_teste = df_teste.loc[mask,:]\n",
    "    elif condicao == 3:\n",
    "        mask = df_teste.letra_3 != letra\n",
    "        df_teste = df_teste.loc[mask,:]\n",
    "    elif condicao == 4:\n",
    "        mask = df_teste.letra_4 != letra\n",
    "        df_teste = df_teste.loc[mask,:]\n",
    "        \n",
    "        \n",
    "        \n",
    "df_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "1e53d8a6-2a5d-4296-b642-e399be39f0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>n_vogais</th>\n",
       "      <th>vogais_unicas</th>\n",
       "      <th>letra_0</th>\n",
       "      <th>letra_1</th>\n",
       "      <th>letra_2</th>\n",
       "      <th>letra_3</th>\n",
       "      <th>letra_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3535</th>\n",
       "      <td>pavor</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>p</td>\n",
       "      <td>a</td>\n",
       "      <td>v</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     palavra  n_vogais  vogais_unicas letra_0 letra_1 letra_2 letra_3 letra_4\n",
       "3535   pavor         2              2       p       a       v       o       r"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_teste[df_teste.palavra == 'pavor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "3ad171b8-7136-4761-985c-7515efbf76a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>n_vogais</th>\n",
       "      <th>vogais_unicas</th>\n",
       "      <th>letra_0</th>\n",
       "      <th>letra_1</th>\n",
       "      <th>letra_2</th>\n",
       "      <th>letra_3</th>\n",
       "      <th>letra_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3402</th>\n",
       "      <td>orara</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     palavra  n_vogais  vogais_unicas letra_0 letra_1 letra_2 letra_3 letra_4\n",
       "3402   orara         3              2       o       r       a       r       a"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_teste[df_teste.palavra.apply(lambda x: contem_apenas_aro(x,letras))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "aced0157-129a-4c74-b2a4-9b0a260bfbd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aro'"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "bcf44204-ec17-40fc-9e53-5e0bf70c977e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pavor'"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_teste[df_teste.palavra == 'pavor'].iloc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "4a5c0714-cf0c-4eb7-b690-158172cd4497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste = df_teste[df_teste.palavra == 'pavor'].iloc[0][0]\n",
    "letras in teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "872c4e75-1af0-4734-a548-3deedb78160c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['p', 'a', 'v', 'o', 'r']"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_pavor = []\n",
    "for i in teste:\n",
    "    lista_pavor.append(i)\n",
    "    \n",
    "lista_pavor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "19cdab60-1bd5-4e51-9dcb-4f6b6ea138e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for i in teste:\n",
    "    print(i in letras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "50181424-cfd1-4ea3-b750-65e8d9e732e8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "#https://www.tutorialspoint.com/program-to-remove-duplicate-characters-from-a-given-string-in-python\n",
    "def tira_duplicadas_palavra(s): #removendo as duplicadas da string\n",
    "    d = OrderedDict()\n",
    "    for c in s:\n",
    "        if c not in d:\n",
    "            d[c] = 0\n",
    "        d[c] += 1\n",
    "\n",
    "    return ''.join(d.keys())\n",
    "\n",
    "\n",
    "# contador = 0\n",
    "# for i in tira_duplicadas_palavra(teste):\n",
    "#     if (i in letras):\n",
    "#         contador += 1\n",
    "\n",
    "# print(contador == len(letras))\n",
    "\n",
    "def confere_letras_nas_palavras(palavra, letras_desejadas): \n",
    "    #aqui uma simples checagem se as cada letra da palavra está em letras desejadas (letras)\n",
    "    contador = 0\n",
    "    reduzido = tira_duplicadas_palavra(palavra)\n",
    "    \n",
    "    for letra in tira_duplicadas_palavra(palavra):\n",
    "        if (letra in letras_desejadas): #condicional para que se tiver na palavra some 1 ao contador\n",
    "            contador += 1\n",
    "\"\"\"\n",
    "    'pavor' = tira_duplicadas => 'pavor'\n",
    "    'aro' = tira duplicadas => 'aro'\n",
    "    len(aro) = 3\n",
    "    contador = 3\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    if (contador == len(tira_duplicadas_palavra(letras_desejadas))): \n",
    "        #se for verdadeiro o tamanho das letras_desejadas com o numero do contador\n",
    "        \n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "5797cb9d-bf22-429d-87f6-9534c4653531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confere_letras_nas_palavras('mamba','aro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "065864f2-1dfe-482b-9a18-e3834b78334a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>n_vogais</th>\n",
       "      <th>vogais_unicas</th>\n",
       "      <th>letra_0</th>\n",
       "      <th>letra_1</th>\n",
       "      <th>letra_2</th>\n",
       "      <th>letra_3</th>\n",
       "      <th>letra_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ramos</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>r</td>\n",
       "      <td>a</td>\n",
       "      <td>m</td>\n",
       "      <td>o</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>boiar</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>i</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>bolar</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>l</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>botar</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>broas</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>r</td>\n",
       "      <td>o</td>\n",
       "      <td>a</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5045</th>\n",
       "      <td>vapor</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>v</td>\n",
       "      <td>a</td>\n",
       "      <td>p</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5236</th>\n",
       "      <td>voara</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>v</td>\n",
       "      <td>o</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5255</th>\n",
       "      <td>votar</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>v</td>\n",
       "      <td>o</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5339</th>\n",
       "      <td>evora</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>e</td>\n",
       "      <td>v</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5403</th>\n",
       "      <td>orfas</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>f</td>\n",
       "      <td>a</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     palavra  n_vogais  vogais_unicas letra_0 letra_1 letra_2 letra_3 letra_4\n",
       "99     ramos         2              2       r       a       m       o       s\n",
       "807    boiar         3              3       b       o       i       a       r\n",
       "813    bolar         2              2       b       o       l       a       r\n",
       "838    botar         2              2       b       o       t       a       r\n",
       "874    broas         2              2       b       r       o       a       s\n",
       "...      ...       ...            ...     ...     ...     ...     ...     ...\n",
       "5045   vapor         2              2       v       a       p       o       r\n",
       "5236   voara         3              2       v       o       a       r       a\n",
       "5255   votar         2              2       v       o       t       a       r\n",
       "5339   evora         3              3       e       v       o       r       a\n",
       "5403   orfas         2              2       o       r       f       a       s\n",
       "\n",
       "[157 rows x 8 columns]"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letras = 'aro'\n",
    "df_teste[df_teste.palavra.apply(lambda x: confere_letras_nas_palavras(x, letras))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "2242cee0-5fa0-4263-9584-f1a5e9016c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letras in df_teste.palavra.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "b56fb414-a28b-4811-a2fc-e0d01edfb1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'r', 'o']"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3be17af-e356-4264-93dc-2bd1097a101b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "8952f940-4265-48eb-8489-4caff52f635f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>letra_1</th>\n",
       "      <th>letra_2</th>\n",
       "      <th>letra_3</th>\n",
       "      <th>letra_4</th>\n",
       "      <th>letra_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aro</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>o</td>\n",
       "      <td>a</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>orara</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  palavra letra_1 letra_2 letra_3 letra_4 letra_5\n",
       "0     aro       a       r       o       a       o\n",
       "6   orara       o       r       a       r       a"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['palavra'].str.contains('^[aro]*$')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2c909b-09d7-4f14-affa-5c028fe19c85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f98fad-b492-4c30-aa71-6445095ec751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10d548b4-162c-43cf-99bb-842d2fdb709c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#função que vai dizer se ta funcionando ou não\n",
    "def get_notificacao(palavra_sorteada, df, file, now, session_id, dicionario,tentativa):\n",
    "#def get_notificacao(palavra_sorteada, df):\n",
    "    vencedor = 'wc-notify'\n",
    "    notificacao = driver.find_element(By.CSS_SELECTOR, vencedor)\n",
    "    notificacao = notificacao.text\n",
    "    #print(notificacao)\n",
    "    terminou = True\n",
    "    if notificacao == '':\n",
    "        notificacao = 'palavra aceita'\n",
    "        terminou = True\n",
    "        \n",
    "        \n",
    "    elif notificacao == 'essa palavra não é aceita':\n",
    "        #file.write(f'{-1},{palavra_sorteada},{notificacao},{data},{session_id},{variavel_randomica},{dicionario}\\n')\n",
    "        #nesse ponto precisei meio que criar ela recursivamente, pra ir filtrando as palavras que não poderiamos colocar!\n",
    "        while terminou == True:\n",
    "            file.write(f'{-1},{palavra_sorteada},{notificacao},{data},{session_id},{variavel_randomica},{dicionario}\\n')\n",
    "            #aqui vai ter uma mini função, que talvez eu encapsule em outro lugar\n",
    "            df = df[df.palavra != palavra_sorteada]\n",
    "            palavra_sorteada = sorteia_palavra(df.palavra.values.tolist())\n",
    "\n",
    "            x_path_board = '/html/body'\n",
    "            board_inicial = driver.find_element('xpath',x_path_board)\n",
    "\n",
    "            for i in range(5):\n",
    "                board_inicial.send_keys(Keys.BACKSPACE)\n",
    "                sleep(1)\n",
    "\n",
    "            envia_palavra(palavra_sorteada)\n",
    "            dicionario = retorna_dicionario_respostas(tentativa)\n",
    "            letras_erradas, letras_lugar_errado, letras_corretas = retorna_resultado_tentativa_palavra(dicionario)\n",
    "\n",
    "            df = palavras_com_letra_posicao_errada(letras_lugar_errado, df)\n",
    "            df = letra_na_posicao(letras_corretas, df)\n",
    "            df = letras_nao_aceitas(letras_erradas, df)\n",
    "            \n",
    "            terminou, df, notificacao, palavra_sorteada = get_notificacao(palavra_sorteada, df, file, now, session_id,dicionario,tentativa)\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "    else:\n",
    "        terminou = False\n",
    "        \n",
    "    return terminou, df, notificacao, palavra_sorteada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d8f9fb-30eb-4528-84b4-0838bc05e3e3",
   "metadata": {},
   "source": [
    "FAZENDO UMA SEGUNDA VERSÃO DA FUNCAO ACIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebbfb4c0-d076-4e07-b86f-526d3b606187",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#função que vai dizer se ta funcionando ou não\n",
    "def get_notificacao(palavra_sorteada, df, file, now, session_id, dicionario,tentativa, letras_aceitas):\n",
    "#def get_notificacao(palavra_sorteada, df):\n",
    "    vencedor = 'wc-notify'\n",
    "    notificacao = driver.find_element(By.CSS_SELECTOR, vencedor)\n",
    "    notificacao = notificacao.text\n",
    "    #print(notificacao)\n",
    "    terminou = True\n",
    "    if notificacao == '':\n",
    "        notificacao = 'palavra aceita' #para input do resultados.txt\n",
    "        terminou = True\n",
    "        \n",
    "        \n",
    "    elif notificacao == 'essa palavra não é aceita':\n",
    "        terminou = False\n",
    "        #file.write(f'{-1},{palavra_sorteada},{notificacao},{data},{session_id},{variavel_randomica},{dicionario}\\n')\n",
    "        #nesse ponto precisei meio que criar ela recursivamente, pra ir filtrando as palavras que não poderiamos colocar!\n",
    "        while terminou == False:\n",
    "            \n",
    "            \n",
    "            #apagando palavra\n",
    "            apaga_palavra()\n",
    "            \n",
    "            \n",
    "            file.write(f'{-1},{palavra_sorteada},{notificacao},{data},{session_id},{variavel_randomica},{dicionario}\\n')\n",
    "            #aqui vai ter uma mini função, que talvez eu encapsule em outro lugar\n",
    "            df = df[df.palavra != palavra_sorteada].reset_index(drop=True)\n",
    "            palavra_sorteada = sorteia_palavra(df.palavra.values.tolist())\n",
    "            \n",
    "            #palavra_sorteada = sorteia_palavra(df.palavra)\n",
    "\n",
    "            envia_palavra(palavra_sorteada)\n",
    "\n",
    "            #pegar informações da palavra enviada\n",
    "            dicionario = retorna_dicionario_respostas(tentativa)\n",
    "            df, letras_aceitas = filtra_df(dicionario, df, letras_aceitas)\n",
    "#             print('-------- dentro do get_noficacao ------')\n",
    "#             print('palavra_sorteada: ',palavra_sorteada)\n",
    "#             print()\n",
    "#             print('dicionario: ', dicionario)\n",
    "#             print()\n",
    "#             print('letras_aceitas: ',letras_aceitas)\n",
    "#             print('tentativa: ', tentativa)\n",
    "#             print('-------- fim do get_noficacao ------')\n",
    "#             df.to_csv('debugando.csv')\n",
    "            #df, letras_aceitas = filtra_df(dicionario, df, letras_aceitas)\n",
    "            #df.to_csv('debugando.csv')\n",
    "            \n",
    "            #terminou, df, notificacao, palavra_sorteada = get_notificacao(palavra_sorteada, df, file, now, session_id,dicionario,tentativa, letras_aceitas)\n",
    "            terminou, df, notificacao, palavra_sorteada, letras_aceitas, tentativa = get_notificacao(palavra_sorteada, df, file, now, session_id, dicionario,tentativa, letras_aceitas)\n",
    "            #tentativa += 1 # foi o jeito de corrigir o erro, não sei como só isso resolveu, verificar deep dps\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "    else:\n",
    "        terminou = False\n",
    "        \n",
    "    return terminou, df, notificacao, palavra_sorteada, letras_aceitas, tentativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8804b7a-2f01-4c43-99c8-78073cd19da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_attempt(df):\n",
    "    melhores_palavras_para_vogais = df[df.vogais_unicas == 4]\n",
    "    #melhores_palavras_para_vogais = df[df.palavra == 'aureo']\n",
    "    #return sorteia_palavra(melhores_palavras_para_vogais.palavra.values.tolist())\n",
    "    return 'aureo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "4cf40bec-9395-4ab3-b797-76e9412a007b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtra_df(dicionario, df, letras_aceitas):\n",
    "#         envia_palavra(palavra_sorteada)\n",
    "\n",
    "#         #pegar informações da palavra enviada\n",
    "#         dicionario = retorna_dicionario_respostas(tentativa)\n",
    "\n",
    "        #retornar resultado das letras\n",
    "        letras_erradas, letras_lugar_errado, letras_corretas, letras_aceitas = descompacta_dicionario(dicionario, letras_aceitas)\n",
    "\n",
    "        df = palavras_com_letra_posicao_errada(letras_lugar_errado, df)\n",
    "        df = letra_na_posicao(letras_corretas, df)\n",
    "        df = letras_nao_aceitas(letras_erradas, df, letras_aceitas)\n",
    "        \n",
    "        return df, letras_aceitas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca99dd4f-510d-4588-8ec3-b3d323a674bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263414cb-2957-40c7-ab9c-eb3c405dba23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce83434-60ff-4ebb-8a8e-74cc2e14a5e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d478d6a-d379-4853-858c-d1bca9bc5c51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c81b624-1101-46c0-a0f0-c2217a82c52c",
   "metadata": {},
   "source": [
    "# NOVO BLOCO FINAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a56a4c-f5be-4f8a-9f54-1f95bc55c581",
   "metadata": {},
   "source": [
    "259 variavel_randomica que estava dando erro ontem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "73cddb24-3330-4ba1-86a9-7ed8fa0648d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n",
      "------------------------------------\n",
      "palavra sorteada:  aureo\n",
      "{0: ('letter place', 'a'), 1: ('letter wrong', 'u'), 2: ('letter place', 'r'), 3: ('letter wrong', 'e'), 4: ('letter place', 'o')}\n",
      "tentativa:  0\n",
      "letras erradas:  [('u', 1), ('e', 3)]\n",
      "letras lugar errado:  [('a', 0), ('r', 2), ('o', 4)]\n",
      "letras corretas:  []\n",
      "letras aceitas:  aro\n",
      "------------------------------------\n",
      "palavra sorteada:  rosca\n",
      "{0: ('letter place', 'r'), 1: ('letter place', 'o'), 2: ('letter wrong', 's'), 3: ('letter wrong', 'c'), 4: ('letter place', 'a')}\n",
      "tentativa:  1\n",
      "letras erradas:  [('s', 2), ('c', 3)]\n",
      "letras lugar errado:  [('r', 0), ('o', 1), ('a', 4)]\n",
      "letras corretas:  []\n",
      "letras aceitas:  aroroa\n",
      "------------------------------------\n",
      "palavra sorteada:  topar\n",
      "{0: ('letter wrong', 't'), 1: ('letter place', 'o'), 2: ('letter place', 'p'), 3: ('letter place', 'a'), 4: ('letter right', 'r')}\n",
      "tentativa:  2\n",
      "letras erradas:  [('t', 0)]\n",
      "letras lugar errado:  [('o', 1), ('p', 2), ('a', 3)]\n",
      "letras corretas:  [('r', 4)]\n",
      "letras aceitas:  aroroaropa\n",
      "------------------------------------\n",
      "palavra sorteada:  optar\n",
      "{0: ('letter place', 'o'), 1: ('letter place', 'p'), 2: ('letter wrong', 't'), 3: ('letter place', 'a'), 4: ('letter right', 'r')}\n",
      "tentativa:  3\n",
      "letras erradas:  [('t', 2)]\n",
      "letras lugar errado:  [('o', 0), ('p', 1), ('a', 3)]\n",
      "letras corretas:  [('r', 4)]\n",
      "letras aceitas:  aroroaroparopa\n",
      "------------------------------------\n",
      "palavra sorteada:  pavor\n",
      "{0: ('letter right done', 'p'), 1: ('letter right done', 'a'), 2: ('letter right done', 'v'), 3: ('letter right done', 'o'), 4: ('letter right done', 'r')}\n",
      "tentativa:  4\n",
      "letras erradas:  []\n",
      "letras lugar errado:  []\n",
      "letras corretas:  []\n",
      "letras aceitas:  aroroaroparopa\n"
     ]
    }
   ],
   "source": [
    "letras_aceitas = ''\n",
    "\n",
    "file = open('resultados.txt', 'a')\n",
    "\n",
    "caminho = 'br-utf8.csv'\n",
    "\n",
    "df = carrega_dataframe_csv(caminho)\n",
    "\n",
    "driver = inicializa_termo()\n",
    "\n",
    "\n",
    "terminou = True\n",
    "tentativa = 0\n",
    "\n",
    "now = datetime.now()\n",
    "data = now.strftime(\"%d/%m/%Y\")\n",
    "session_id = driver.session_id\n",
    "\n",
    "#só verificando o seed que foi gerado pra caso precisar replicar\n",
    "variavel_randomica = random.randint(0,1000)\n",
    "variavel_randomica = 92\n",
    "a = random.seed(variavel_randomica)\n",
    "print(variavel_randomica)\n",
    "\n",
    "#print('first')\n",
    "#pegando a primeira palavra\n",
    "palavra_sorteada = first_attempt(df)\n",
    "\n",
    "envia_palavra(palavra_sorteada)\n",
    "\n",
    "#pegar informações da palavra enviada\n",
    "dicionario = retorna_dicionario_respostas(tentativa)\n",
    "\n",
    "#print(palavra_sorteada)\n",
    "#df, letras_aceitas = filtra_df(dicionario, df, letras_aceitas)\n",
    "\n",
    "df, letras_aceitas, letras_erradas, letras_lugar_errado, letras_corretas = filtra_df_2(dicionario, df, letras_aceitas)\n",
    "\n",
    "#driver.implicitly_wait(10)\n",
    "sleep(1)\n",
    "print('------------------------------------')\n",
    "print('palavra sorteada: ',palavra_sorteada) \n",
    "print(dicionario)\n",
    "print('tentativa: ',tentativa)\n",
    "print('letras erradas: ', letras_erradas)\n",
    "print('letras lugar errado: ', letras_lugar_errado)\n",
    "print('letras corretas: ', letras_corretas)\n",
    "print('letras aceitas: ',letras_aceitas)\n",
    "\n",
    "tentativa += 1\n",
    "\n",
    "while terminou == True:\n",
    "    #driver.implicitly_wait(5)\n",
    "    #for tentativa in range(5):\n",
    "    #print(tentativa)\n",
    "\n",
    "    palavra_sorteada = sorteia_palavra(df.palavra.values.tolist())\n",
    "    #print(palavra_sorteada)\n",
    "\n",
    "    envia_palavra(palavra_sorteada)\n",
    "\n",
    "    #pegar informações da palavra enviada\n",
    "    dicionario = retorna_dicionario_respostas(tentativa)\n",
    "\n",
    "    #print(palavra_sorteada)\n",
    "    #df.to_csv('debugando.csv')\n",
    "    df, letras_aceitas, letras_erradas, letras_lugar_errado, letras_corretas = filtra_df_2(dicionario, df, letras_aceitas)\n",
    "    #driver.implicitly_wait(30)\n",
    "    sleep(1)\n",
    "\n",
    "        #terminou, df, notificacao, palavra_sorteada, letras_aceitas, tentativa = get_notificacao(palavra_sorteada, df, file, now, session_id, dicionario,tentativa, letras_aceitas)\n",
    "    print('------------------------------------')\n",
    "    print('palavra sorteada: ',palavra_sorteada) \n",
    "    print(dicionario)\n",
    "    \n",
    "    print('tentativa: ',tentativa)\n",
    "    print('letras erradas: ', letras_erradas)\n",
    "    print('letras lugar errado: ', letras_lugar_errado)\n",
    "    print('letras corretas: ', letras_corretas)\n",
    "    \n",
    "    print('letras aceitas: ',letras_aceitas)\n",
    "    terminou, df, notificacao, palavra_sorteada, letras_aceitas, tentativa = get_notificacao(palavra_sorteada, df, file, now, session_id, dicionario,tentativa, letras_aceitas)\n",
    "    \n",
    "    #file.write('tentativa,palavra,resultado,data,session_id\\n')\n",
    "    file.write(f'{tentativa},{palavra_sorteada},{notificacao},{data},{session_id},{variavel_randomica},{dicionario}\\n')\n",
    "    tentativa += 1\n",
    "    \n",
    "    if tentativa > 6:\n",
    "        terminou = False\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff852a0-7c29-4ee8-b6d0-0091a4599ce6",
   "metadata": {},
   "source": [
    "-----------------\n",
    "teste 2\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "e322f5db-4d7e-4111-9f5c-743fb5018310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "820\n",
      "------------------------------------\n",
      "palavra sorteada:  aureo\n",
      "{0: ('letter place', 'a'), 1: ('letter wrong', 'u'), 2: ('letter place', 'r'), 3: ('letter wrong', 'e'), 4: ('letter place', 'o')}\n",
      "tentativa:  0\n",
      "letras erradas:  [('u', 1), ('e', 3)]\n",
      "letras lugar errado:  [('a', 0), ('r', 2), ('o', 4)]\n",
      "letras corretas:  []\n",
      "letras aceitas:  aro\n",
      "------------------------------------\n",
      "palavra sorteada:  fuzis\n",
      "{0: ('letter wrong', 'f'), 1: ('letter wrong', 'u'), 2: ('letter wrong', 'z'), 3: ('letter wrong', 'i'), 4: ('letter wrong', 's')}\n",
      "tentativa:  1\n",
      "letras erradas:  [('f', 0), ('u', 1), ('z', 2), ('i', 3), ('s', 4)]\n",
      "letras lugar errado:  []\n",
      "letras corretas:  []\n",
      "letras aceitas:  aro\n",
      "------------------------------------\n",
      "palavra sorteada:  rocas\n",
      "{0: ('letter place', 'r'), 1: ('letter place', 'o'), 2: ('letter wrong', 'c'), 3: ('letter place', 'a'), 4: ('letter wrong', 's')}\n",
      "tentativa:  2\n",
      "letras erradas:  [('c', 2), ('s', 4)]\n",
      "letras lugar errado:  [('r', 0), ('o', 1), ('a', 3)]\n",
      "letras corretas:  []\n",
      "letras aceitas:  aroroa\n",
      "------------------------------------\n",
      "palavra sorteada:  tosar\n",
      "{0: ('letter wrong', 't'), 1: ('letter place', 'o'), 2: ('letter wrong', 's'), 3: ('letter place', 'a'), 4: ('letter right', 'r')}\n",
      "tentativa:  3\n",
      "letras erradas:  [('t', 0), ('s', 2)]\n",
      "letras lugar errado:  [('o', 1), ('a', 3)]\n",
      "letras corretas:  [('r', 4)]\n",
      "letras aceitas:  aroroaroa\n",
      "------------------------------------\n",
      "palavra sorteada:  sabor\n",
      "{0: ('letter wrong', 's'), 1: ('letter right', 'a'), 2: ('letter wrong', 'b'), 3: ('letter right', 'o'), 4: ('letter right', 'r')}\n",
      "tentativa:  4\n",
      "letras erradas:  [('s', 0), ('b', 2)]\n",
      "letras lugar errado:  []\n",
      "letras corretas:  [('a', 1), ('o', 3), ('r', 4)]\n",
      "letras aceitas:  aroroaroaaor\n",
      "------------------------------------\n",
      "palavra sorteada:  fator\n",
      "{0: ('letter wrong', 'f'), 1: ('letter right', 'a'), 2: ('letter wrong', 't'), 3: ('letter right', 'o'), 4: ('letter right', 'r')}\n",
      "tentativa:  5\n",
      "letras erradas:  [('f', 0), ('t', 2)]\n",
      "letras lugar errado:  []\n",
      "letras corretas:  [('a', 1), ('o', 3), ('r', 4)]\n",
      "letras aceitas:  aroroaroaaoraor\n"
     ]
    }
   ],
   "source": [
    "letras_aceitas = ''\n",
    "\n",
    "file = open('resultados.txt', 'a')\n",
    "\n",
    "caminho = 'br-utf8.csv'\n",
    "\n",
    "df = carrega_dataframe_csv(caminho)\n",
    "\n",
    "driver = inicializa_termo()\n",
    "\n",
    "\n",
    "terminou = True\n",
    "tentativa = 0\n",
    "\n",
    "now = datetime.now()\n",
    "data = now.strftime(\"%d/%m/%Y\")\n",
    "session_id = driver.session_id\n",
    "\n",
    "#só verificando o seed que foi gerado pra caso precisar replicar\n",
    "variavel_randomica = random.randint(0,1000)\n",
    "variavel_randomica = 820\n",
    "a = random.seed(variavel_randomica)\n",
    "print(variavel_randomica)\n",
    "\n",
    "#print('first')\n",
    "#pegando a primeira palavra\n",
    "palavra_sorteada = first_attempt(df)\n",
    "\n",
    "envia_palavra(palavra_sorteada)\n",
    "\n",
    "#pegar informações da palavra enviada\n",
    "dicionario = retorna_dicionario_respostas(tentativa)\n",
    "\n",
    "#print(palavra_sorteada)\n",
    "#df, letras_aceitas = filtra_df(dicionario, df, letras_aceitas)\n",
    "\n",
    "df, letras_aceitas, letras_erradas, letras_lugar_errado, letras_corretas = filtra_df_2(dicionario, df, letras_aceitas)\n",
    "\n",
    "#driver.implicitly_wait(10)\n",
    "sleep(1)\n",
    "print('------------------------------------')\n",
    "print('palavra sorteada: ',palavra_sorteada) \n",
    "print(dicionario)\n",
    "print('tentativa: ',tentativa)\n",
    "print('letras erradas: ', letras_erradas)\n",
    "print('letras lugar errado: ', letras_lugar_errado)\n",
    "print('letras corretas: ', letras_corretas)\n",
    "print('letras aceitas: ',letras_aceitas)\n",
    "df.to_csv('debugando.csv')\n",
    "\n",
    "tentativa += 1\n",
    "\n",
    "while terminou == True:\n",
    "    #driver.implicitly_wait(5)\n",
    "    #for tentativa in range(5):\n",
    "    #print(tentativa)\n",
    "\n",
    "    palavra_sorteada = sorteia_palavra(df.palavra.values.tolist())\n",
    "    #print(palavra_sorteada)\n",
    "\n",
    "    envia_palavra(palavra_sorteada)\n",
    "\n",
    "    #pegar informações da palavra enviada\n",
    "    dicionario = retorna_dicionario_respostas(tentativa)\n",
    "\n",
    "    #print(palavra_sorteada)\n",
    "    #df.to_csv('debugando.csv')\n",
    "    df, letras_aceitas, letras_erradas, letras_lugar_errado, letras_corretas = filtra_df_2(dicionario, df, letras_aceitas)\n",
    "    #driver.implicitly_wait(30)\n",
    "    sleep(1)\n",
    "\n",
    "        #terminou, df, notificacao, palavra_sorteada, letras_aceitas, tentativa = get_notificacao(palavra_sorteada, df, file, now, session_id, dicionario,tentativa, letras_aceitas)\n",
    "    print('------------------------------------')\n",
    "    print('palavra sorteada: ',palavra_sorteada) \n",
    "    print(dicionario)\n",
    "    \n",
    "    print('tentativa: ',tentativa)\n",
    "    print('letras erradas: ', letras_erradas)\n",
    "    print('letras lugar errado: ', letras_lugar_errado)\n",
    "    print('letras corretas: ', letras_corretas)\n",
    "    \n",
    "    print('letras aceitas: ',letras_aceitas)\n",
    "    terminou, df, notificacao, palavra_sorteada, letras_aceitas, tentativa = get_notificacao(palavra_sorteada, df, file, now, session_id, dicionario,tentativa, letras_aceitas)\n",
    "    \n",
    "    #file.write('tentativa,palavra,resultado,data,session_id\\n')\n",
    "    file.write(f'{tentativa},{palavra_sorteada},{notificacao},{data},{session_id},{variavel_randomica},{dicionario}\\n')\n",
    "    tentativa += 1\n",
    "    \n",
    "    if tentativa > 6:\n",
    "        terminou = False\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ddff5581-8561-4cd4-9fac-f21bc967547e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251\n",
      "------------------------------------\n",
      "palavra sorteada:  aureo\n",
      "{0: ('letter place', 'a'), 1: ('letter wrong', 'u'), 2: ('letter place', 'r'), 3: ('letter wrong', 'e'), 4: ('letter place', 'o')}\n",
      "tentativa:  0\n",
      "letras erradas:  [('u', 1, False), ('e', 3, False)]\n",
      "letras lugar errado:  [('a', 0), ('r', 2), ('o', 4)]\n",
      "letras corretas:  []\n",
      "letras aceitas:  aro\n",
      "------------------------------------\n",
      "palavra sorteada:  sogra\n",
      "{0: ('letter wrong', 's'), 1: ('letter place', 'o'), 2: ('letter wrong', 'g'), 3: ('letter place', 'r'), 4: ('letter place', 'a')}\n",
      "tentativa:  1\n",
      "letras erradas:  [('s', 0, False), ('g', 2, False)]\n",
      "letras lugar errado:  [('o', 1), ('r', 3), ('a', 4)]\n",
      "letras corretas:  []\n",
      "letras aceitas:  aroora\n",
      "------------------------------------\n",
      "palavra sorteada:  ornai\n",
      "{0: ('letter place', 'o'), 1: ('letter place', 'r'), 2: ('letter wrong', 'n'), 3: ('letter place', 'a'), 4: ('letter wrong', 'i')}\n",
      "tentativa:  2\n",
      "letras erradas:  [('n', 2, False), ('i', 4, False)]\n",
      "letras lugar errado:  [('o', 0), ('r', 1), ('a', 3)]\n",
      "letras corretas:  []\n",
      "letras aceitas:  arooraora\n",
      "------------------------------------\n",
      "palavra sorteada:  vapor\n",
      "{0: ('letter place', 'v'), 1: ('letter right', 'a'), 2: ('letter place', 'p'), 3: ('letter right', 'o'), 4: ('letter right', 'r')}\n",
      "tentativa:  3\n",
      "letras erradas:  []\n",
      "letras lugar errado:  [('v', 0), ('p', 2)]\n",
      "letras corretas:  [('a', 1), ('o', 3), ('r', 4)]\n",
      "letras aceitas:  arooraoraaorvp\n",
      "------------------------------------\n",
      "palavra sorteada:  pavor\n",
      "{0: ('letter right done', 'p'), 1: ('letter right done', 'a'), 2: ('letter right done', 'v'), 3: ('letter right done', 'o'), 4: ('letter right done', 'r')}\n",
      "tentativa:  4\n",
      "letras erradas:  []\n",
      "letras lugar errado:  []\n",
      "letras corretas:  []\n",
      "letras aceitas:  arooraoraaorvp\n"
     ]
    }
   ],
   "source": [
    "letras_aceitas = ''\n",
    "\n",
    "file = open('resultados.txt', 'a')\n",
    "\n",
    "caminho = 'br-utf8.csv'\n",
    "\n",
    "df = carrega_dataframe_csv(caminho)\n",
    "\n",
    "driver = inicializa_termo()\n",
    "\n",
    "\n",
    "terminou = True\n",
    "tentativa = 0\n",
    "\n",
    "now = datetime.now()\n",
    "data = now.strftime(\"%d/%m/%Y\")\n",
    "session_id = driver.session_id\n",
    "\n",
    "#só verificando o seed que foi gerado pra caso precisar replicar\n",
    "variavel_randomica = random.randint(0,1000)\n",
    "\n",
    "a = random.seed(variavel_randomica)\n",
    "print(variavel_randomica)\n",
    "\n",
    "#print('first')\n",
    "#pegando a primeira palavra\n",
    "palavra_sorteada = first_attempt(df)\n",
    "\n",
    "envia_palavra(palavra_sorteada)\n",
    "\n",
    "#pegar informações da palavra enviada\n",
    "dicionario = retorna_dicionario_respostas(tentativa)\n",
    "\n",
    "#print(palavra_sorteada)\n",
    "#df, letras_aceitas = filtra_df(dicionario, df, letras_aceitas)\n",
    "\n",
    "df, letras_aceitas, letras_erradas, letras_lugar_errado, letras_corretas = filtra_df_2(dicionario, df, letras_aceitas)\n",
    "\n",
    "#driver.implicitly_wait(10)\n",
    "sleep(1)\n",
    "print('------------------------------------')\n",
    "print('palavra sorteada: ',palavra_sorteada) \n",
    "print(dicionario)\n",
    "print('tentativa: ',tentativa)\n",
    "print('letras erradas: ', letras_erradas)\n",
    "print('letras lugar errado: ', letras_lugar_errado)\n",
    "print('letras corretas: ', letras_corretas)\n",
    "print('letras aceitas: ',letras_aceitas)\n",
    "df.to_csv('debugando.csv')\n",
    "\n",
    "tentativa += 1\n",
    "\n",
    "while terminou == True:\n",
    "    #driver.implicitly_wait(5)\n",
    "    #for tentativa in range(5):\n",
    "    #print(tentativa)\n",
    "\n",
    "    palavra_sorteada = sorteia_palavra(df.palavra.values.tolist())\n",
    "    #print(palavra_sorteada)\n",
    "\n",
    "    envia_palavra(palavra_sorteada)\n",
    "\n",
    "    #pegar informações da palavra enviada\n",
    "    dicionario = retorna_dicionario_respostas(tentativa)\n",
    "\n",
    "    #print(palavra_sorteada)\n",
    "    #df.to_csv('debugando.csv')\n",
    "    df, letras_aceitas, letras_erradas, letras_lugar_errado, letras_corretas = filtra_df_2(dicionario, df, letras_aceitas)\n",
    "    #driver.implicitly_wait(30)\n",
    "    sleep(1)\n",
    "\n",
    "        #terminou, df, notificacao, palavra_sorteada, letras_aceitas, tentativa = get_notificacao(palavra_sorteada, df, file, now, session_id, dicionario,tentativa, letras_aceitas)\n",
    "    print('------------------------------------')\n",
    "    print('palavra sorteada: ',palavra_sorteada) \n",
    "    print(dicionario)\n",
    "\n",
    "    print('tentativa: ',tentativa)\n",
    "    print('letras erradas: ', letras_erradas)\n",
    "    print('letras lugar errado: ', letras_lugar_errado)\n",
    "    print('letras corretas: ', letras_corretas)\n",
    "\n",
    "    print('letras aceitas: ',letras_aceitas)\n",
    "    terminou, df, notificacao, palavra_sorteada, letras_aceitas, tentativa = get_notificacao(palavra_sorteada, df, file, now, session_id, dicionario,tentativa, letras_aceitas)\n",
    "\n",
    "    #file.write('tentativa,palavra,resultado,data,session_id\\n')\n",
    "    file.write(f'{tentativa},{palavra_sorteada},{notificacao},{data},{session_id},{variavel_randomica},{dicionario}\\n')\n",
    "    tentativa += 1\n",
    "\n",
    "    if tentativa > 6:\n",
    "        terminou = False\n",
    "\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51cbb08f-9d9c-4b09-a50e-41148395a088",
   "metadata": {},
   "outputs": [],
   "source": [
    "letras_aceitas = ''\n",
    "\n",
    "file = open('resultados.txt', 'a')\n",
    "\n",
    "caminho = 'br-utf8.csv'\n",
    "\n",
    "df = carrega_dataframe_csv(caminho)\n",
    "\n",
    "driver = inicializa_termo()\n",
    "\n",
    "def roda_tudo(driver,df,letras_aceitas):\n",
    "    terminou = True\n",
    "    tentativa = 0\n",
    "\n",
    "    now = datetime.now()\n",
    "    data = now.strftime(\"%d/%m/%Y\")\n",
    "    session_id = driver.session_id\n",
    "\n",
    "    #só verificando o seed que foi gerado pra caso precisar replicar\n",
    "    variavel_randomica = random.randint(0,1000)\n",
    "\n",
    "    a = random.seed(variavel_randomica)\n",
    "    print(variavel_randomica)\n",
    "\n",
    "    #print('first')\n",
    "    #pegando a primeira palavra\n",
    "    palavra_sorteada = first_attempt(df)\n",
    "\n",
    "    envia_palavra(palavra_sorteada)\n",
    "\n",
    "    #pegar informações da palavra enviada\n",
    "    dicionario = retorna_dicionario_respostas(tentativa)\n",
    "\n",
    "    #print(palavra_sorteada)\n",
    "    #df, letras_aceitas = filtra_df(dicionario, df, letras_aceitas)\n",
    "\n",
    "    df, letras_aceitas, letras_erradas, letras_lugar_errado, letras_corretas = filtra_df_2(dicionario, df, letras_aceitas)\n",
    "\n",
    "    #driver.implicitly_wait(10)\n",
    "    sleep(1)\n",
    "    print('------------------------------------')\n",
    "    print('palavra sorteada: ',palavra_sorteada) \n",
    "    print(dicionario)\n",
    "    print('tentativa: ',tentativa)\n",
    "    print('letras erradas: ', letras_erradas)\n",
    "    print('letras lugar errado: ', letras_lugar_errado)\n",
    "    print('letras corretas: ', letras_corretas)\n",
    "    print('letras aceitas: ',letras_aceitas)\n",
    "    df.to_csv('debugando.csv')\n",
    "\n",
    "    tentativa += 1\n",
    "\n",
    "    while terminou == True:\n",
    "        #driver.implicitly_wait(5)\n",
    "        #for tentativa in range(5):\n",
    "        #print(tentativa)\n",
    "\n",
    "        palavra_sorteada = sorteia_palavra(df.palavra.values.tolist())\n",
    "        #print(palavra_sorteada)\n",
    "\n",
    "        envia_palavra(palavra_sorteada)\n",
    "\n",
    "        #pegar informações da palavra enviada\n",
    "        dicionario = retorna_dicionario_respostas(tentativa)\n",
    "\n",
    "        #print(palavra_sorteada)\n",
    "        #df.to_csv('debugando.csv')\n",
    "        df, letras_aceitas, letras_erradas, letras_lugar_errado, letras_corretas = filtra_df_2(dicionario, df, letras_aceitas)\n",
    "        #driver.implicitly_wait(30)\n",
    "        sleep(1)\n",
    "\n",
    "            #terminou, df, notificacao, palavra_sorteada, letras_aceitas, tentativa = get_notificacao(palavra_sorteada, df, file, now, session_id, dicionario,tentativa, letras_aceitas)\n",
    "        print('------------------------------------')\n",
    "        print('palavra sorteada: ',palavra_sorteada) \n",
    "        print(dicionario)\n",
    "\n",
    "        print('tentativa: ',tentativa)\n",
    "        print('letras erradas: ', letras_erradas)\n",
    "        print('letras lugar errado: ', letras_lugar_errado)\n",
    "        print('letras corretas: ', letras_corretas)\n",
    "\n",
    "        print('letras aceitas: ',letras_aceitas)\n",
    "        terminou, df, notificacao, palavra_sorteada, letras_aceitas, tentativa = get_notificacao(palavra_sorteada, df, file, now, session_id, dicionario,tentativa, letras_aceitas)\n",
    "\n",
    "        #file.write('tentativa,palavra,resultado,data,session_id\\n')\n",
    "        file.write(f'{tentativa},{palavra_sorteada},{notificacao},{data},{session_id},{variavel_randomica},{dicionario}\\n')\n",
    "        tentativa += 1\n",
    "\n",
    "        if tentativa > 6:\n",
    "            terminou = False\n",
    "\n",
    "    file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f20ea65-fcbe-4ade-bcbe-41ceb26ca7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252\n",
      "------------------------------------\n",
      "palavra sorteada:  aureo\n",
      "{0: ('letter place', 'a'), 1: ('letter wrong', 'u'), 2: ('letter place', 'r'), 3: ('letter wrong', 'e'), 4: ('letter place', 'o')}\n",
      "tentativa:  0\n",
      "letras erradas:  [('u', 1, False), ('e', 3, False)]\n",
      "letras lugar errado:  [('a', 0), ('r', 2), ('o', 4)]\n",
      "letras corretas:  []\n",
      "letras aceitas:  aro\n",
      "------------------------------------\n",
      "palavra sorteada:  broas\n",
      "{0: ('letter wrong', 'b'), 1: ('letter place', 'r'), 2: ('letter place', 'o'), 3: ('letter place', 'a'), 4: ('letter wrong', 's')}\n",
      "tentativa:  1\n",
      "letras erradas:  [('b', 0, False), ('s', 4, False)]\n",
      "letras lugar errado:  [('r', 1), ('o', 2), ('a', 3)]\n",
      "letras corretas:  []\n",
      "letras aceitas:  aroroa\n",
      "------------------------------------\n",
      "palavra sorteada:  major\n",
      "{0: ('letter wrong', 'm'), 1: ('letter right', 'a'), 2: ('letter wrong', 'j'), 3: ('letter right', 'o'), 4: ('letter right', 'r')}\n",
      "tentativa:  2\n",
      "letras erradas:  [('m', 0, False), ('j', 2, False)]\n",
      "letras lugar errado:  []\n",
      "letras corretas:  [('a', 1), ('o', 3), ('r', 4)]\n",
      "letras aceitas:  aroroaaor\n",
      "------------------------------------\n",
      "palavra sorteada:  valor\n",
      "{0: ('letter place', 'v'), 1: ('letter right', 'a'), 2: ('letter wrong', 'l'), 3: ('letter right', 'o'), 4: ('letter right', 'r')}\n",
      "tentativa:  3\n",
      "letras erradas:  [('l', 2, False)]\n",
      "letras lugar errado:  [('v', 0)]\n",
      "letras corretas:  [('a', 1), ('o', 3), ('r', 4)]\n",
      "letras aceitas:  aroroaaoraorv\n",
      "------------------------------------\n",
      "palavra sorteada:  favor\n",
      "{0: ('letter wrong', 'f'), 1: ('letter right', 'a'), 2: ('letter right', 'v'), 3: ('letter right', 'o'), 4: ('letter right', 'r')}\n",
      "tentativa:  4\n",
      "letras erradas:  [('f', 0, False)]\n",
      "letras lugar errado:  []\n",
      "letras corretas:  [('a', 1), ('v', 2), ('o', 3), ('r', 4)]\n",
      "letras aceitas:  aroroaaoraorvavor\n",
      "------------------------------------\n",
      "palavra sorteada:  pavor\n",
      "{0: ('letter right done', 'p'), 1: ('letter right done', 'a'), 2: ('letter right done', 'v'), 3: ('letter right done', 'o'), 4: ('letter right done', 'r')}\n",
      "tentativa:  5\n",
      "letras erradas:  []\n",
      "letras lugar errado:  []\n",
      "letras corretas:  []\n",
      "letras aceitas:  aroroaaoraorvavor\n"
     ]
    }
   ],
   "source": [
    "roda_tudo(driver,df,letras_aceitas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08884810-2973-4ee1-848b-a6d9a62f17c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296c5fb7-7707-4cec-b49b-231a1d65f0bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2fccae6d-3e1c-4b43-8e84-d1e98603e38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "820\n"
     ]
    }
   ],
   "source": [
    "letras_aceitas = ''\n",
    "\n",
    "file = open('resultados.txt', 'a')\n",
    "\n",
    "caminho = 'br-utf8.csv'\n",
    "\n",
    "df = carrega_dataframe_csv(caminho)\n",
    "\n",
    "driver = inicializa_termo()\n",
    "\n",
    "\n",
    "terminou = True\n",
    "tentativa = 0\n",
    "\n",
    "now = datetime.now()\n",
    "data = now.strftime(\"%d/%m/%Y\")\n",
    "session_id = driver.session_id\n",
    "\n",
    "#só verificando o seed que foi gerado pra caso precisar replicar\n",
    "variavel_randomica = random.randint(0,1000)\n",
    "a = random.seed(variavel_randomica)\n",
    "print(variavel_randomica)\n",
    "\n",
    "\n",
    "palavra_sorteada = first_attempt(df)\n",
    "\n",
    "envia_palavra(palavra_sorteada)\n",
    "\n",
    "#pegar informações da palavra enviada\n",
    "dicionario = retorna_dicionario_respostas(tentativa)\n",
    "\n",
    "#\n",
    "\n",
    "df, letras_aceitas, letras_erradas, letras_lugar_errado, letras_corretas = filtra_df_2(dicionario, df, letras_aceitas)\n",
    "\n",
    "\n",
    "sleep(1)\n",
    "\n",
    "tentativa += 1\n",
    "\n",
    "while terminou == True:\n",
    "\n",
    "\n",
    "    palavra_sorteada = sorteia_palavra(df.palavra.values.tolist())\n",
    "\n",
    "\n",
    "    envia_palavra(palavra_sorteada)\n",
    "\n",
    "    #pegar informações da palavra enviada\n",
    "    dicionario = retorna_dicionario_respostas(tentativa)\n",
    "\n",
    "    df, letras_aceitas, letras_erradas, letras_lugar_errado, letras_corretas = filtra_df_2(dicionario, df, letras_aceitas)\n",
    "\n",
    "    sleep(1)\n",
    "\n",
    "        #terminou, df, notificacao, palavra_sorteada, letras_aceitas, tentativa = get_notificacao(palavra_sorteada, df, file, now, session_id, dicionario,tentativa, letras_aceitas)\n",
    "    terminou, df, notificacao, palavra_sorteada, letras_aceitas, tentativa = get_notificacao(palavra_sorteada, df, file, now, session_id, dicionario,tentativa, letras_aceitas)\n",
    "    \n",
    "    #file.write('tentativa,palavra,resultado,data,session_id\\n')\n",
    "    file.write(f'{tentativa},{palavra_sorteada},{notificacao},{data},{session_id},{variavel_randomica},{dicionario}\\n')\n",
    "    tentativa += 1\n",
    "    \n",
    "    if tentativa > 6:\n",
    "        terminou = False\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43201fcf-cb82-4caf-b79b-cf0a8956353c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2169130-dc55-47ca-86d6-e66095e2437c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a2901f-27d4-4684-bf5d-4d6207b90083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b64fdf-867b-4ab0-bbcf-680ea6a2e74c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3ffeb96c-5ee9-4049-a754-c4dbfc0f60ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#depois procurar pq nao ta funcionando essa funçaõ\n",
    "\n",
    "#fazer função do bloco final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5080e062-db1c-4c9a-84b2-ebd21469844f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fonte',\n",
       " 'frase',\n",
       " 'viver',\n",
       " 'quero',\n",
       " 'frase',\n",
       " 'forma',\n",
       " 'casar',\n",
       " 'viver',\n",
       " 'criar',\n",
       " 'conto',\n",
       " 'gozar',\n",
       " 'minha',\n",
       " 'penso',\n",
       " 'quero',\n",
       " 'ainda',\n",
       " 'tenha',\n",
       " 'corpo',\n",
       " 'minha',\n",
       " 'lenha',\n",
       " 'desse',\n",
       " 'quero',\n",
       " 'ainda',\n",
       " 'tenha',\n",
       " 'minha',\n",
       " 'assim',\n",
       " 'penso',\n",
       " 'ponho',\n",
       " 'forma',\n",
       " 'tomou',\n",
       " 'nossa',\n",
       " 'latim',\n",
       " 'frase',\n",
       " 'penso',\n",
       " 'penso',\n",
       " 'estou',\n",
       " 'estar',\n",
       " 'areia',\n",
       " 'vento',\n",
       " 'norte',\n",
       " 'fundo',\n",
       " 'achas',\n",
       " 'tanta',\n",
       " 'coval',\n",
       " 'vazio',\n",
       " 'praia',\n",
       " 'raiva',\n",
       " 'louco',\n",
       " 'lugar',\n",
       " 'praia',\n",
       " 'gente',\n",
       " 'nisto',\n",
       " 'vacuo',\n",
       " 'visto',\n",
       " 'magoa',\n",
       " 'vento',\n",
       " 'norte',\n",
       " 'pulso',\n",
       " 'mundo',\n",
       " 'levas',\n",
       " 'areia',\n",
       " 'tenho',\n",
       " 'levar',\n",
       " 'fosse',\n",
       " 'fosse',\n",
       " 'longe',\n",
       " 'ideia',\n",
       " 'noite',\n",
       " 'chuva',\n",
       " 'vento',\n",
       " 'torvo',\n",
       " 'vento',\n",
       " 'lugar',\n",
       " 'noite',\n",
       " 'fazes',\n",
       " 'crias',\n",
       " 'mundo',\n",
       " 'areia',\n",
       " 'minha',\n",
       " 'tedio',\n",
       " 'lares',\n",
       " 'razao',\n",
       " 'atira',\n",
       " 'paria',\n",
       " 'vento',\n",
       " 'forma',\n",
       " 'noite',\n",
       " 'termo',\n",
       " 'almas',\n",
       " 'tenho',\n",
       " 'almas',\n",
       " 'tenho',\n",
       " 'mudei',\n",
       " 'nunca',\n",
       " 'tanto',\n",
       " 'tenho',\n",
       " 'calma',\n",
       " 'sente',\n",
       " 'sonho',\n",
       " 'nasce',\n",
       " 'minha',\n",
       " 'minha',\n",
       " 'mobil',\n",
       " 'estou',\n",
       " 'lendo',\n",
       " 'sogue',\n",
       " 'senti',\n",
       " 'vibra',\n",
       " 'grito',\n",
       " 'vibra',\n",
       " 'grita',\n",
       " 'fundo',\n",
       " 'vibra',\n",
       " 'morto',\n",
       " 'vibra',\n",
       " 'polos',\n",
       " 'mundo',\n",
       " 'feito',\n",
       " 'mundo',\n",
       " 'enche',\n",
       " 'mundo',\n",
       " 'vasto',\n",
       " 'nosso',\n",
       " 'alado',\n",
       " 'todos',\n",
       " 'saber',\n",
       " 'deram',\n",
       " 'sorte',\n",
       " 'todos',\n",
       " 'saber',\n",
       " 'morte',\n",
       " 'estes',\n",
       " 'vibra',\n",
       " 'arder',\n",
       " 'visao',\n",
       " 'todos',\n",
       " 'todos',\n",
       " 'passa',\n",
       " 'genio',\n",
       " 'vibra',\n",
       " 'forma',\n",
       " 'outra',\n",
       " 'mesma',\n",
       " 'esvai',\n",
       " 'todos',\n",
       " 'todos',\n",
       " 'vibra',\n",
       " 'gente',\n",
       " 'varia',\n",
       " 'neste',\n",
       " 'mundo',\n",
       " 'misto',\n",
       " 'peito',\n",
       " 'atrai',\n",
       " 'rubra',\n",
       " 'altos',\n",
       " 'motes',\n",
       " 'dados',\n",
       " 'todos',\n",
       " 'todos',\n",
       " 'sobre',\n",
       " 'ondas',\n",
       " 'haver',\n",
       " 'vindo',\n",
       " 'mesmo',\n",
       " 'venha',\n",
       " 'havia',\n",
       " 'fundo',\n",
       " 'traca',\n",
       " 'vosso',\n",
       " 'vario',\n",
       " 'fatal',\n",
       " 'rasgo',\n",
       " 'titas',\n",
       " 'esses',\n",
       " 'vibra',\n",
       " 'feito',\n",
       " 'mundo',\n",
       " 'justo',\n",
       " 'vibra',\n",
       " 'nosso',\n",
       " 'deixa',\n",
       " 'atras',\n",
       " 'furor',\n",
       " 'todos',\n",
       " 'chama',\n",
       " 'mundo',\n",
       " 'visto',\n",
       " 'maior',\n",
       " 'vinde',\n",
       " 'todos',\n",
       " 'fomos',\n",
       " 'vibra',\n",
       " 'vibra',\n",
       " 'grita',\n",
       " 'nossa',\n",
       " 'ansia',\n",
       " 'libra',\n",
       " 'vibra',\n",
       " 'todos',\n",
       " 'chama',\n",
       " 'vibra',\n",
       " 'mesmo',\n",
       " 'arder',\n",
       " 'fazer',\n",
       " 'feito',\n",
       " 'reune',\n",
       " 'corpo',\n",
       " 'fundo',\n",
       " 'surdo',\n",
       " 'canta',\n",
       " 'jesus',\n",
       " 'oelho',\n",
       " 'febre',\n",
       " 'houve',\n",
       " 'viver',\n",
       " 'claro',\n",
       " 'seres',\n",
       " 'nudez',\n",
       " 'desta',\n",
       " 'visao',\n",
       " 'nocao',\n",
       " 'todos',\n",
       " 'viver',\n",
       " 'forma',\n",
       " 'tinha',\n",
       " 'nudez',\n",
       " 'houve',\n",
       " 'vezes',\n",
       " 'mesma',\n",
       " 'fazer',\n",
       " 'assim',\n",
       " 'desse',\n",
       " 'claro',\n",
       " 'posso',\n",
       " 'ouvir',\n",
       " 'senao',\n",
       " 'pecas',\n",
       " 'vezes',\n",
       " 'todas',\n",
       " 'devem',\n",
       " 'dizem',\n",
       " 'podia',\n",
       " 'outra',\n",
       " 'neste',\n",
       " 'salao',\n",
       " 'armas',\n",
       " 'forma',\n",
       " 'olhar',\n",
       " 'causa',\n",
       " 'viver',\n",
       " 'olhar',\n",
       " 'desse',\n",
       " 'serem',\n",
       " 'elmos',\n",
       " 'marca',\n",
       " 'sobre',\n",
       " 'sobre',\n",
       " 'vicio',\n",
       " 'mesma',\n",
       " 'armas',\n",
       " 'entro',\n",
       " 'ecoam',\n",
       " 'minha',\n",
       " 'entra',\n",
       " 'vazia',\n",
       " 'coisa',\n",
       " 'poder',\n",
       " 'sejam',\n",
       " 'assim',\n",
       " 'assim',\n",
       " 'razao',\n",
       " 'razao',\n",
       " 'roubo',\n",
       " 'valor',\n",
       " 'troca',\n",
       " 'metal',\n",
       " 'ideia',\n",
       " 'comum',\n",
       " 'banal',\n",
       " 'entre',\n",
       " 'metal',\n",
       " 'outro',\n",
       " 'fosse',\n",
       " 'latao',\n",
       " 'desse',\n",
       " 'ouvir',\n",
       " 'expor',\n",
       " 'pensa',\n",
       " 'coisa',\n",
       " 'assim',\n",
       " 'tenho',\n",
       " 'venha',\n",
       " 'saber',\n",
       " 'passa',\n",
       " 'coisa',\n",
       " 'corpo',\n",
       " 'corpo',\n",
       " 'forma',\n",
       " 'assim',\n",
       " 'todos',\n",
       " 'corpo',\n",
       " 'sabem',\n",
       " 'corpo',\n",
       " 'nocao',\n",
       " 'assim',\n",
       " 'serve',\n",
       " 'jogam',\n",
       " 'casos',\n",
       " 'assim',\n",
       " 'acham',\n",
       " 'graca',\n",
       " 'circo',\n",
       " 'nodoa',\n",
       " 'feliz',\n",
       " 'haver',\n",
       " 'tanta',\n",
       " 'coisa',\n",
       " 'vezes',\n",
       " 'causa',\n",
       " 'coisa',\n",
       " 'coisa',\n",
       " 'serao',\n",
       " 'coisa',\n",
       " 'comum',\n",
       " 'assim',\n",
       " 'penso',\n",
       " 'julgo',\n",
       " 'penso',\n",
       " 'olhar',\n",
       " 'olhar',\n",
       " 'saiba',\n",
       " 'abrem',\n",
       " 'sinto',\n",
       " 'pasmo',\n",
       " 'assim',\n",
       " 'vezes',\n",
       " 'entao',\n",
       " 'estao',\n",
       " 'sinto',\n",
       " 'viver',\n",
       " 'sinto',\n",
       " 'saiba',\n",
       " 'posso',\n",
       " 'viver',\n",
       " 'tinha',\n",
       " 'outro',\n",
       " 'belas',\n",
       " 'belas',\n",
       " 'belas',\n",
       " 'posso',\n",
       " 'visse',\n",
       " 'deles',\n",
       " 'serem',\n",
       " 'mesmo',\n",
       " 'haver',\n",
       " 'sobre',\n",
       " 'claro',\n",
       " 'assim',\n",
       " 'corpo',\n",
       " 'sente',\n",
       " 'nocao',\n",
       " 'seria',\n",
       " 'futil',\n",
       " 'fazer',\n",
       " 'falar',\n",
       " 'supor',\n",
       " 'facil',\n",
       " 'supor',\n",
       " 'fazer',\n",
       " 'falar',\n",
       " 'fazem',\n",
       " 'sinto',\n",
       " 'surge',\n",
       " 'volta',\n",
       " 'dizer',\n",
       " 'volta',\n",
       " 'volta',\n",
       " 'julgo',\n",
       " 'nunca',\n",
       " 'estar',\n",
       " 'vezes',\n",
       " 'igual',\n",
       " 'entre',\n",
       " 'todos',\n",
       " 'igual',\n",
       " 'coisa',\n",
       " 'saber',\n",
       " 'viver',\n",
       " 'podem',\n",
       " 'saber',\n",
       " 'vivem',\n",
       " 'estou',\n",
       " 'viver',\n",
       " 'susto',\n",
       " 'viver',\n",
       " 'viver',\n",
       " 'vivem',\n",
       " 'comer',\n",
       " 'olhos',\n",
       " 'viver',\n",
       " 'entre',\n",
       " 'viver',\n",
       " 'viver',\n",
       " 'entao',\n",
       " 'tendo',\n",
       " 'viver',\n",
       " 'falar',\n",
       " 'circo',\n",
       " 'sabem',\n",
       " 'fazer',\n",
       " 'pinos',\n",
       " 'desse',\n",
       " 'salto',\n",
       " 'havia',\n",
       " 'saber',\n",
       " 'dando',\n",
       " 'dizer',\n",
       " 'sabem',\n",
       " 'nunca',\n",
       " 'coisa',\n",
       " 'posso',\n",
       " 'posso',\n",
       " 'saber',\n",
       " 'visse',\n",
       " 'podia',\n",
       " 'supor',\n",
       " 'belas',\n",
       " 'penas',\n",
       " 'penas',\n",
       " 'deste',\n",
       " 'sinto',\n",
       " 'haver',\n",
       " 'penso',\n",
       " 'nunca',\n",
       " 'igual',\n",
       " 'penso',\n",
       " 'deste',\n",
       " 'vivem',\n",
       " 'vezes',\n",
       " 'poder',\n",
       " 'visto',\n",
       " 'julgo',\n",
       " 'estar',\n",
       " 'disso',\n",
       " 'tenha',\n",
       " 'disso',\n",
       " 'possa',\n",
       " 'dessa',\n",
       " 'feliz',\n",
       " 'aleas',\n",
       " 'secas',\n",
       " 'sonho',\n",
       " 'vezes',\n",
       " 'tenho',\n",
       " 'viver',\n",
       " 'nunca',\n",
       " 'passa',\n",
       " 'aleas',\n",
       " 'desse',\n",
       " 'secas',\n",
       " 'menos',\n",
       " 'ouvir',\n",
       " 'secas',\n",
       " 'secas',\n",
       " 'tenho',\n",
       " 'pisar',\n",
       " 'menos',\n",
       " 'nesta',\n",
       " 'outro',\n",
       " 'gente',\n",
       " 'passa',\n",
       " 'falso',\n",
       " 'falsa',\n",
       " 'tenho',\n",
       " 'basta',\n",
       " 'ideia',\n",
       " 'ideia',\n",
       " 'ideia',\n",
       " 'menos',\n",
       " 'outra',\n",
       " 'haver',\n",
       " 'entre',\n",
       " 'assim',\n",
       " 'assim',\n",
       " 'mesmo',\n",
       " 'pensa',\n",
       " 'podem',\n",
       " 'gente',\n",
       " 'ferro',\n",
       " 'brasa',\n",
       " 'posso',\n",
       " 'saber',\n",
       " 'ferro',\n",
       " 'brasa',\n",
       " 'ferro',\n",
       " 'brasa',\n",
       " 'ideia',\n",
       " 'posso',\n",
       " 'notar',\n",
       " 'falta',\n",
       " 'delas',\n",
       " 'poder',\n",
       " 'gozar',\n",
       " 'serem',\n",
       " 'essas',\n",
       " 'dizem',\n",
       " 'seria',\n",
       " 'coisa',\n",
       " 'sente',\n",
       " 'nunca',\n",
       " 'razao',\n",
       " 'seria',\n",
       " 'salao',\n",
       " 'nobre',\n",
       " 'azuis',\n",
       " 'vezes',\n",
       " 'salao',\n",
       " 'feita',\n",
       " 'pelas',\n",
       " 'entre',\n",
       " 'vezes',\n",
       " 'frios',\n",
       " 'pelos',\n",
       " 'neste',\n",
       " 'solar',\n",
       " 'vezes',\n",
       " 'serei',\n",
       " 'corpo',\n",
       " 'baixo',\n",
       " 'muito',\n",
       " 'muito',\n",
       " 'gosto',\n",
       " 'outra',\n",
       " 'tenho',\n",
       " 'colar',\n",
       " 'penar',\n",
       " 'terra',\n",
       " 'terra',\n",
       " 'minha',\n",
       " 'deixa',\n",
       " 'pense',\n",
       " 'ainda',\n",
       " 'vives',\n",
       " 'mesmo',\n",
       " 'morto',\n",
       " 'estar',\n",
       " 'saber',\n",
       " 'mesmo',\n",
       " 'assim',\n",
       " 'basta',\n",
       " 'quero',\n",
       " 'assim',\n",
       " 'posso',\n",
       " 'ontem',\n",
       " 'porta',\n",
       " 'vento',\n",
       " 'sabes',\n",
       " 'deste',\n",
       " 'ainda',\n",
       " 'caixa',\n",
       " 'tampa',\n",
       " 'quero',\n",
       " 'leque',\n",
       " 'pensa',\n",
       " 'pensa',\n",
       " 'horas',\n",
       " 'noite',\n",
       " 'pouca',\n",
       " 'noite',\n",
       " 'podes',\n",
       " 'dormi',\n",
       " 'olhos',\n",
       " 'coisa',\n",
       " 'fitar',\n",
       " 'lugar',\n",
       " 'noite',\n",
       " 'noite',\n",
       " 'havia',\n",
       " 'baile',\n",
       " 'todos',\n",
       " 'baile',\n",
       " 'estar',\n",
       " 'estar',\n",
       " 'estar',\n",
       " 'deram',\n",
       " 'darei',\n",
       " 'farei',\n",
       " 'tenho',\n",
       " 'horas',\n",
       " 'tempo',\n",
       " 'trigo',\n",
       " 'tempo',\n",
       " 'falar',\n",
       " 'levas',\n",
       " 'batem',\n",
       " 'antes',\n",
       " 'quero',\n",
       " 'matem',\n",
       " 'ouvir',\n",
       " 'parar',\n",
       " 'chita',\n",
       " 'levas',\n",
       " 'peito',\n",
       " 'andar',\n",
       " 'antes',\n",
       " 'jeito',\n",
       " 'sabem',\n",
       " 'rosas',\n",
       " 'essas',\n",
       " 'sabes',\n",
       " 'fomos',\n",
       " 'fomos',\n",
       " 'sinta',\n",
       " 'andam',\n",
       " 'sabem',\n",
       " 'minha',\n",
       " 'loura',\n",
       " 'minha',\n",
       " 'loura',\n",
       " 'agora',\n",
       " 'foste',\n",
       " 'livro',\n",
       " 'olhas',\n",
       " 'nunca',\n",
       " 'dizes',\n",
       " 'calei',\n",
       " 'aquem',\n",
       " 'posto',\n",
       " 'saber',\n",
       " 'ousei',\n",
       " 'dizer',\n",
       " 'falar',\n",
       " 'supus',\n",
       " 'fosse',\n",
       " 'assim',\n",
       " 'todos',\n",
       " 'penso',\n",
       " 'gesto',\n",
       " 'lenco',\n",
       " 'salva',\n",
       " 'prata',\n",
       " 'salva',\n",
       " 'prata',\n",
       " 'saber',\n",
       " 'noite',\n",
       " 'penar',\n",
       " 'barro',\n",
       " 'dorme',\n",
       " 'xaile',\n",
       " 'posto',\n",
       " 'verde',\n",
       " 'verde',\n",
       " 'verde',\n",
       " 'coisa',\n",
       " 'coisa',\n",
       " 'perde',\n",
       " 'gente',\n",
       " 'colhe',\n",
       " 'dizem',\n",
       " 'tenho',\n",
       " 'coisa',\n",
       " 'levas',\n",
       " 'claro',\n",
       " 'tenho',\n",
       " 'andas',\n",
       " 'visse',\n",
       " 'outro',\n",
       " 'nuvem',\n",
       " 'gente',\n",
       " 'menos',\n",
       " 'magoa',\n",
       " 'sonho',\n",
       " 'teres',\n",
       " 'sente',\n",
       " 'nuvem',\n",
       " 'passa',\n",
       " 'graca',\n",
       " 'nuvem',\n",
       " 'vento',\n",
       " 'ambos',\n",
       " 'beira',\n",
       " 'muito',\n",
       " 'fundo',\n",
       " 'pedra',\n",
       " 'olhar',\n",
       " 'mundo',\n",
       " 'velha',\n",
       " 'maria',\n",
       " 'maria',\n",
       " 'dizer',\n",
       " 'podes',\n",
       " 'assim',\n",
       " 'olhos',\n",
       " 'ambos',\n",
       " 'estar',\n",
       " 'pedir',\n",
       " 'lavra',\n",
       " 'julga',\n",
       " 'lavra',\n",
       " 'lavra',\n",
       " 'pente',\n",
       " 'ouvir',\n",
       " 'fores',\n",
       " 'supor',\n",
       " 'noite',\n",
       " 'vezes',\n",
       " 'vezes',\n",
       " 'digas',\n",
       " 'dizes',\n",
       " 'dizes',\n",
       " 'mundo',\n",
       " 'igual',\n",
       " 'todas',\n",
       " 'dizes',\n",
       " 'fazem',\n",
       " 'linha',\n",
       " 'muito',\n",
       " 'pense',\n",
       " 'nunca',\n",
       " 'coisa',\n",
       " 'coses',\n",
       " 'fazes',\n",
       " 'dizer',\n",
       " 'ondas',\n",
       " 'conta',\n",
       " 'olhar',\n",
       " 'todos',\n",
       " 'vento',\n",
       " 'nesta',\n",
       " 'tinha',\n",
       " 'nuvem',\n",
       " 'passa',\n",
       " 'passa',\n",
       " 'canto',\n",
       " 'canto',\n",
       " 'sabes',\n",
       " 'andar',\n",
       " 'olhos',\n",
       " 'olhei',\n",
       " 'pobre',\n",
       " 'pobre',\n",
       " 'muito',\n",
       " 'gente',\n",
       " 'digas',\n",
       " 'mundo',\n",
       " 'todas',\n",
       " 'bilha',\n",
       " 'assim',\n",
       " 'filha',\n",
       " 'antes',\n",
       " 'loura',\n",
       " 'olhos',\n",
       " 'quero',\n",
       " 'saber',\n",
       " 'horta',\n",
       " 'amiga',\n",
       " 'feliz',\n",
       " 'graos',\n",
       " 'deles',\n",
       " 'deixa',\n",
       " 'dizem',\n",
       " 'tenho',\n",
       " 'livro',\n",
       " 'negra',\n",
       " 'olhos',\n",
       " 'falar',\n",
       " 'netos',\n",
       " 'bater',\n",
       " 'parar',\n",
       " 'vezes',\n",
       " 'gente',\n",
       " 'conta',\n",
       " 'entre',\n",
       " 'mesmo',\n",
       " 'olhar',\n",
       " 'gente',\n",
       " 'olhar',\n",
       " 'saber',\n",
       " 'sente',\n",
       " 'havia',\n",
       " 'deste',\n",
       " 'outra',\n",
       " 'daria',\n",
       " 'dobra',\n",
       " 'olhos',\n",
       " 'deixa',\n",
       " 'matar',\n",
       " 'muito',\n",
       " 'pense',\n",
       " 'pense',\n",
       " 'nunca',\n",
       " 'minha',\n",
       " 'junto',\n",
       " 'feliz',\n",
       " 'pouco',\n",
       " 'ambos',\n",
       " 'lados',\n",
       " 'falar',\n",
       " 'beijo',\n",
       " 'ideia',\n",
       " 'louca',\n",
       " 'cento',\n",
       " 'tenho',\n",
       " 'horas',\n",
       " 'algum',\n",
       " 'tenho',\n",
       " 'longe',\n",
       " 'saber',\n",
       " 'assim',\n",
       " 'breve',\n",
       " 'breve',\n",
       " 'manha',\n",
       " 'dizem',\n",
       " 'nasce',\n",
       " 'noite',\n",
       " 'nuvem',\n",
       " 'nuvem',\n",
       " 'falta',\n",
       " 'desce',\n",
       " 'pouco',\n",
       " 'desce',\n",
       " 'saber',\n",
       " 'livre',\n",
       " 'tocar',\n",
       " 'foste',\n",
       " 'estar',\n",
       " 'festa',\n",
       " 'minha',\n",
       " 'festa',\n",
       " 'gente',\n",
       " 'canto',\n",
       " 'todos',\n",
       " 'graca',\n",
       " 'nuvem',\n",
       " 'dizer',\n",
       " 'deste',\n",
       " 'assim',\n",
       " 'assim',\n",
       " 'nasci',\n",
       " 'gosto',\n",
       " 'rosas',\n",
       " 'senao',\n",
       " 'rosas',\n",
       " 'baixo',\n",
       " 'entre',\n",
       " 'olhos',\n",
       " 'dizem',\n",
       " 'saber',\n",
       " 'razao',\n",
       " 'quero',\n",
       " 'saber',\n",
       " 'nunca',\n",
       " 'foste',\n",
       " 'maria',\n",
       " 'cravo',\n",
       " 'deste',\n",
       " 'papel',\n",
       " 'tanto',\n",
       " 'feliz',\n",
       " 'tiver',\n",
       " 'netos',\n",
       " 'sejas',\n",
       " 'monte',\n",
       " 'verde',\n",
       " 'trova',\n",
       " 'perde',\n",
       " 'olhos',\n",
       " 'nunca',\n",
       " 'seras',\n",
       " 'minha',\n",
       " 'quero',\n",
       " 'jeito',\n",
       " 'diabo',\n",
       " 'homem',\n",
       " 'lenco',\n",
       " 'olhos',\n",
       " 'olhos',\n",
       " 'loura',\n",
       " 'olhos',\n",
       " 'azuis',\n",
       " 'dobra',\n",
       " 'tanta',\n",
       " 'pelos',\n",
       " 'estao',\n",
       " 'vivos',\n",
       " 'quero',\n",
       " 'minha',\n",
       " 'magoa',\n",
       " 'estou',\n",
       " 'leque',\n",
       " 'solto',\n",
       " 'maria',\n",
       " 'maria',\n",
       " 'senao',\n",
       " 'volto',\n",
       " 'vezes',\n",
       " 'disse',\n",
       " 'nunca',\n",
       " 'diria',\n",
       " 'torno',\n",
       " 'dizer',\n",
       " 'outro',\n",
       " 'bater',\n",
       " 'roupa',\n",
       " 'pedra',\n",
       " 'achas',\n",
       " 'minha',\n",
       " 'magoa',\n",
       " 'pouca',\n",
       " 'muito',\n",
       " 'magoa',\n",
       " 'lenco',\n",
       " 'posto',\n",
       " 'posto',\n",
       " 'entre',\n",
       " 'olhos',\n",
       " 'falso',\n",
       " 'fitam',\n",
       " 'vezes',\n",
       " 'vezes',\n",
       " 'achei',\n",
       " 'barca',\n",
       " 'linha',\n",
       " 'tenho',\n",
       " 'venho',\n",
       " 'dizer',\n",
       " 'amigo',\n",
       " 'valer',\n",
       " 'maria',\n",
       " 'assim',\n",
       " 'maria',\n",
       " 'maria',\n",
       " 'graca',\n",
       " 'graca',\n",
       " 'graca',\n",
       " 'graca',\n",
       " 'estas',\n",
       " 'curta',\n",
       " 'perna',\n",
       " 'furta',\n",
       " 'atras',\n",
       " 'longe',\n",
       " 'serra',\n",
       " 'nuvem',\n",
       " 'falta',\n",
       " 'doido',\n",
       " 'nossa',\n",
       " 'entre',\n",
       " 'cetim',\n",
       " 'chita',\n",
       " 'seres',\n",
       " 'cabaz',\n",
       " 'vinha',\n",
       " 'vazio',\n",
       " 'houve',\n",
       " 'loica',\n",
       " 'mesmo',\n",
       " 'negar',\n",
       " 'tolas',\n",
       " 'cravo',\n",
       " 'papel',\n",
       " 'enche',\n",
       " 'noite',\n",
       " 'filha',\n",
       " 'rosas',\n",
       " 'caixa',\n",
       " 'gosta',\n",
       " 'lenco',\n",
       " 'preto',\n",
       " 'valer',\n",
       " 'desse',\n",
       " 'dizer',\n",
       " 'loura',\n",
       " 'preto',\n",
       " 'peito',\n",
       " 'sobra',\n",
       " 'falta',\n",
       " 'senao',\n",
       " 'assim',\n",
       " 'gesto',\n",
       " 'arroz',\n",
       " 'verte',\n",
       " 'quero',\n",
       " 'corou',\n",
       " 'calor',\n",
       " 'corar',\n",
       " 'outro',\n",
       " 'deram',\n",
       " 'senao',\n",
       " 'peito',\n",
       " 'feito',\n",
       " 'botao',\n",
       " 'cousa',\n",
       " 'tenho',\n",
       " 'posso',\n",
       " 'dizer',\n",
       " 'disse',\n",
       " 'farta',\n",
       " 'saber',\n",
       " 'tenho',\n",
       " ...]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "local = 'livros.txt'\n",
    "def abrir_arquivo(local):\n",
    "    with open(local, 'r', encoding = 'utf8') as f:\n",
    "        palavras = f.read()\n",
    "    f.close()\n",
    "    lista_tokens = nltk.tokenize.word_tokenize(palavras)\n",
    "    lista_palavras = []\n",
    "    for i in lista_tokens:\n",
    "        if i.isalpha():\n",
    "            if len(i) == 5:\n",
    "                lista_palavras.append(remove_acentos(i.lower()))\n",
    "            \n",
    "    f.close()\n",
    "    return lista_palavras\n",
    "\n",
    "lista_palavras = abrir_arquivo(local)\n",
    "lista_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "493c3abc-3392-42f5-a27e-5d34ccfdf981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('minha', 361),\n",
       " ('assim', 194),\n",
       " ('olhos', 186),\n",
       " ('muito', 163),\n",
       " ('agora', 149),\n",
       " ('ainda', 147),\n",
       " ('outra', 145),\n",
       " ('tinha', 137),\n",
       " ('mesmo', 129),\n",
       " ('disse', 127)]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def probabilidade(palavra):\n",
    "    return frequencia[palavra]/total_de_palavras\n",
    "\n",
    "frequencia = nltk.FreqDist(lista_palavras)\n",
    "total_de_palavras = len(lista_palavras)\n",
    "frequencia.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b9b1c2f0-129f-4ad1-b194-7356af38430c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9026"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lista_palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ef6c431a-ad4b-493a-9554-2453356594cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>n_vogais</th>\n",
       "      <th>vogais_unicas</th>\n",
       "      <th>letra_0</th>\n",
       "      <th>letra_1</th>\n",
       "      <th>letra_2</th>\n",
       "      <th>letra_3</th>\n",
       "      <th>letra_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aarao</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>a</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abner</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acaia</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>i</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acker</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>k</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aires</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>i</td>\n",
       "      <td>r</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5419</th>\n",
       "      <td>unica</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>n</td>\n",
       "      <td>i</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5420</th>\n",
       "      <td>unico</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>n</td>\n",
       "      <td>i</td>\n",
       "      <td>c</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5421</th>\n",
       "      <td>urico</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>r</td>\n",
       "      <td>i</td>\n",
       "      <td>c</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5422</th>\n",
       "      <td>uteis</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "      <td>i</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>utero</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5424 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     palavra  n_vogais  vogais_unicas letra_0 letra_1 letra_2 letra_3 letra_4\n",
       "0      aarao         4              2       a       a       r       a       o\n",
       "1      abner         2              2       a       b       n       e       r\n",
       "2      acaia         4              2       a       c       a       i       a\n",
       "3      acker         2              2       a       c       k       e       r\n",
       "4      aires         3              3       a       i       r       e       s\n",
       "...      ...       ...            ...     ...     ...     ...     ...     ...\n",
       "5419   unica         3              3       u       n       i       c       a\n",
       "5420   unico         3              3       u       n       i       c       o\n",
       "5421   urico         3              3       u       r       i       c       o\n",
       "5422   uteis         3              3       u       t       e       i       s\n",
       "5423   utero         3              3       u       t       e       r       o\n",
       "\n",
       "[5424 rows x 8 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caminho = 'br-utf8.csv'\n",
    "df = carrega_dataframe_csv(caminho)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "16973ee7-6b99-4ba2-bdc4-284d3b2d3aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>n_vogais</th>\n",
       "      <th>vogais_unicas</th>\n",
       "      <th>letra_0</th>\n",
       "      <th>letra_1</th>\n",
       "      <th>letra_2</th>\n",
       "      <th>letra_3</th>\n",
       "      <th>letra_4</th>\n",
       "      <th>probabilidade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aarao</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>a</td>\n",
       "      <td>o</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abner</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acaia</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>i</td>\n",
       "      <td>a</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acker</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>k</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aires</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>i</td>\n",
       "      <td>r</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  palavra  n_vogais  vogais_unicas letra_0 letra_1 letra_2 letra_3 letra_4  \\\n",
       "0   aarao         4              2       a       a       r       a       o   \n",
       "1   abner         2              2       a       b       n       e       r   \n",
       "2   acaia         4              2       a       c       a       i       a   \n",
       "3   acker         2              2       a       c       k       e       r   \n",
       "4   aires         3              3       a       i       r       e       s   \n",
       "\n",
       "   probabilidade  \n",
       "0            0.0  \n",
       "1            0.0  \n",
       "2            0.0  \n",
       "3            0.0  \n",
       "4            0.0  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['probabilidade'] = df.palavra.apply(lambda x: probabilidade(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "36392896-9e43-4fe3-8c89-a4fb718be960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>n_vogais</th>\n",
       "      <th>vogais_unicas</th>\n",
       "      <th>letra_0</th>\n",
       "      <th>letra_1</th>\n",
       "      <th>letra_2</th>\n",
       "      <th>letra_3</th>\n",
       "      <th>letra_4</th>\n",
       "      <th>probabilidade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3051</th>\n",
       "      <td>minha</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>m</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>h</td>\n",
       "      <td>a</td>\n",
       "      <td>0.034329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>assim</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>i</td>\n",
       "      <td>m</td>\n",
       "      <td>0.018448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3364</th>\n",
       "      <td>olhos</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>o</td>\n",
       "      <td>l</td>\n",
       "      <td>h</td>\n",
       "      <td>o</td>\n",
       "      <td>s</td>\n",
       "      <td>0.017687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3173</th>\n",
       "      <td>muito</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>m</td>\n",
       "      <td>u</td>\n",
       "      <td>i</td>\n",
       "      <td>t</td>\n",
       "      <td>o</td>\n",
       "      <td>0.015500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>agora</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>a</td>\n",
       "      <td>0.014169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>fitem</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>f</td>\n",
       "      <td>i</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "      <td>m</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>fitei</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>f</td>\n",
       "      <td>i</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "      <td>i</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>fitai</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>f</td>\n",
       "      <td>i</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>i</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>fisgo</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>f</td>\n",
       "      <td>i</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>o</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>utero</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "      <td>o</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5424 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     palavra  n_vogais  vogais_unicas letra_0 letra_1 letra_2 letra_3 letra_4  \\\n",
       "3051   minha         2              2       m       i       n       h       a   \n",
       "550    assim         2              2       a       s       s       i       m   \n",
       "3364   olhos         2              1       o       l       h       o       s   \n",
       "3173   muito         3              3       m       u       i       t       o   \n",
       "285    agora         3              2       a       g       o       r       a   \n",
       "...      ...       ...            ...     ...     ...     ...     ...     ...   \n",
       "2025   fitem         2              2       f       i       t       e       m   \n",
       "2024   fitei         3              2       f       i       t       e       i   \n",
       "2020   fitai         3              2       f       i       t       a       i   \n",
       "2019   fisgo         2              2       f       i       s       g       o   \n",
       "5423   utero         3              3       u       t       e       r       o   \n",
       "\n",
       "      probabilidade  \n",
       "3051       0.034329  \n",
       "550        0.018448  \n",
       "3364       0.017687  \n",
       "3173       0.015500  \n",
       "285        0.014169  \n",
       "...             ...  \n",
       "2025       0.000000  \n",
       "2024       0.000000  \n",
       "2020       0.000000  \n",
       "2019       0.000000  \n",
       "5423       0.000000  \n",
       "\n",
       "[5424 rows x 9 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['probabilidade'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5c72fa28-e310-4478-b8c5-93eee8691eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>n_vogais</th>\n",
       "      <th>vogais_unicas</th>\n",
       "      <th>letra_0</th>\n",
       "      <th>letra_1</th>\n",
       "      <th>letra_2</th>\n",
       "      <th>letra_3</th>\n",
       "      <th>letra_4</th>\n",
       "      <th>probabilidade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5372</th>\n",
       "      <td>aureo</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>a</td>\n",
       "      <td>u</td>\n",
       "      <td>r</td>\n",
       "      <td>e</td>\n",
       "      <td>o</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     palavra  n_vogais  vogais_unicas letra_0 letra_1 letra_2 letra_3 letra_4  \\\n",
       "5372   aureo         4              4       a       u       r       e       o   \n",
       "\n",
       "      probabilidade  \n",
       "5372            0.0  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.palavra == 'aureo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5272f5e6-11d0-4c9e-8fc6-c4af629c8dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def conta_consoantes(palavra):\n",
    "    \n",
    "    contador = 0\n",
    "    vogais = 'bcdfghjklmnpqrstvxywz'\n",
    "    allowed = frozenset(vogais)\n",
    "    \n",
    "    for letra in palavra:\n",
    "        if letra in vogais:\n",
    "            contador += 1\n",
    "    consoantes_unicas = len(allowed.intersection(palavra))\n",
    "    \n",
    "    return consoantes_unicas, contador\n",
    "\n",
    "\n",
    "conta_consoantes('perde')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "35c47074-ab1a-4c94-86ca-f1a0615ea8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conta_consoantes('arroz')[0]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ae3957cc-f551-4452-9f01-4f7d7cb56fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>n_vogais</th>\n",
       "      <th>vogais_unicas</th>\n",
       "      <th>letra_0</th>\n",
       "      <th>letra_1</th>\n",
       "      <th>letra_2</th>\n",
       "      <th>letra_3</th>\n",
       "      <th>letra_4</th>\n",
       "      <th>probabilidade</th>\n",
       "      <th>n_consoantes</th>\n",
       "      <th>consoantes_unicas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aarao</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>a</td>\n",
       "      <td>o</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abner</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acaia</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>i</td>\n",
       "      <td>a</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acker</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>k</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aires</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>i</td>\n",
       "      <td>r</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5419</th>\n",
       "      <td>unica</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>n</td>\n",
       "      <td>i</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5420</th>\n",
       "      <td>unico</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>n</td>\n",
       "      <td>i</td>\n",
       "      <td>c</td>\n",
       "      <td>o</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5421</th>\n",
       "      <td>urico</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>r</td>\n",
       "      <td>i</td>\n",
       "      <td>c</td>\n",
       "      <td>o</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5422</th>\n",
       "      <td>uteis</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "      <td>i</td>\n",
       "      <td>s</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>utero</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "      <td>o</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5424 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     palavra  n_vogais  vogais_unicas letra_0 letra_1 letra_2 letra_3 letra_4  \\\n",
       "0      aarao         4              2       a       a       r       a       o   \n",
       "1      abner         2              2       a       b       n       e       r   \n",
       "2      acaia         4              2       a       c       a       i       a   \n",
       "3      acker         2              2       a       c       k       e       r   \n",
       "4      aires         3              3       a       i       r       e       s   \n",
       "...      ...       ...            ...     ...     ...     ...     ...     ...   \n",
       "5419   unica         3              3       u       n       i       c       a   \n",
       "5420   unico         3              3       u       n       i       c       o   \n",
       "5421   urico         3              3       u       r       i       c       o   \n",
       "5422   uteis         3              3       u       t       e       i       s   \n",
       "5423   utero         3              3       u       t       e       r       o   \n",
       "\n",
       "      probabilidade  n_consoantes  consoantes_unicas  \n",
       "0          0.000000             1                  1  \n",
       "1          0.000000             3                  3  \n",
       "2          0.000000             1                  1  \n",
       "3          0.000000             3                  3  \n",
       "4          0.000000             2                  2  \n",
       "...             ...           ...                ...  \n",
       "5419       0.000761             2                  2  \n",
       "5420       0.000856             2                  2  \n",
       "5421       0.000000             2                  2  \n",
       "5422       0.000190             2                  2  \n",
       "5423       0.000000             2                  2  \n",
       "\n",
       "[5424 rows x 11 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['n_consoantes'] = df.palavra.apply(lambda x: conta_consoantes(x)[1])\n",
    "df['consoantes_unicas'] = df.palavra.apply(lambda x: conta_consoantes(x)[0])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "314bdd95-61c8-4b8b-b3e9-d02763e037cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>n_vogais</th>\n",
       "      <th>vogais_unicas</th>\n",
       "      <th>letra_0</th>\n",
       "      <th>letra_1</th>\n",
       "      <th>letra_2</th>\n",
       "      <th>letra_3</th>\n",
       "      <th>letra_4</th>\n",
       "      <th>probabilidade</th>\n",
       "      <th>n_consoantes</th>\n",
       "      <th>consoantes_unicas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aarao</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>a</td>\n",
       "      <td>o</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abner</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acker</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>k</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aires</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>i</td>\n",
       "      <td>r</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>alair</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>l</td>\n",
       "      <td>a</td>\n",
       "      <td>i</td>\n",
       "      <td>r</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5419</th>\n",
       "      <td>unica</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>n</td>\n",
       "      <td>i</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5420</th>\n",
       "      <td>unico</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>n</td>\n",
       "      <td>i</td>\n",
       "      <td>c</td>\n",
       "      <td>o</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5421</th>\n",
       "      <td>urico</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>r</td>\n",
       "      <td>i</td>\n",
       "      <td>c</td>\n",
       "      <td>o</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5422</th>\n",
       "      <td>uteis</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "      <td>i</td>\n",
       "      <td>s</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>utero</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "      <td>o</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4515 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     palavra  n_vogais  vogais_unicas letra_0 letra_1 letra_2 letra_3 letra_4  \\\n",
       "0      aarao         4              2       a       a       r       a       o   \n",
       "1      abner         2              2       a       b       n       e       r   \n",
       "3      acker         2              2       a       c       k       e       r   \n",
       "4      aires         3              3       a       i       r       e       s   \n",
       "5      alair         3              2       a       l       a       i       r   \n",
       "...      ...       ...            ...     ...     ...     ...     ...     ...   \n",
       "5419   unica         3              3       u       n       i       c       a   \n",
       "5420   unico         3              3       u       n       i       c       o   \n",
       "5421   urico         3              3       u       r       i       c       o   \n",
       "5422   uteis         3              3       u       t       e       i       s   \n",
       "5423   utero         3              3       u       t       e       r       o   \n",
       "\n",
       "      probabilidade  n_consoantes  consoantes_unicas  \n",
       "0          0.000000             1                  1  \n",
       "1          0.000000             3                  3  \n",
       "3          0.000000             3                  3  \n",
       "4          0.000000             2                  2  \n",
       "5          0.000000             2                  2  \n",
       "...             ...           ...                ...  \n",
       "5419       0.000761             2                  2  \n",
       "5420       0.000856             2                  2  \n",
       "5421       0.000000             2                  2  \n",
       "5422       0.000190             2                  2  \n",
       "5423       0.000000             2                  2  \n",
       "\n",
       "[4515 rows x 11 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consoantes_mais_usadas = 'srndm'\n",
    "\n",
    "lista = []\n",
    "\n",
    "for indice in consoantes_mais_usadas:\n",
    "    lista.append(indice)\n",
    "\n",
    "\n",
    "\n",
    "mask = df.letra_0.isin(lista) | df.letra_1.isin(lista) | df.letra_2.isin(lista) | df.letra_3.isin(lista) | df.letra_4.isin(lista)\n",
    "df = df.loc[mask,:]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a16435-7972-4fb9-928e-efe278d06d44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "90bb914f-ef72-4ca2-b044-862cc0d11518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>n_vogais</th>\n",
       "      <th>vogais_unicas</th>\n",
       "      <th>letra_0</th>\n",
       "      <th>letra_1</th>\n",
       "      <th>letra_2</th>\n",
       "      <th>letra_3</th>\n",
       "      <th>letra_4</th>\n",
       "      <th>probabilidade</th>\n",
       "      <th>n_consoantes</th>\n",
       "      <th>consoantes_unicas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abner</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acker</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>k</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alpes</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>l</td>\n",
       "      <td>p</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>andre</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>n</td>\n",
       "      <td>d</td>\n",
       "      <td>r</td>\n",
       "      <td>e</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>argel</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>g</td>\n",
       "      <td>e</td>\n",
       "      <td>l</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   palavra  n_vogais  vogais_unicas letra_0 letra_1 letra_2 letra_3 letra_4  \\\n",
       "1    abner         2              2       a       b       n       e       r   \n",
       "3    acker         2              2       a       c       k       e       r   \n",
       "9    alpes         2              2       a       l       p       e       s   \n",
       "11   andre         2              2       a       n       d       r       e   \n",
       "12   argel         2              2       a       r       g       e       l   \n",
       "\n",
       "    probabilidade  n_consoantes  consoantes_unicas  \n",
       "1             0.0             3                  3  \n",
       "3             0.0             3                  3  \n",
       "9             0.0             3                  3  \n",
       "11            0.0             3                  3  \n",
       "12            0.0             3                  3  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = (df.consoantes_unicas == 3) | (df.consoantes_unicas == 4)\n",
    "df = df.loc[mask,:]\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c02238-937c-4a02-8ada-ea2d26f1e7cc",
   "metadata": {},
   "source": [
    "# proximo passo seria pegar todas as palavras que mandou pro site e guardar tbm, pra tentar gerar um machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "714c38e8-a9e4-433c-9506-adf05f6b1394",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                           Version\n",
      "--------------------------------- -------------------\n",
      "aiohttp                           3.7.4\n",
      "altair                            4.2.0\n",
      "ann-visualizer                    2.5\n",
      "anyio                             3.1.0\n",
      "apyori                            1.1.2\n",
      "argon2-cffi                       20.1.0\n",
      "arrow                             0.17.0\n",
      "arviz                             0.11.2\n",
      "astor                             0.8.1\n",
      "async-generator                   1.10\n",
      "async-timeout                     3.0.1\n",
      "attrs                             21.2.0\n",
      "Babel                             2.9.1\n",
      "backcall                          0.2.0\n",
      "backports.functools-lru-cache     1.6.4\n",
      "base58                            2.1.1\n",
      "basedosdados                      1.5.5\n",
      "beautifulsoup4                    4.9.3\n",
      "binaryornot                       0.4.4\n",
      "bleach                            3.3.0\n",
      "blinker                           1.4\n",
      "blis                              0.7.4\n",
      "bokeh                             2.3.2\n",
      "boto                              2.49.0\n",
      "boto3                             1.17.93\n",
      "botocore                          1.20.93\n",
      "Bottleneck                        1.2.1\n",
      "branca                            0.4.2\n",
      "brotlipy                          0.7.0\n",
      "bz2file                           0.98\n",
      "cached-property                   1.5.2\n",
      "cachetools                        4.2.2\n",
      "cassiopeia                        5.0.1\n",
      "catalogue                         2.0.4\n",
      "catboost                          0.26\n",
      "category-encoders                 2.3.0\n",
      "certifi                           2021.10.8\n",
      "cffi                              1.14.5\n",
      "cftime                            1.5.0\n",
      "chardet                           3.0.4\n",
      "click                             8.0.3\n",
      "cloudpickle                       1.6.0\n",
      "colorama                          0.4.4\n",
      "colorcet                          2.0.6\n",
      "cookiecutter                      1.7.3\n",
      "cryptography                      3.4.7\n",
      "cycler                            0.10.0\n",
      "cymem                             2.0.5\n",
      "Cython                            0.29.23\n",
      "cytoolz                           0.11.0\n",
      "dask                              2021.6.0\n",
      "datapipelines                     1.0.7\n",
      "decorator                         5.0.9\n",
      "deep-translator                   1.6.1\n",
      "defusedxml                        0.7.1\n",
      "discord.py                        2.0.1\n",
      "distributed                       2021.6.0\n",
      "eli5                              0.11.0\n",
      "entrypoints                       0.3\n",
      "et-xmlfile                        1.0.1\n",
      "exceptiongroup                    1.1.2\n",
      "feature-engine                    1.1.1\n",
      "ffmpeg                            1.4\n",
      "folium                            0.0.0\n",
      "fsspec                            2021.6.0\n",
      "futures                           3.1.1\n",
      "fuzzywuzzy                        0.18.0\n",
      "gitdb                             4.0.9\n",
      "GitPython                         3.1.26\n",
      "google-api-core                   1.26.3\n",
      "google-auth                       1.30.0\n",
      "google-auth-oauthlib              0.4.4\n",
      "google-cloud-bigquery             1.28.0\n",
      "google-cloud-bigquery-storage     1.1.0\n",
      "google-cloud-core                 1.5.0\n",
      "google-cloud-storage              1.31.2\n",
      "google-crc32c                     1.1.2\n",
      "google-resumable-media            1.2.0\n",
      "googleapis-common-protos          1.53.0\n",
      "googletrans                       3.1.0a0\n",
      "goslate                           1.5.1\n",
      "graphviz                          0.16\n",
      "greenlet                          1.1.0\n",
      "grpcio                            1.38.0\n",
      "h11                               0.9.0\n",
      "h2                                3.2.0\n",
      "h5py                              3.2.1\n",
      "hdbscan                           0.8.27\n",
      "HeapDict                          1.0.1\n",
      "hpack                             3.0.0\n",
      "hstspreload                       2021.8.1\n",
      "htmlmin                           0.1.12\n",
      "httpcore                          0.9.1\n",
      "httpx                             0.13.3\n",
      "hyperframe                        5.2.0\n",
      "idna                              2.10\n",
      "ImageHash                         4.2.1\n",
      "imbalanced-learn                  0.8.0\n",
      "importlib-metadata                4.5.0\n",
      "importlib-resources               5.2.0\n",
      "ipykernel                         5.5.5\n",
      "ipython                           7.24.1\n",
      "ipython-genutils                  0.2.0\n",
      "ipywidgets                        7.6.4\n",
      "jdcal                             1.4.1\n",
      "jedi                              0.18.0\n",
      "Jinja2                            2.11.2\n",
      "jinja2-time                       0.2.0\n",
      "jmespath                          0.10.0\n",
      "joblib                            1.0.1\n",
      "json5                             0.9.5\n",
      "jsonschema                        3.2.0\n",
      "jupyter-client                    6.1.12\n",
      "jupyter-contrib-core              0.3.3\n",
      "jupyter-contrib-nbextensions      0.5.1\n",
      "jupyter-core                      4.7.1\n",
      "jupyter-highlight-selected-word   0.2.0\n",
      "jupyter-latex-envs                1.4.6\n",
      "jupyter-nbextensions-configurator 0.4.1\n",
      "jupyter-server                    1.8.0\n",
      "jupyterlab                        3.0.16\n",
      "jupyterlab-iframe                 0.3.1\n",
      "jupyterlab-pygments               0.1.2\n",
      "jupyterlab-server                 2.6.0\n",
      "jupyterlab-widgets                1.0.1\n",
      "jupyterthemes                     0.20.0\n",
      "kiwisolver                        1.3.1\n",
      "lesscpy                           0.15.0\n",
      "libretranslatepy                  2.1.1\n",
      "lightgbm                          3.2.1\n",
      "lime                              0.2.0.1\n",
      "llvmlite                          0.36.0\n",
      "locket                            0.2.0\n",
      "lxml                              4.6.3\n",
      "MarkupSafe                        1.1.1\n",
      "matplotlib                        3.4.2\n",
      "matplotlib-inline                 0.1.2\n",
      "merakicommons                     1.0.10\n",
      "missingno                         0.4.2\n",
      "mistune                           0.8.4\n",
      "mlxtend                           0.19.0\n",
      "msgpack                           1.0.2\n",
      "multidict                         5.1.0\n",
      "multimethod                       1.4\n",
      "multipledispatch                  0.6.0\n",
      "murmurhash                        1.0.5\n",
      "natsort                           7.1.1\n",
      "nba-api                           1.1.9\n",
      "nbclassic                         0.3.1\n",
      "nbclient                          0.5.3\n",
      "nbconvert                         6.0.7\n",
      "nbformat                          5.1.3\n",
      "nest-asyncio                      1.5.1\n",
      "netCDF4                           1.5.6\n",
      "networkx                          2.6.2\n",
      "nltk                              3.6.2\n",
      "notebook                          6.4.0\n",
      "numba                             0.53.1\n",
      "numpy                             1.20.3\n",
      "oauthlib                          3.1.1\n",
      "olefile                           0.46\n",
      "openai                            0.27.8\n",
      "openpyxl                          3.0.7\n",
      "outcome                           1.2.0\n",
      "packaging                         20.9\n",
      "pandas                            1.2.4\n",
      "pandas-flavor                     0.2.0\n",
      "pandas-gbq                        0.13.2\n",
      "pandas-profiling                  3.0.0\n",
      "pandocfilters                     1.4.2\n",
      "param                             1.11.1\n",
      "parso                             0.8.2\n",
      "partd                             1.2.0\n",
      "pathy                             0.5.2\n",
      "patsy                             0.5.1\n",
      "pep8                              1.7.1\n",
      "phik                              0.12.0\n",
      "pickleshare                       0.7.5\n",
      "Pillow                            8.2.0\n",
      "pip                               21.1.2\n",
      "plotly                            4.14.3\n",
      "ply                               3.11\n",
      "poyo                              0.5.0\n",
      "preshed                           3.0.5\n",
      "prometheus-client                 0.11.0\n",
      "prompt-toolkit                    3.0.18\n",
      "protobuf                          3.16.0\n",
      "psutil                            5.8.0\n",
      "psycopg2                          2.8.6\n",
      "PuLP                              2.6.0\n",
      "pyaml                             20.4.0\n",
      "pyarrow                           6.0.1\n",
      "pyasn1                            0.4.8\n",
      "pyasn1-modules                    0.2.7\n",
      "pycparser                         2.20\n",
      "pyct                              0.4.8\n",
      "pydantic                          1.8.2\n",
      "pydata-google-auth                1.2.0\n",
      "pydeck                            0.7.1\n",
      "Pygments                          2.9.0\n",
      "pyjanitor                         0.21.0\n",
      "Pympler                           1.0.1\n",
      "PyNaCl                            1.5.0\n",
      "pynndescent                       0.5.2\n",
      "pyod                              0.8.7\n",
      "pyOpenSSL                         20.0.1\n",
      "pyparsing                         2.4.7\n",
      "PyQt5                             5.12.3\n",
      "PyQt5-sip                         4.19.18\n",
      "PyQtChart                         5.12\n",
      "PyQtWebEngine                     5.12.1\n",
      "pyreadline                        2.1\n",
      "pyrsistent                        0.17.3\n",
      "PySocks                           1.7.1\n",
      "pystan                            2.19.1.1\n",
      "python-dateutil                   2.8.1\n",
      "python-Levenshtein                0.12.2\n",
      "python-slugify                    5.0.2\n",
      "pytz                              2021.1\n",
      "pytz-deprecation-shim             0.1.0.post0\n",
      "PyWavelets                        1.1.1\n",
      "pywin32                           300\n",
      "pywinpty                          1.1.1\n",
      "pyxlsb                            1.0.8\n",
      "PyYAML                            5.4.1\n",
      "pyzmq                             22.1.0\n",
      "regex                             2021.4.4\n",
      "requests                          2.25.1\n",
      "requests-oauthlib                 1.3.0\n",
      "retrying                          1.3.3\n",
      "rfc3986                           1.5.0\n",
      "rsa                               4.7.2\n",
      "ruamel.yaml                       0.17.4\n",
      "ruamel.yaml.clib                  0.2.6\n",
      "s3transfer                        0.4.2\n",
      "scikit-learn                      1.0\n",
      "scikit-surprise                   1.1.1\n",
      "scipy                             1.6.3\n",
      "seaborn                           0.11.1\n",
      "selenium                          4.11.2\n",
      "Send2Trash                        1.5.0\n",
      "setuptools                        49.6.0.post20210108\n",
      "shap                              0.39.0\n",
      "shellingham                       1.4.0\n",
      "singledispatch                    0.0.0\n",
      "six                               1.16.0\n",
      "slicer                            0.0.7\n",
      "smart-open                        2.2.1\n",
      "smmap                             5.0.0\n",
      "sniffio                           1.2.0\n",
      "sortedcontainers                  2.4.0\n",
      "soupsieve                         2.0.1\n",
      "spacy                             3.0.6\n",
      "spacy-legacy                      3.0.5\n",
      "SQLAlchemy                        1.4.18\n",
      "srsly                             2.4.1\n",
      "statsmodels                       0.12.2\n",
      "streamlit                         1.4.0\n",
      "sweetviz                          2.1.2\n",
      "tabulate                          0.8.9\n",
      "tangled-up-in-unicode             0.1.0\n",
      "tblib                             1.7.0\n",
      "terminado                         0.10.1\n",
      "testpath                          0.5.0\n",
      "text-unidecode                    1.3\n",
      "thinc                             8.0.3\n",
      "threadpoolctl                     2.1.0\n",
      "toml                              0.10.2\n",
      "tomlkit                           0.7.0\n",
      "toolz                             0.11.1\n",
      "tornado                           6.1\n",
      "tornado-proxy-handlers            0.0.5\n",
      "tqdm                              4.50.2\n",
      "traitlets                         5.0.5\n",
      "translate                         3.6.1\n",
      "trio                              0.22.2\n",
      "trio-websocket                    0.10.3\n",
      "typer                             0.3.2\n",
      "typing-extensions                 3.10.0.0\n",
      "tzdata                            2021.5\n",
      "tzlocal                           4.1\n",
      "umap-learn                        0.5.1\n",
      "Unidecode                         1.2.0\n",
      "urllib3                           1.26.5\n",
      "validators                        0.18.2\n",
      "visions                           0.7.1\n",
      "wasabi                            0.8.2\n",
      "watchdog                          2.1.6\n",
      "wcwidth                           0.2.5\n",
      "webencodings                      0.5.1\n",
      "websocket-client                  0.57.0\n",
      "wheel                             0.36.2\n",
      "widgetsnbextension                3.5.1\n",
      "win-inet-pton                     1.1.0\n",
      "wincertstore                      0.2\n",
      "wsproto                           1.2.0\n",
      "xarray                            0.18.2\n",
      "xlrd                              2.0.1\n",
      "xmltodict                         0.12.0\n",
      "yarl                              1.6.3\n",
      "youtube-dl                        2021.12.17\n",
      "zict                              2.0.0\n",
      "zipp                              3.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9bf16758-e2c6-4705-bed3-4b5458220620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aiohttp==3.7.4', 'altair==4.2.0', 'ann-visualizer==2.5', 'anyio==3.1.0', 'apyori==1.1.2', 'argon2-cffi==20.1.0', 'arrow==0.17.0', 'arviz==0.11.2', 'astor==0.8.1', 'async-generator==1.10', 'async-timeout==3.0.1', 'attrs==21.2.0', 'babel==2.9.1', 'backcall==0.2.0', 'backports.functools-lru-cache==1.6.4', 'base58==2.1.1', 'basedosdados==1.5.5', 'beautifulsoup4==4.9.3', 'binaryornot==0.4.4', 'bleach==3.3.0', 'blinker==1.4', 'blis==0.7.4', 'bokeh==2.3.2', 'boto3==1.17.93', 'boto==2.49.0', 'botocore==1.20.93', 'bottleneck==1.2.1', 'branca==0.4.2', 'brotlipy==0.7.0', 'bz2file==0.98', 'cached-property==1.5.2', 'cachetools==4.2.2', 'cassiopeia==5.0.1', 'catalogue==2.0.4', 'catboost==0.26', 'category-encoders==2.3.0', 'certifi==2021.10.8', 'cffi==1.14.5', 'cftime==1.5.0', 'chardet==3.0.4', 'click==8.0.3', 'cloudpickle==1.6.0', 'colorama==0.4.4', 'colorcet==2.0.6', 'cookiecutter==1.7.3', 'cryptography==3.4.7', 'cycler==0.10.0', 'cymem==2.0.5', 'cython==0.29.23', 'cytoolz==0.11.0', 'dask==2021.6.0', 'datapipelines==1.0.7', 'decorator==5.0.9', 'deep-translator==1.6.1', 'defusedxml==0.7.1', 'discord.py==2.0.1', 'distributed==2021.6.0', 'eli5==0.11.0', 'entrypoints==0.3', 'et-xmlfile==1.0.1', 'exceptiongroup==1.1.2', 'feature-engine==1.1.1', 'ffmpeg==1.4', 'folium==0.0.0', 'fsspec==2021.6.0', 'futures==3.1.1', 'fuzzywuzzy==0.18.0', 'gitdb==4.0.9', 'gitpython==3.1.26', 'google-api-core==1.26.3', 'google-auth-oauthlib==0.4.4', 'google-auth==1.30.0', 'google-cloud-bigquery-storage==1.1.0', 'google-cloud-bigquery==1.28.0', 'google-cloud-core==1.5.0', 'google-cloud-storage==1.31.2', 'google-crc32c==1.1.2', 'google-resumable-media==1.2.0', 'googleapis-common-protos==1.53.0', 'googletrans==3.1.0a0', 'goslate==1.5.1', 'graphviz==0.16', 'greenlet==1.1.0', 'grpcio==1.38.0', 'h11==0.9.0', 'h2==3.2.0', 'h5py==3.2.1', 'hdbscan==0.8.27', 'heapdict==1.0.1', 'hpack==3.0.0', 'hstspreload==2021.8.1', 'htmlmin==0.1.12', 'httpcore==0.9.1', 'httpx==0.13.3', 'hyperframe==5.2.0', 'idna==2.10', 'imagehash==4.2.1', 'imbalanced-learn==0.8.0', 'importlib-metadata==4.5.0', 'importlib-resources==5.2.0', 'ipykernel==5.5.5', 'ipython-genutils==0.2.0', 'ipython==7.24.1', 'ipywidgets==7.6.4', 'jdcal==1.4.1', 'jedi==0.18.0', 'jinja2-time==0.2.0', 'jinja2==2.11.2', 'jmespath==0.10.0', 'joblib==1.0.1', 'json5==0.9.5', 'jsonschema==3.2.0', 'jupyter-client==6.1.12', 'jupyter-contrib-core==0.3.3', 'jupyter-contrib-nbextensions==0.5.1', 'jupyter-core==4.7.1', 'jupyter-highlight-selected-word==0.2.0', 'jupyter-latex-envs==1.4.6', 'jupyter-nbextensions-configurator==0.4.1', 'jupyter-server==1.8.0', 'jupyterlab-iframe==0.3.1', 'jupyterlab-pygments==0.1.2', 'jupyterlab-server==2.6.0', 'jupyterlab-widgets==1.0.1', 'jupyterlab==3.0.16', 'jupyterthemes==0.20.0', 'kiwisolver==1.3.1', 'lesscpy==0.15.0', 'libretranslatepy==2.1.1', 'lightgbm==3.2.1', 'lime==0.2.0.1', 'llvmlite==0.36.0', 'locket==0.2.0', 'lxml==4.6.3', 'markupsafe==1.1.1', 'matplotlib-inline==0.1.2', 'matplotlib==3.4.2', 'merakicommons==1.0.10', 'missingno==0.4.2', 'mistune==0.8.4', 'mlxtend==0.19.0', 'msgpack==1.0.2', 'multidict==5.1.0', 'multimethod==1.4', 'multipledispatch==0.6.0', 'murmurhash==1.0.5', 'natsort==7.1.1', 'nba-api==1.1.9', 'nbclassic==0.3.1', 'nbclient==0.5.3', 'nbconvert==6.0.7', 'nbformat==5.1.3', 'nest-asyncio==1.5.1', 'netcdf4==1.5.6', 'networkx==2.6.2', 'nltk==3.6.2', 'notebook==6.4.0', 'numba==0.53.1', 'numpy==1.20.3', 'oauthlib==3.1.1', 'olefile==0.46', 'openai==0.27.8', 'openpyxl==3.0.7', 'outcome==1.2.0', 'packaging==20.9', 'pandas-flavor==0.2.0', 'pandas-gbq==0.13.2', 'pandas-profiling==3.0.0', 'pandas==1.2.4', 'pandocfilters==1.4.2', 'param==1.11.1', 'parso==0.8.2', 'partd==1.2.0', 'pathy==0.5.2', 'patsy==0.5.1', 'pep8==1.7.1', 'phik==0.12.0', 'pickleshare==0.7.5', 'pillow==8.2.0', 'pip==21.1.2', 'plotly==4.14.3', 'ply==3.11', 'poyo==0.5.0', 'preshed==3.0.5', 'prometheus-client==0.11.0', 'prompt-toolkit==3.0.18', 'protobuf==3.16.0', 'psutil==5.8.0', 'psycopg2==2.8.6', 'pulp==2.6.0', 'pyaml==20.4.0', 'pyarrow==6.0.1', 'pyasn1-modules==0.2.7', 'pyasn1==0.4.8', 'pycparser==2.20', 'pyct==0.4.8', 'pydantic==1.8.2', 'pydata-google-auth==1.2.0', 'pydeck==0.7.1', 'pygments==2.9.0', 'pyjanitor==0.21.0', 'pympler==1.0.1', 'pynacl==1.5.0', 'pynndescent==0.5.2', 'pyod==0.8.7', 'pyopenssl==20.0.1', 'pyparsing==2.4.7', 'pyqt5-sip==4.19.18', 'pyqt5==5.12.3', 'pyqtchart==5.12', 'pyqtwebengine==5.12.1', 'pyreadline==2.1', 'pyrsistent==0.17.3', 'pysocks==1.7.1', 'pystan==2.19.1.1', 'python-dateutil==2.8.1', 'python-levenshtein==0.12.2', 'python-slugify==5.0.2', 'pytz-deprecation-shim==0.1.0.post0', 'pytz==2021.1', 'pywavelets==1.1.1', 'pywin32==300', 'pywinpty==1.1.1', 'pyxlsb==1.0.8', 'pyyaml==5.4.1', 'pyzmq==22.1.0', 'regex==2021.4.4', 'requests-oauthlib==1.3.0', 'requests==2.25.1', 'retrying==1.3.3', 'rfc3986==1.5.0', 'rsa==4.7.2', 'ruamel.yaml.clib==0.2.6', 'ruamel.yaml==0.17.4', 's3transfer==0.4.2', 'scikit-learn==1.0', 'scikit-surprise==1.1.1', 'scipy==1.6.3', 'seaborn==0.11.1', 'selenium==4.11.2', 'send2trash==1.5.0', 'setuptools==49.6.0.post20210108', 'shap==0.39.0', 'shellingham==1.4.0', 'singledispatch==0.0.0', 'six==1.16.0', 'slicer==0.0.7', 'smart-open==2.2.1', 'smmap==5.0.0', 'sniffio==1.2.0', 'sortedcontainers==2.4.0', 'soupsieve==2.0.1', 'spacy-legacy==3.0.5', 'spacy==3.0.6', 'sqlalchemy==1.4.18', 'srsly==2.4.1', 'statsmodels==0.12.2', 'streamlit==1.4.0', 'sweetviz==2.1.2', 'tabulate==0.8.9', 'tangled-up-in-unicode==0.1.0', 'tblib==1.7.0', 'terminado==0.10.1', 'testpath==0.5.0', 'text-unidecode==1.3', 'thinc==8.0.3', 'threadpoolctl==2.1.0', 'toml==0.10.2', 'tomlkit==0.7.0', 'toolz==0.11.1', 'tornado-proxy-handlers==0.0.5', 'tornado==6.1', 'tqdm==4.50.2', 'traitlets==5.0.5', 'translate==3.6.1', 'trio-websocket==0.10.3', 'trio==0.22.2', 'typer==0.3.2', 'typing-extensions==3.10.0.0', 'tzdata==2021.5', 'tzlocal==4.1', 'umap-learn==0.5.1', 'unidecode==1.2.0', 'urllib3==1.26.5', 'validators==0.18.2', 'visions==0.7.1', 'wasabi==0.8.2', 'watchdog==2.1.6', 'wcwidth==0.2.5', 'webencodings==0.5.1', 'websocket-client==0.57.0', 'wheel==0.36.2', 'widgetsnbextension==3.5.1', 'win-inet-pton==1.1.0', 'wincertstore==0.2', 'wsproto==1.2.0', 'xarray==0.18.2', 'xlrd==2.0.1', 'xmltodict==0.12.0', 'yarl==1.6.3', 'youtube-dl==2021.12.17', 'zict==2.0.0', 'zipp==3.4.1']\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "installed_packages = pkg_resources.working_set\n",
    "installed_packages_list = sorted([\"%s==%s\" % (i.key, i.version) for i in installed_packages])\n",
    "print(installed_packages_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5415f8cb-3812-463c-ab71-fcb71993ff59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aiohttp==3.7.4',\n",
       " 'altair==4.2.0',\n",
       " 'ann-visualizer==2.5',\n",
       " 'anyio==3.1.0',\n",
       " 'apyori==1.1.2',\n",
       " 'argon2-cffi==20.1.0',\n",
       " 'arrow==0.17.0',\n",
       " 'arviz==0.11.2',\n",
       " 'astor==0.8.1',\n",
       " 'async-generator==1.10',\n",
       " 'async-timeout==3.0.1',\n",
       " 'attrs==21.2.0',\n",
       " 'babel==2.9.1',\n",
       " 'backcall==0.2.0',\n",
       " 'backports.functools-lru-cache==1.6.4',\n",
       " 'base58==2.1.1',\n",
       " 'basedosdados==1.5.5',\n",
       " 'beautifulsoup4==4.9.3',\n",
       " 'binaryornot==0.4.4',\n",
       " 'bleach==3.3.0',\n",
       " 'blinker==1.4',\n",
       " 'blis==0.7.4',\n",
       " 'bokeh==2.3.2',\n",
       " 'boto3==1.17.93',\n",
       " 'boto==2.49.0',\n",
       " 'botocore==1.20.93',\n",
       " 'bottleneck==1.2.1',\n",
       " 'branca==0.4.2',\n",
       " 'brotlipy==0.7.0',\n",
       " 'bz2file==0.98',\n",
       " 'cached-property==1.5.2',\n",
       " 'cachetools==4.2.2',\n",
       " 'cassiopeia==5.0.1',\n",
       " 'catalogue==2.0.4',\n",
       " 'catboost==0.26',\n",
       " 'category-encoders==2.3.0',\n",
       " 'certifi==2021.10.8',\n",
       " 'cffi==1.14.5',\n",
       " 'cftime==1.5.0',\n",
       " 'chardet==3.0.4',\n",
       " 'click==8.0.3',\n",
       " 'cloudpickle==1.6.0',\n",
       " 'colorama==0.4.4',\n",
       " 'colorcet==2.0.6',\n",
       " 'cookiecutter==1.7.3',\n",
       " 'cryptography==3.4.7',\n",
       " 'cycler==0.10.0',\n",
       " 'cymem==2.0.5',\n",
       " 'cython==0.29.23',\n",
       " 'cytoolz==0.11.0',\n",
       " 'dask==2021.6.0',\n",
       " 'datapipelines==1.0.7',\n",
       " 'decorator==5.0.9',\n",
       " 'deep-translator==1.6.1',\n",
       " 'defusedxml==0.7.1',\n",
       " 'discord.py==2.0.1',\n",
       " 'distributed==2021.6.0',\n",
       " 'eli5==0.11.0',\n",
       " 'entrypoints==0.3',\n",
       " 'et-xmlfile==1.0.1',\n",
       " 'exceptiongroup==1.1.2',\n",
       " 'feature-engine==1.1.1',\n",
       " 'ffmpeg==1.4',\n",
       " 'folium==0.0.0',\n",
       " 'fsspec==2021.6.0',\n",
       " 'futures==3.1.1',\n",
       " 'fuzzywuzzy==0.18.0',\n",
       " 'gitdb==4.0.9',\n",
       " 'gitpython==3.1.26',\n",
       " 'google-api-core==1.26.3',\n",
       " 'google-auth-oauthlib==0.4.4',\n",
       " 'google-auth==1.30.0',\n",
       " 'google-cloud-bigquery-storage==1.1.0',\n",
       " 'google-cloud-bigquery==1.28.0',\n",
       " 'google-cloud-core==1.5.0',\n",
       " 'google-cloud-storage==1.31.2',\n",
       " 'google-crc32c==1.1.2',\n",
       " 'google-resumable-media==1.2.0',\n",
       " 'googleapis-common-protos==1.53.0',\n",
       " 'googletrans==3.1.0a0',\n",
       " 'goslate==1.5.1',\n",
       " 'graphviz==0.16',\n",
       " 'greenlet==1.1.0',\n",
       " 'grpcio==1.38.0',\n",
       " 'h11==0.9.0',\n",
       " 'h2==3.2.0',\n",
       " 'h5py==3.2.1',\n",
       " 'hdbscan==0.8.27',\n",
       " 'heapdict==1.0.1',\n",
       " 'hpack==3.0.0',\n",
       " 'hstspreload==2021.8.1',\n",
       " 'htmlmin==0.1.12',\n",
       " 'httpcore==0.9.1',\n",
       " 'httpx==0.13.3',\n",
       " 'hyperframe==5.2.0',\n",
       " 'idna==2.10',\n",
       " 'imagehash==4.2.1',\n",
       " 'imbalanced-learn==0.8.0',\n",
       " 'importlib-metadata==4.5.0',\n",
       " 'importlib-resources==5.2.0',\n",
       " 'ipykernel==5.5.5',\n",
       " 'ipython-genutils==0.2.0',\n",
       " 'ipython==7.24.1',\n",
       " 'ipywidgets==7.6.4',\n",
       " 'jdcal==1.4.1',\n",
       " 'jedi==0.18.0',\n",
       " 'jinja2-time==0.2.0',\n",
       " 'jinja2==2.11.2',\n",
       " 'jmespath==0.10.0',\n",
       " 'joblib==1.0.1',\n",
       " 'json5==0.9.5',\n",
       " 'jsonschema==3.2.0',\n",
       " 'jupyter-client==6.1.12',\n",
       " 'jupyter-contrib-core==0.3.3',\n",
       " 'jupyter-contrib-nbextensions==0.5.1',\n",
       " 'jupyter-core==4.7.1',\n",
       " 'jupyter-highlight-selected-word==0.2.0',\n",
       " 'jupyter-latex-envs==1.4.6',\n",
       " 'jupyter-nbextensions-configurator==0.4.1',\n",
       " 'jupyter-server==1.8.0',\n",
       " 'jupyterlab-iframe==0.3.1',\n",
       " 'jupyterlab-pygments==0.1.2',\n",
       " 'jupyterlab-server==2.6.0',\n",
       " 'jupyterlab-widgets==1.0.1',\n",
       " 'jupyterlab==3.0.16',\n",
       " 'jupyterthemes==0.20.0',\n",
       " 'kiwisolver==1.3.1',\n",
       " 'lesscpy==0.15.0',\n",
       " 'libretranslatepy==2.1.1',\n",
       " 'lightgbm==3.2.1',\n",
       " 'lime==0.2.0.1',\n",
       " 'llvmlite==0.36.0',\n",
       " 'locket==0.2.0',\n",
       " 'lxml==4.6.3',\n",
       " 'markupsafe==1.1.1',\n",
       " 'matplotlib-inline==0.1.2',\n",
       " 'matplotlib==3.4.2',\n",
       " 'merakicommons==1.0.10',\n",
       " 'missingno==0.4.2',\n",
       " 'mistune==0.8.4',\n",
       " 'mlxtend==0.19.0',\n",
       " 'msgpack==1.0.2',\n",
       " 'multidict==5.1.0',\n",
       " 'multimethod==1.4',\n",
       " 'multipledispatch==0.6.0',\n",
       " 'murmurhash==1.0.5',\n",
       " 'natsort==7.1.1',\n",
       " 'nba-api==1.1.9',\n",
       " 'nbclassic==0.3.1',\n",
       " 'nbclient==0.5.3',\n",
       " 'nbconvert==6.0.7',\n",
       " 'nbformat==5.1.3',\n",
       " 'nest-asyncio==1.5.1',\n",
       " 'netcdf4==1.5.6',\n",
       " 'networkx==2.6.2',\n",
       " 'nltk==3.6.2',\n",
       " 'notebook==6.4.0',\n",
       " 'numba==0.53.1',\n",
       " 'numpy==1.20.3',\n",
       " 'oauthlib==3.1.1',\n",
       " 'olefile==0.46',\n",
       " 'openai==0.27.8',\n",
       " 'openpyxl==3.0.7',\n",
       " 'outcome==1.2.0',\n",
       " 'packaging==20.9',\n",
       " 'pandas-flavor==0.2.0',\n",
       " 'pandas-gbq==0.13.2',\n",
       " 'pandas-profiling==3.0.0',\n",
       " 'pandas==1.2.4',\n",
       " 'pandocfilters==1.4.2',\n",
       " 'param==1.11.1',\n",
       " 'parso==0.8.2',\n",
       " 'partd==1.2.0',\n",
       " 'pathy==0.5.2',\n",
       " 'patsy==0.5.1',\n",
       " 'pep8==1.7.1',\n",
       " 'phik==0.12.0',\n",
       " 'pickleshare==0.7.5',\n",
       " 'pillow==8.2.0',\n",
       " 'pip==21.1.2',\n",
       " 'plotly==4.14.3',\n",
       " 'ply==3.11',\n",
       " 'poyo==0.5.0',\n",
       " 'preshed==3.0.5',\n",
       " 'prometheus-client==0.11.0',\n",
       " 'prompt-toolkit==3.0.18',\n",
       " 'protobuf==3.16.0',\n",
       " 'psutil==5.8.0',\n",
       " 'psycopg2==2.8.6',\n",
       " 'pulp==2.6.0',\n",
       " 'pyaml==20.4.0',\n",
       " 'pyarrow==6.0.1',\n",
       " 'pyasn1-modules==0.2.7',\n",
       " 'pyasn1==0.4.8',\n",
       " 'pycparser==2.20',\n",
       " 'pyct==0.4.8',\n",
       " 'pydantic==1.8.2',\n",
       " 'pydata-google-auth==1.2.0',\n",
       " 'pydeck==0.7.1',\n",
       " 'pygments==2.9.0',\n",
       " 'pyjanitor==0.21.0',\n",
       " 'pympler==1.0.1',\n",
       " 'pynacl==1.5.0',\n",
       " 'pynndescent==0.5.2',\n",
       " 'pyod==0.8.7',\n",
       " 'pyopenssl==20.0.1',\n",
       " 'pyparsing==2.4.7',\n",
       " 'pyqt5-sip==4.19.18',\n",
       " 'pyqt5==5.12.3',\n",
       " 'pyqtchart==5.12',\n",
       " 'pyqtwebengine==5.12.1',\n",
       " 'pyreadline==2.1',\n",
       " 'pyrsistent==0.17.3',\n",
       " 'pysocks==1.7.1',\n",
       " 'pystan==2.19.1.1',\n",
       " 'python-dateutil==2.8.1',\n",
       " 'python-levenshtein==0.12.2',\n",
       " 'python-slugify==5.0.2',\n",
       " 'pytz-deprecation-shim==0.1.0.post0',\n",
       " 'pytz==2021.1',\n",
       " 'pywavelets==1.1.1',\n",
       " 'pywin32==300',\n",
       " 'pywinpty==1.1.1',\n",
       " 'pyxlsb==1.0.8',\n",
       " 'pyyaml==5.4.1',\n",
       " 'pyzmq==22.1.0',\n",
       " 'regex==2021.4.4',\n",
       " 'requests-oauthlib==1.3.0',\n",
       " 'requests==2.25.1',\n",
       " 'retrying==1.3.3',\n",
       " 'rfc3986==1.5.0',\n",
       " 'rsa==4.7.2',\n",
       " 'ruamel.yaml.clib==0.2.6',\n",
       " 'ruamel.yaml==0.17.4',\n",
       " 's3transfer==0.4.2',\n",
       " 'scikit-learn==1.0',\n",
       " 'scikit-surprise==1.1.1',\n",
       " 'scipy==1.6.3',\n",
       " 'seaborn==0.11.1',\n",
       " 'selenium==4.11.2',\n",
       " 'send2trash==1.5.0',\n",
       " 'setuptools==49.6.0.post20210108',\n",
       " 'shap==0.39.0',\n",
       " 'shellingham==1.4.0',\n",
       " 'singledispatch==0.0.0',\n",
       " 'six==1.16.0',\n",
       " 'slicer==0.0.7',\n",
       " 'smart-open==2.2.1',\n",
       " 'smmap==5.0.0',\n",
       " 'sniffio==1.2.0',\n",
       " 'sortedcontainers==2.4.0',\n",
       " 'soupsieve==2.0.1',\n",
       " 'spacy-legacy==3.0.5',\n",
       " 'spacy==3.0.6',\n",
       " 'sqlalchemy==1.4.18',\n",
       " 'srsly==2.4.1',\n",
       " 'statsmodels==0.12.2',\n",
       " 'streamlit==1.4.0',\n",
       " 'sweetviz==2.1.2',\n",
       " 'tabulate==0.8.9',\n",
       " 'tangled-up-in-unicode==0.1.0',\n",
       " 'tblib==1.7.0',\n",
       " 'terminado==0.10.1',\n",
       " 'testpath==0.5.0',\n",
       " 'text-unidecode==1.3',\n",
       " 'thinc==8.0.3',\n",
       " 'threadpoolctl==2.1.0',\n",
       " 'toml==0.10.2',\n",
       " 'tomlkit==0.7.0',\n",
       " 'toolz==0.11.1',\n",
       " 'tornado-proxy-handlers==0.0.5',\n",
       " 'tornado==6.1',\n",
       " 'tqdm==4.50.2',\n",
       " 'traitlets==5.0.5',\n",
       " 'translate==3.6.1',\n",
       " 'trio-websocket==0.10.3',\n",
       " 'trio==0.22.2',\n",
       " 'typer==0.3.2',\n",
       " 'typing-extensions==3.10.0.0',\n",
       " 'tzdata==2021.5',\n",
       " 'tzlocal==4.1',\n",
       " 'umap-learn==0.5.1',\n",
       " 'unidecode==1.2.0',\n",
       " 'urllib3==1.26.5',\n",
       " 'validators==0.18.2',\n",
       " 'visions==0.7.1',\n",
       " 'wasabi==0.8.2',\n",
       " 'watchdog==2.1.6',\n",
       " 'wcwidth==0.2.5',\n",
       " 'webencodings==0.5.1',\n",
       " 'websocket-client==0.57.0',\n",
       " 'wheel==0.36.2',\n",
       " 'widgetsnbextension==3.5.1',\n",
       " 'win-inet-pton==1.1.0',\n",
       " 'wincertstore==0.2',\n",
       " 'wsproto==1.2.0',\n",
       " 'xarray==0.18.2',\n",
       " 'xlrd==2.0.1',\n",
       " 'xmltodict==0.12.0',\n",
       " 'yarl==1.6.3',\n",
       " 'youtube-dl==2021.12.17',\n",
       " 'zict==2.0.0',\n",
       " 'zipp==3.4.1']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "installed_packages_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2d49078e-b57f-4e3b-9192-b98eece08d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close()>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_r = open('requirements.txt', 'a')\n",
    "for item in installed_packages_list:\n",
    "    file_r.write(f'{item}\\n')\n",
    "file_r.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccdd25b-b605-496c-bbf3-29cf74b199e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_r.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "05a0429e-39df-4d0a-9a47-efaa2f4cf2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pipreqs\n",
      "  Downloading pipreqs-0.4.13-py2.py3-none-any.whl (33 kB)\n",
      "Collecting docopt\n",
      "  Using cached docopt-0.6.2.tar.gz (25 kB)\n",
      "Collecting yarg\n",
      "  Using cached yarg-0.1.9-py2.py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\elias-acer\\anaconda3\\envs\\dh\\lib\\site-packages (from yarg->pipreqs) (2.25.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\elias-acer\\anaconda3\\envs\\dh\\lib\\site-packages (from requests->yarg->pipreqs) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\elias-acer\\anaconda3\\envs\\dh\\lib\\site-packages (from requests->yarg->pipreqs) (2021.10.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\elias-acer\\anaconda3\\envs\\dh\\lib\\site-packages (from requests->yarg->pipreqs) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\elias-acer\\anaconda3\\envs\\dh\\lib\\site-packages (from requests->yarg->pipreqs) (3.0.4)\n",
      "Building wheels for collected packages: docopt\n",
      "  Building wheel for docopt (setup.py): started\n",
      "  Building wheel for docopt (setup.py): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=e568856a3e4c6b2fd714c6a545fc0cb4f8aaa6c47e119271c480352452418341\n",
      "  Stored in directory: c:\\users\\elias-acer\\appdata\\local\\pip\\cache\\wheels\\70\\4a\\46\\1309fc853b8d395e60bafaf1b6df7845bdd82c95fd59dd8d2b\n",
      "Successfully built docopt\n",
      "Installing collected packages: yarg, docopt, pipreqs\n",
      "Successfully installed docopt-0.6.2 pipreqs-0.4.13 yarg-0.1.9\n"
     ]
    }
   ],
   "source": [
    "!pip install pipreqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "76c48711-d10c-416c-a65d-f43d44bd1a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pipreqs' from 'C:\\\\Users\\\\Elias-Acer\\\\anaconda3\\\\envs\\\\dh\\\\lib\\\\site-packages\\\\pipreqs\\\\__init__.py'>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pipreqs\n",
    "pipreqs \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "be41906c-ffa8-4ea8-b406-826cd7528875",
   "metadata": {},
   "outputs": [],
   "source": [
    "caminho = r\"C:\\\\Users\\\\Elias-Acer\\\\Alura\\\\NLP\\\\termo solver\\\\project_termo_solver\\\\\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "62de8f24-e934-49aa-929b-07897e755abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Usage:\n",
      "    pipreqs [options] [<path>]\n"
     ]
    }
   ],
   "source": [
    "!pipreqs --use-local '.\\termo solver'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521b66d2-9308-41b2-a0cf-c5d77279ab74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
